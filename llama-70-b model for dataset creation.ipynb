{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048cee2e",
   "metadata": {},
   "source": [
    "# Llama Model for Classifying Misleading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58786e-a306-40a3-b13a-f103fc63017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 30/30 [03:24<00:00,  6.81s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "hf_token = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "cache_dir = \"./\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_dir,token= hf_token)\n",
    "# Load the model and move sit to GPU 1\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir,\n",
    "    device_map=\"auto\",  # enables automatic GPU placement\n",
    "    token= hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daf0385-cd6f-4d40-8dbd-f5225c03b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d75f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load model and tokenizer\n",
    "\n",
    "# Prepare the input prompt\n",
    "def prepare_prompt(row):\n",
    "    return f\"\"\"You will be given a fact, a correct statement, a false statement, and a tweet (inside triple backticks).  \n",
    "Your task is to classify the relationship between the tweet and the fact. \n",
    "First, decide whether the tweet is **irrelevant** to the fact.  \n",
    "If the tweet is relevant, determine whether it supports or refutes the fact.\n",
    "\n",
    "Respond with only one of the following labels:  [irrelevant, supporting, or refuting] \n",
    "Do not provide any explanation.\n",
    "\n",
    "Fact: {row['fact']}  \n",
    "Correct Statement: {row['supporting']}  \n",
    "False Statement: {row['refuting']}  \n",
    "Tweet: ```{row['tweet_text']}```\"\"\"\n",
    "\n",
    "# Generate stance for each row\n",
    "def get_stance(row):\n",
    "    input_text = prepare_prompt(row)\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    # Generate model output\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    # Decode model output\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "df = df[df['Final Labeling'].notna() & (df['Final Labeling'].str.strip() != '')]\n",
    "# Apply stance generation function to the entire DataFrame\n",
    "df['stance_llama_70_b_new_val'] = df.apply(get_stance, axis=1)\n",
    "# Save the entire DataFrame to one CSV\n",
    "df.to_csv(\"final_results_2.csv\", index=False)\n",
    "print(\"All results saved to final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c1a2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91413933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutralProcessing complete. Results saved to 'updated_stance_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "client = OpenAI(api_key = api_key)\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "def prepare_prompt(row):\n",
    "    \"\"\"\n",
    "    Prepares the input prompt for the stance classification task.\n",
    "    \"\"\"\n",
    "    return f\"\"\"You will be provided with a tweet, delimited by triple backticks, related to the given fact, correct statement, and false statement. Indicate whether the tweet supports, refutes, or is neutral regarding the fact.\n",
    "    Your response should be one of the following: [supporting, refuting, neutral]. Do not include any explanation.\n",
    "Fact: {row['fact']}\n",
    "Correct Statement: {row['supporting']}\n",
    "False Statement: {row['refuting']}\n",
    "Tweet: {row['tweet_text']}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_stance(row):\n",
    "    \"\"\"\n",
    "    Sends the prepared prompt to the OpenAI model and returns the response.\n",
    "    \"\"\"\n",
    "    prompt_text = prepare_prompt(row)\n",
    "    \n",
    "    try:\n",
    "        # Send the prompt to the OpenAI API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"meta/llama-3.1-70b-instruct\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            temperature=0.2,\n",
    "            top_p=0.7,\n",
    "            max_tokens=1024,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in completion:\n",
    "          if chunk.choices[0].delta.content is not None:\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row.name}: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "# Apply the model to each row and create a new column\n",
    "df['stance_llama_api_final'] = df.apply(get_stance, axis=1)\n",
    "# Save the updated dataframe\n",
    "#df.to_csv(\"final_results.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'updated_stance_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac212088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_prompt(row):\n",
    "    \"\"\"\n",
    "    Prepares the input prompt for the stance classification task.\n",
    "    \"\"\"\n",
    "    return f\"\"\"You will be provided with a tweet, delimited by triple backticks, related to the given fact, correct statement, and false statement. Indicate whether the tweet supports or refutes regarding the fact.\n",
    "    Your response should be one of the following: [supporting, refuting]. Do not include any explanation.\n",
    "Fact: {row['fact']}\n",
    "Correct Statement: {row['supporting']}\n",
    "False Statement: {row['refuting']}\n",
    "Tweet: {row['tweet_text']}\n",
    "    \"\"\"\n",
    "def get_stance(row):\n",
    "    prompt_text = prepare_prompt(row)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"meta/llama-3.1-70b-instruct\",\n",
    "      messages=[{\"role\":\"user\",\"content\": prompt_text}],\n",
    "      temperature=0.2,\n",
    "      top_p=0.7,\n",
    "      max_tokens=1024,\n",
    "      stream=False\n",
    "    )\n",
    "    response_text = completion.choices[0].message.content.strip()\n",
    "    print(response_text)\n",
    "    return response_text\n",
    "df = pd.read_csv(\"multimodal-playground/ann_dataset_misleading.csv\")\n",
    "# Apply the model to each row and create a new column\n",
    "df['stance_llama_api_final'] = df.apply(get_stance, axis=1)\n",
    "# Save the updated dataframe\n",
    "df.to_csv(\"final_results_2.csv\", index=False)\n",
    "\n",
    "print(\"Processing complete. Results saved to 'updated_stance_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef850831-8365-4723-a42c-420c9dad5218",
   "metadata": {},
   "source": [
    "# Cross Encoder Models for Topic Relevancy for Misleading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c766b-d742-47d0-9598-70b4052d7626",
   "metadata": {},
   "source": [
    "# MixedBread AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75721c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cache_dir = \"./\"\n",
    "\n",
    "    \n",
    "# Load the model, here we use our base sized model\n",
    "# Load the model\n",
    "model = CrossEncoder(\n",
    "    \"mixedbread-ai/mxbai-rerank-large-v1\",\n",
    "device=\"cuda:0\",    cache_dir=cache_dir\n",
    ")\n",
    "# Example query and documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2621fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float32(0.99801946), np.float32(0.9969399), np.float32(0.0294786)]\n",
      "[\"'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\", \"Harper Lee, an American novelist widely known for her novel 'To Kill a Mockingbird', was born in 1926 in Monroeville, Alabama. She received the Pulitzer Prize for Fiction in 1961.\", \"'The Great Gatsby', a novel written by American author F. Scott Fitzgerald, was published in 1925. The story is set in the Jazz Age and follows the life of millionaire Jay Gatsby and his pursuit of Daisy Buchanan.\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"Who wrote 'To Kill a Mockingbird'?\"\n",
    "documents = [\n",
    "    \"'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\",\n",
    "    \"The novel 'Moby-Dick' was written by Herman Melville and first published in 1851. It is considered a masterpiece of American literature and deals with complex themes of obsession, revenge, and the conflict between good and evil.\",\n",
    "    \"Harper Lee, an American novelist widely known for her novel 'To Kill a Mockingbird', was born in 1926 in Monroeville, Alabama. She received the Pulitzer Prize for Fiction in 1961.\",\n",
    "    \"Jane Austen was an English novelist known primarily for her six major novels, which interpret, critique and comment upon the British landed gentry at the end of the 18th century.\",\n",
    "    \"The 'Harry Potter' series, which consists of seven fantasy novels written by British author J.K. Rowling, is among the most popular and critically acclaimed books of the modern era.\",\n",
    "    \"'The Great Gatsby', a novel written by American author F. Scott Fitzgerald, was published in 1925. The story is set in the Jazz Age and follows the life of millionaire Jay Gatsby and his pursuit of Daisy Buchanan.\"\n",
    "]\n",
    "\n",
    "# Lets get the scores\n",
    "results = model.rank(query, documents, return_documents=True, top_k=3)\n",
    "# Extract scores\n",
    "scores = [item['score'] for item in results]\n",
    "text = [item['text'] for item in results]\n",
    "\n",
    "print(scores)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce0bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  fact  \\\n",
      "0    Any pauses in counting were part of routine pr...   \n",
      "1    Any pauses in counting were part of routine pr...   \n",
      "2    Any pauses in counting were part of routine pr...   \n",
      "3    Any pauses in counting were part of routine pr...   \n",
      "4    Any pauses in counting were part of routine pr...   \n",
      "..                                                 ...   \n",
      "817  This image, claimed to show discarded 2020 bal...   \n",
      "818  This image, claimed to show discarded 2020 bal...   \n",
      "819  This image, claimed to show discarded 2020 bal...   \n",
      "820  This image, claimed to show discarded 2020 bal...   \n",
      "821  This image, claimed to show discarded 2020 bal...   \n",
      "\n",
      "                                            tweet_text  score_mixedbread_fact  \n",
      "0    Why Did Six Battleground States with Democrat ...                 0.4280  \n",
      "1    Take a look at these 5 States that were all fa...                 0.4077  \n",
      "2    The EXACT moment when all these swing states S...                 0.3370  \n",
      "3    These are the vote counts when ALL of these De...                 0.3000  \n",
      "4    This is how it was when they stopped counting....                 0.2938  \n",
      "..                                                 ...                    ...  \n",
      "817  This photo represents more than the margin of ...                 0.1014  \n",
      "818  Biden knew vote by mail is his only chance of ...                 0.0809  \n",
      "819  Saw this on a back ally road in PA yesterday.....                 0.0453  \n",
      "820  Biden demands vote by mail ballot harvesting.....                 0.0432  \n",
      "821  TWITTER,FACEBOOK,GOOGLE,&amp; OTHER PLATFORMS ...                 0.0183  \n",
      "\n",
      "[822 rows x 3 columns]\n",
      "                                          tweet_text  \\\n",
      "0  I'm not sure voter malpractice occurred, but a...   \n",
      "1  Although I believe trump will lose the electio...   \n",
      "2  Michigan - Biden votes came out of nowhere fro...   \n",
      "3  See how Demos add fake voters in WI and MI. ??...   \n",
      "4  For Biden, it is considered that at the moment...   \n",
      "\n",
      "  is tweet-image pair relevant? Author Labeling         storyid  \\\n",
      "0                           NaN             NaN  story_2+648+28   \n",
      "1                           NaN             NaN  story_2+648+28   \n",
      "2                           NaN             NaN  story_2+648+28   \n",
      "3                      positive        refuting  story_2+648+28   \n",
      "4                      positive        refuting  story_2+648+28   \n",
      "\n",
      "                                          supporting  \\\n",
      "0  The vote spike for Biden in these charts was d...   \n",
      "1  The vote spike for Biden in these charts was d...   \n",
      "2  The vote spike for Biden in these charts was d...   \n",
      "3  The vote spike for Biden in these charts was d...   \n",
      "4  The vote spike for Biden in these charts was d...   \n",
      "\n",
      "                                            refuting  \\\n",
      "0  Early morning election results with sudden spi...   \n",
      "1  Early morning election results with sudden spi...   \n",
      "2  Early morning election results with sudden spi...   \n",
      "3  Early morning election results with sudden spi...   \n",
      "4  Early morning election results with sudden spi...   \n",
      "\n",
      "                                                fact   max_score   stance1  \\\n",
      "0  Some graphs online misrepresent normal vote-co...  6864430791  supports   \n",
      "1  Some graphs online misrepresent normal vote-co...  6496571467   refutes   \n",
      "2  Some graphs online misrepresent normal vote-co...  5463319356  supports   \n",
      "3  Some graphs online misrepresent normal vote-co...  6654402574  supports   \n",
      "4  Some graphs online misrepresent normal vote-co...  7175901637  supports   \n",
      "\n",
      "   stance2  ... stance_llama_irr_r bge_score bge_score_llm score_mixedbread  \\\n",
      "0      NaN  ...         irrelevant   -4.0273        3.7559           0.0088   \n",
      "1      NaN  ...           relevant  -10.0000        1.6396           0.0069   \n",
      "2      NaN  ...           relevant   -7.9023        3.0820           0.0121   \n",
      "3  refutes  ...           relevant   -3.0957        5.1992           0.0078   \n",
      "4  refutes  ...           relevant   -3.8281        3.5059           0.0068   \n",
      "\n",
      "  score_stella_s  score_stella_p  colbert_score  score_stella_1.5b_p  \\\n",
      "0         0.4276          0.6018      12.976562               0.6311   \n",
      "1         0.3330          0.5207       0.000000               0.5095   \n",
      "2         0.3947          0.5239      14.734375               0.5677   \n",
      "3         0.4395          0.6045      17.015625               0.6168   \n",
      "4         0.4146          0.6047      14.015625               0.5832   \n",
      "\n",
      "   max_score_mixedbread  max_score_mixedbread_new_val  \n",
      "0                0.0190                        0.0086  \n",
      "1                0.1060                        0.0069  \n",
      "2                0.1461                        0.0121  \n",
      "3                0.0266                        0.0078  \n",
      "4                0.0221                        0.0068  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Group rows by 'fact' and collect corresponding tweets\n",
    "grouped = df.groupby('fact')['tweet_text'].apply(list).reset_index()\n",
    "grouped.columns = ['fact', 'documents']\n",
    "\n",
    "# Prepare a DataFrame to store the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate over each fact and its associated documents\n",
    "for _, row in grouped.iterrows():\n",
    "    fact = row['fact']  # Query\n",
    "    documents = row['documents']  # List of tweets\n",
    "    results = model.rank(fact, documents, return_documents=True, top_k=len(documents))  # Rank all documents\n",
    "\n",
    "    # Map the scores back to the original DataFrame rows\n",
    "    for result in results:\n",
    "        results_list.append({\n",
    "            'fact': fact,\n",
    "            'tweet_text': result['text'],\n",
    "            'score_mixedbread_fact': round(result['score'], 4)\n",
    "        })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df_fact = pd.DataFrame(results_list)\n",
    "\n",
    "# Group rows by 'fact' and collect corresponding tweets\n",
    "grouped = df.groupby('supporting')['tweet_text'].apply(list).reset_index()\n",
    "grouped.columns = ['supporting', 'documents']\n",
    "\n",
    "# Prepare a DataFrame to store the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate over each fact and its associated documents\n",
    "for _, row in grouped.iterrows():\n",
    "    supporting = row['supporting']  # Query\n",
    "    documents = row['documents']  # List of tweets\n",
    "    results = model.rank(supporting, documents, return_documents=True, top_k=len(documents))  # Rank all documents\n",
    "\n",
    "    # Map the scores back to the original DataFrame rows\n",
    "    for result in results:\n",
    "        results_list.append({\n",
    "            'supporting': supporting,\n",
    "            'tweet_text': result['text'],\n",
    "            'score_mixedbread_supporting': round(result['score'], 4)\n",
    "        })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df_supporting = pd.DataFrame(results_list)\n",
    "\n",
    "# Group rows by 'fact' and collect corresponding tweets\n",
    "grouped = df.groupby('refuting')['tweet_text'].apply(list).reset_index()\n",
    "grouped.columns = ['refuting', 'documents']\n",
    "\n",
    "# Prepare a DataFrame to store the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate over each fact and its associated documents\n",
    "for _, row in grouped.iterrows():\n",
    "    refuting = row['refuting']  # Query\n",
    "    documents = row['documents']  # List of tweets\n",
    "    results = model.rank(refuting, documents, return_documents=True, top_k=len(documents))  # Rank all documents\n",
    "\n",
    "    # Map the scores back to the original DataFrame rows\n",
    "    for result in results:\n",
    "        results_list.append({\n",
    "            'refuting': fact,\n",
    "            'tweet_text': result['text'],\n",
    "            'score_mixedbread_refuting': round(result['score'], 4)\n",
    "        })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df_refuting = pd.DataFrame(results_list)\n",
    "# Merging all dataframes on 'tweet_text' column\n",
    "merged_df = pd.merge(results_df_fact, results_df_supporting, on=\"tweet_text\", how=\"outer\")\n",
    "merged_df = pd.merge(merged_df, results_df_refuting, on=\"tweet_text\", how=\"outer\")\n",
    "\n",
    "# Taking the maximum score across all score columns\n",
    "merged_df[\"max_score_mixedbread_new_val\"] = merged_df[[\"score_mixedbread_refuting\", \"score_mixedbread_supporting\", \"score_mixedbread_fact\"]\n",
    "].min(axis=1)\n",
    "# Creating a new DataFrame with only the necessary columns\n",
    "results_df_max = merged_df[[\"tweet_text\", \"max_score_mixedbread_new_val\"]]\n",
    "print(results_df_fact)\n",
    "# Displaying the results\n",
    "results_df_max\n",
    "\n",
    "#Merge the original DataFrame with the scores DataFrame on 'fact' and 'tweet_text'\n",
    "merged_df = pd.merge(df, results_df_max, on=['tweet_text'], how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "merged_df.to_csv(\"updated_stance_results_with_max_mixedbread_scores.csv\", index=False)\n",
    "\n",
    "# Print a sample of the updated DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.002203631036310363\n",
      "Minimum Misclassification: 40\n",
      "Misclassification Rate: 0.2312\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 20  32]\n",
      " [  8 113]]\n",
      "                                           tweet_text  max_score_mixedbread_y  \\\n",
      "3   See how Demos add fake voters in WI and MI. ??...                  0.0078   \n",
      "4   For Biden, it is considered that at the moment...                  0.0068   \n",
      "6   Look at democrats mysterious jump to win after...                  0.0066   \n",
      "13  I still have not heard an explanation of this....                  0.0035   \n",
      "17  Michigan manufactures Biden Ballots outrageous...                  0.0048   \n",
      "\n",
      "   Author Labeling Final Classification  \n",
      "3         refuting                  NaN  \n",
      "4         refuting                  NaN  \n",
      "6         refuting                  NaN  \n",
      "13        refuting                  NaN  \n",
      "17        refuting                  NaN  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "# Map Author Labeling to binary classes\n",
    "df['Author Labeling Binary'] = df['Author Labeling'].map({\n",
    "    'irrelevant': 0,\n",
    "    'refuting': 1,\n",
    "    'supporting': 1\n",
    "})\n",
    "\n",
    "# Ensure there are no missing values in scores or labels\n",
    "df = df.dropna(subset=['max_score_mixedbread_y', 'Author Labeling Binary'])\n",
    "\n",
    "# Sweep through thresholds to find the optimal one\n",
    "thresholds = np.linspace(df['max_score_mixedbread_y'].min(), df['max_score_mixedbread_y'].max(), 100000)  # 100 thresholds between min and max score\n",
    "min_misclassification = float('inf')\n",
    "optimal_threshold = None\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Predict based on the threshold\n",
    "    df['Predicted Label'] = (df['max_score_mixedbread_y'] >= threshold).astype(int)\n",
    "\n",
    "    # Calculate misclassification error\n",
    "    misclassification = (df['Predicted Label'] != df['Author Labeling Binary']).sum()\n",
    "\n",
    "    # Update optimal threshold\n",
    "    if misclassification < min_misclassification:\n",
    "        min_misclassification = misclassification\n",
    "        optimal_threshold = threshold\n",
    "df['Predicted Label'] = (df['max_score_mixedbread_y'] >= optimal_threshold).astype(int)\n",
    "\n",
    "# Print the optimal threshold and the corresponding misclassification error\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Minimum Misclassification: {min_misclassification}\")\n",
    "\n",
    "# Apply the optimal threshold to classify tweets\n",
    "df['Final Classification'] = (df['max_score_mixedbread_y'] >= optimal_threshold).map({0: 'irrelevant', 1: 'relevant'})\n",
    "\n",
    "# Calculate Misclassification Rate\n",
    "misclassification_rate = min_misclassification / len(df)\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "\n",
    "# Generate the Confusion Matrix\n",
    "y_true = df['Author Labeling Binary']\n",
    "y_pred = df['Predicted Label']\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['irrelevant', 'relevant']).plot()\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(\"classified_stance_results.csv\", index=False)\n",
    "\n",
    "# Display a sample of the classified DataFrame\n",
    "print(df[['tweet_text', 'max_score_mixedbread_y', 'Author Labeling', 'Final Classification']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031101b-e8e0-41ed-ac96-e6bbe7b04812",
   "metadata": {},
   "source": [
    "# BGE Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3182eb-e1ef-4fa9-9bd4-f0131be16b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "cache_dir = \"./\"\n",
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True, cache_dir= cache_dir) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "score = reranker.compute_score(['query', 'passage'])\n",
    "print(score) # -5.65234375\n",
    "\n",
    "# You can map the scores into 0-1 by set \"normalize=True\", which will apply sigmoid function to the score\n",
    "score = reranker.compute_score(['query', 'passage'], normalize=True)\n",
    "print(score) # 0.003497010252573502\n",
    "\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores) # [-8.1875, 5.26171875]\n",
    "\n",
    "# You can map the scores into 0-1 by set \"normalize=True\", which will apply sigmoid function to the score\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']], normalize=True)\n",
    "print(scores) # [0.00027803096387751553, 0.9948403768236574]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f16b74-cc14-4396-a76c-af543f9f4ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGE ranker scores computed for 'fact', 'supporting', and 'refuting', and maximum score saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute the BGE ranker score\n",
    "def compute_bge_score(query, passage):\n",
    "    # Compute the score using reranker\n",
    "    score = reranker.compute_score([query, passage])\n",
    "    return score[0] if isinstance(score, list) else score\n",
    "\n",
    "# Compute scores for 'fact'\n",
    "df['bge_ranker_score_fact'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['fact'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "# Compute scores for 'supporting'\n",
    "df['bge_ranker_score_supporting'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['supporting'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "# Compute scores for 'refuting'\n",
    "df['bge_ranker_score_refuting'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['refuting'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "# Take the maximum score across the computed columns\n",
    "df['max_bge_ranker_score_new_val'] = df[\n",
    "    ['bge_ranker_score_fact', 'bge_ranker_score_supporting', 'bge_ranker_score_refuting']\n",
    "].max(axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"updated_stance_results_with_bge_ranker_scores.csv\", index=False)\n",
    "\n",
    "print(\"BGE ranker scores computed for 'fact', 'supporting', and 'refuting', and maximum score saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334304f-18a4-4d73-9937-359f47a93f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: -6.664015702657027\n",
      "Minimum Misclassification: 46\n",
      "Misclassification Rate: 0.2659\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 11  41]\n",
      " [  5 116]]\n",
      "                                           tweet_text  \\\n",
      "3   See how Demos add fake voters in WI and MI. ??...   \n",
      "4   For Biden, it is considered that at the moment...   \n",
      "6   Look at democrats mysterious jump to win after...   \n",
      "13  I still have not heard an explanation of this....   \n",
      "17  Michigan manufactures Biden Ballots outrageous...   \n",
      "\n",
      "    max_bge_ranker_score_new_val Author Labeling Final Classification  \n",
      "3                      -0.304688        refuting                  NaN  \n",
      "4                      -1.161133        refuting                  NaN  \n",
      "6                      -5.363281        refuting                  NaN  \n",
      "13                     -2.929688        refuting                  NaN  \n",
      "17                     -3.132812        refuting                  NaN  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "# Map Author Labeling to binary classes\n",
    "df['Author Labeling Binary'] = df['Author Labeling'].map({\n",
    "    'irrelevant': 0,\n",
    "    'refuting': 1,\n",
    "    'supporting': 1\n",
    "})\n",
    "\n",
    "# Ensure there are no missing values in scores or labels\n",
    "df = df.dropna(subset=['max_bge_ranker_score_new_val', 'Author Labeling Binary'])\n",
    "\n",
    "# Sweep through thresholds to find the optimal one\n",
    "thresholds = np.linspace(df['max_bge_ranker_score_new_val'].min(), df['max_bge_ranker_score_new_val'].max(), 100000)  # 100 thresholds between min and max score\n",
    "min_misclassification = float('inf')\n",
    "optimal_threshold = None\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Predict based on the threshold\n",
    "    df['Predicted Label'] = (df['max_bge_ranker_score_new_val'] >= threshold).astype(int)\n",
    "\n",
    "    # Calculate misclassification error\n",
    "    misclassification = (df['Predicted Label'] != df['Author Labeling Binary']).sum()\n",
    "\n",
    "    # Update optimal threshold\n",
    "    if misclassification < min_misclassification:\n",
    "        min_misclassification = misclassification\n",
    "        optimal_threshold = threshold\n",
    "df['Predicted Label'] = (df['max_bge_ranker_score_new_val'] >= optimal_threshold).astype(int)\n",
    "\n",
    "# Print the optimal threshold and the corresponding misclassification error\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Minimum Misclassification: {min_misclassification}\")\n",
    "\n",
    "# Apply the optimal threshold to classify tweets\n",
    "df['Final Classification'] = (df['max_bge_ranker_score_new_val'] >= optimal_threshold).map({0: 'irrelevant', 1: 'relevant'})\n",
    "\n",
    "# Calculate Misclassification Rate\n",
    "misclassification_rate = min_misclassification / len(df)\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "\n",
    "# Generate the Confusion Matrix\n",
    "y_true = df['Author Labeling Binary']\n",
    "y_pred = df['Predicted Label']\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['irrelevant', 'relevant']).plot()\n",
    "\n",
    "# Save the results\n",
    "#df.to_csv(\"classified_stance_results.csv\", index=False)\n",
    "\n",
    "# Display a sample of the classified DataFrame\n",
    "print(df[['tweet_text', 'max_bge_ranker_score_new_val', 'Author Labeling', 'Final Classification']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010faf8-b0f6-4447-8a74-708d418df83f",
   "metadata": {},
   "source": [
    "# BGE Ranker LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e9ca98-3ce3-450f-8751-ff70ecc4864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  9.68it/s]\n",
      "You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.958984375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 71.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98095703125, 10.71875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagLLMReranker\n",
    "cache_dir = \"./\"\n",
    "reranker = FlagLLMReranker('BAAI/bge-reranker-v2-gemma', use_fp16=True, cache_dir= cache_dir) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "# reranker = FlagLLMReranker('BAAI/bge-reranker-v2-gemma', use_bf16=True) # You can also set use_bf16=True to speed up computation with a slight performance degradation\n",
    "\n",
    "score = reranker.compute_score(['query', 'passage'])\n",
    "print(score)\n",
    "\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7fde7-c21b-4d00-bc67-5bdedd4bd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute the BGE ranker score\n",
    "def compute_bge_score(query, passage):\n",
    "    # Compute the score using reranker\n",
    "    score = reranker.compute_score([query, passage])\n",
    "    return score[0] if isinstance(score, list) else score\n",
    "\n",
    "# Compute scores for 'fact'\n",
    "df['bge_ranker_score_fact'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['fact'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "# Compute scores for 'supporting'\n",
    "df['bge_ranker_score_supporting'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['supporting'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "# Compute scores for 'refuting'\n",
    "df['bge_ranker_score_refuting'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['refuting'], row['tweet_text']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df['max_bge_ranker_score_llm_new_val'] = df[\n",
    "    ['bge_ranker_score_fact', 'bge_ranker_score_supporting', 'bge_ranker_score_refuting']\n",
    "].max(axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"updated_stance_results_with_bge_ranker_scores_llm.csv\", index=False)\n",
    "\n",
    "print(\"BGE ranker scores computed for 'fact', 'supporting', and 'refuting', and maximum score saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf826de7-6ad6-45c1-be61-df7704236ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute the BGE ranker score\n",
    "def compute_bge_score(query, passage):\n",
    "    # Compute the score using reranker\n",
    "    score = reranker.compute_score([query, passage])\n",
    "    return score[0] if isinstance(score, list) else score\n",
    "\n",
    "# Compute scores for 'fact'\n",
    "df['bge_ranker_score_fact_llm'] = df.apply(\n",
    "    lambda row: compute_bge_score(row['fact'], row['tweet_text']), axis=1\n",
    ")\n",
    "df.to_csv(\"updated_stance_results_with_bge_ranker_scores.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b6b0b-b9c8-4c44-8016-c7a44747c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 3.865287791061504\n",
      "Minimum Misclassification: 36\n",
      "Misclassification Rate: 0.2081\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 33  19]\n",
      " [ 17 104]]\n",
      "                                           tweet_text  \\\n",
      "3   See how Demos add fake voters in WI and MI. ??...   \n",
      "4   For Biden, it is considered that at the moment...   \n",
      "6   Look at democrats mysterious jump to win after...   \n",
      "13  I still have not heard an explanation of this....   \n",
      "17  Michigan manufactures Biden Ballots outrageous...   \n",
      "\n",
      "    max_bge_ranker_score_llm_new_val Author Labeling Final Classification  \n",
      "3                           7.953125        refuting                  NaN  \n",
      "4                           6.585938        refuting                  NaN  \n",
      "6                           4.542969        refuting                  NaN  \n",
      "13                          6.164062        refuting                  NaN  \n",
      "17                          6.375000        refuting                  NaN  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "# Map Author Labeling to binary classes\n",
    "df['Author Labeling Binary'] = df['Author Labeling'].map({\n",
    "    'irrelevant': 0,\n",
    "    'refuting': 1,\n",
    "    'supporting': 1\n",
    "})\n",
    "\n",
    "# Ensure there are no missing values in scores or labels\n",
    "df = df.dropna(subset=['max_bge_ranker_score_llm_new_val', 'Author Labeling Binary'])\n",
    "\n",
    "# Sweep through thresholds to find the optimal one\n",
    "thresholds = np.linspace(df['max_bge_ranker_score_llm_new_val'].min(), df['max_bge_ranker_score_llm_new_val'].max(), 100000)  # 100 thresholds between min and max score\n",
    "min_misclassification = float('inf')\n",
    "optimal_threshold = None\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Predict based on the threshold\n",
    "    df['Predicted Label'] = (df['max_bge_ranker_score_llm_new_val'] >= threshold).astype(int)\n",
    "\n",
    "    # Calculate misclassification error\n",
    "    misclassification = (df['Predicted Label'] != df['Author Labeling Binary']).sum()\n",
    "\n",
    "    # Update optimal threshold\n",
    "    if misclassification < min_misclassification:\n",
    "        min_misclassification = misclassification\n",
    "        optimal_threshold = threshold\n",
    "df['Predicted Label'] = (df['max_bge_ranker_score_llm_new_val'] >= optimal_threshold).astype(int)\n",
    "\n",
    "# Print the optimal threshold and the corresponding misclassification error\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Minimum Misclassification: {min_misclassification}\")\n",
    "\n",
    "# Apply the optimal threshold to classify tweets\n",
    "df['Final Classification'] = (df['max_bge_ranker_score_llm_new_val'] >= optimal_threshold).map({0: 'irrelevant', 1: 'relevant'})\n",
    "\n",
    "# Calculate Misclassification Rate\n",
    "misclassification_rate = min_misclassification / len(df)\n",
    "print(f\"Misclassification Rate: {misclassification_rate:.4f}\")\n",
    "\n",
    "# Generate the Confusion Matrix\n",
    "y_true = df['Author Labeling Binary']\n",
    "y_pred = df['Predicted Label']\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['irrelevant', 'relevant']).plot()\n",
    "\n",
    "# Save the results\n",
    "#df.to_csv(\"classified_stance_results.csv\", index=False)\n",
    "\n",
    "# Display a sample of the classified DataFrame\n",
    "print(df[['tweet_text', 'max_bge_ranker_score_llm_new_val', 'Author Labeling', 'Final Classification']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1937eb2-4ab8-422c-b038-09d63cdd8646",
   "metadata": {},
   "source": [
    "# Stella Model-1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98835c8a-3342-4aba-a5e3-29326c45abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMERS_CACHE set to: ./\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"./\"\n",
    "\n",
    "import os\n",
    "from transformers.utils import logging\n",
    "\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./\"\n",
    "logging.set_verbosity_info()\n",
    "\n",
    "print(f\"TRANSFORMERS_CACHE set to: {os.environ['TRANSFORMERS_CACHE']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Stella model\n",
    "import os\n",
    "#os.environ[\"TRANSFORMERS_CACHE\"] = \"./\"\n",
    "os.environ['HF_HOME'] = \"./\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Change cache location\n",
    "model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True).cuda()\n",
    "\n",
    "# Queries and documents\n",
    "query_prompt_name = \"s2s_query\"  # Sentence-to-passage query (not used directly in this example)\n",
    "queries = [\n",
    "    \"What are some ways to reduce stress?\",\n",
    "    \"What are the benefits of drinking green tea?\",\n",
    "]\n",
    "\n",
    "# Documents (passage texts)\n",
    "docs = [\n",
    "    \"There are many effective ways to reduce stress. Some common techniques include deep breathing, meditation, and physical activity. Engaging in hobbies, spending time in nature, and connecting with loved ones can also help alleviate stress. Additionally, setting boundaries, practicing self-care, and learning to say no can prevent stress from building up.\",\n",
    "    \"Green tea has been consumed for centuries and is known for its potential health benefits. It contains antioxidants that may help protect the body against damage caused by free radicals. Regular consumption of green tea has been associated with improved heart health, enhanced cognitive function, and a reduced risk of certain types of cancer. The polyphenols in green tea may also have anti-inflammatory and weight loss properties.\",\n",
    "]\n",
    "\n",
    "# Encode the queries and documents\n",
    "query_embeddings = model.encode(queries, convert_to_tensor=True, normalize_embeddings=True)\n",
    "doc_embeddings = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "# Calculate cosine similarity between queries and documents\n",
    "scores = util.cos_sim(query_embeddings, doc_embeddings)\n",
    "\n",
    "# Print the results\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"Query: {query}\")\n",
    "    for j, doc in enumerate(docs):\n",
    "        print(f\" - Document {j + 1}: Score: {scores[i][j].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78685a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_prompt_name = \"s2p_query\"  # Sentence-to-passage query\n",
    "queries = [ \"The sudden jump in Joe Biden's votes in Michigan was due to a temporary data glitch, not fraud.\",\n",
    "\"There is a map or graph that alleges Biden found 138,000+ votes overnight to overtake Trump in Michigan, and it's evidence of an election being stolen\",\n",
    "\"Joe Biden did not mysteriously gain 138,000 Michigan votes all at once\"\n",
    "]\n",
    "\n",
    "# Documents (no prompts needed for docs)\n",
    "docs = [\n",
    "       \"2. Voter Fraud lawsuits - @DonaldJTrumpJr Team will be laser-focus on these: &gt;Limestone County already had 1 arrest &gt;PA has a UPS worker agreeing to testify in court that the supervisors were backdating &gt;Glitch in Michigan &gt;Pennsylvania/Georgia not allowing Republican observers\",\n",
    "\n",
    "]\n",
    "\n",
    "# Encode the queries and documents\n",
    "query_embeddings = model.encode(queries, convert_to_tensor=True, prompt_name=query_prompt_name, normalize_embeddings=True)\n",
    "doc_embeddings = model.encode(docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "# Calculate cosine similarity between queries and documents\n",
    "scores = util.cos_sim(query_embeddings, doc_embeddings)\n",
    "print(scores)\n",
    "mean_score = scores.mean().item()\n",
    "print(f\"Mean Cosine Similarity: {mean_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713592a6-cd47-4886-ba65-062259c9ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    image_path  \\\n",
      "0    CLIP-Dataset/Image Annotation/story_2.jpg   \n",
      "1  CLIP-Dataset/Image Annotation/story_648.jpg   \n",
      "2   CLIP-Dataset/Image Annotation/story_28.jpg   \n",
      "3    CLIP-Dataset/Image Annotation/story_2.jpg   \n",
      "4  CLIP-Dataset/Image Annotation/story_648.jpg   \n",
      "\n",
      "                                                text     label  \\\n",
      "0  See how Demos add fake voters in WI and MI. ??...  refuting   \n",
      "1  See how Demos add fake voters in WI and MI. ??...  refuting   \n",
      "2  See how Demos add fake voters in WI and MI. ??...  refuting   \n",
      "3  For Biden, it is considered that at the moment...  refuting   \n",
      "4  For Biden, it is considered that at the moment...  refuting   \n",
      "\n",
      "   stance_llama_vision  qwen_model  internvl2_model  \\\n",
      "0                    1           0                0   \n",
      "1                    1           0                1   \n",
      "2                    1           0                0   \n",
      "3                    0           0                1   \n",
      "4                    0           0                1   \n",
      "\n",
      "                                 image_exp_internvl2  score_stella_relevancy  \n",
      "0  The image shows a graph depicting the accumula...                  0.6202  \n",
      "1  The image depicts a graph showing the accumula...                  0.5915  \n",
      "2  The image features the word \"FRAUD\" in bold bl...                  0.2500  \n",
      "3  The image shows a graph depicting the accumula...                  0.6384  \n",
      "4  The image depicts a graph showing the accumula...                  0.6272  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Assuming 'model' is already loaded\n",
    "# model = SentenceTransformer(\"dunzhang/stella_en_400M_v5\", trust_remote_code=True)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute scores for a given query type\n",
    "def compute_scores(df, query_col, score_col_name):\n",
    "    # Group rows by the query column (e.g., 'fact') and collect corresponding tweets\n",
    "    grouped = df.groupby(query_col)['text'].apply(list).reset_index()\n",
    "    grouped.columns = [query_col, 'documents']\n",
    "\n",
    "    # Prepare a list to store the results\n",
    "    results_list = []\n",
    "    query_prompt_name = \"s2p_query\"  # Sentence-to-passage query\n",
    "\n",
    "    # Iterate over each query and its associated documents\n",
    "    for _, row in grouped.iterrows():\n",
    "        query = row[query_col]  # Query (e.g., fact, supporting, or refuting)\n",
    "        documents = row['documents']  # List of tweets\n",
    "\n",
    "        # Encode the query and documents\n",
    "        query_embeddings = model.encode(query, convert_to_tensor=True, prompt_name=query_prompt_name, normalize_embeddings=True)\n",
    "        doc_embeddings = model.encode(documents, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "        # Calculate cosine similarity between the query and documents\n",
    "        scores = util.cos_sim(query_embeddings, doc_embeddings)\n",
    "\n",
    "        # Map the scores back to the original DataFrame rows\n",
    "        for idx, score in enumerate(scores[0]):  # Loop through document scores\n",
    "            results_list.append({\n",
    "                query_col: query,\n",
    "                'text': documents[idx],  # Corresponding tweet\n",
    "                score_col_name: round(score.item(), 4)  # Convert tensor to Python float\n",
    "            })\n",
    "\n",
    "    # Convert results into a DataFrame\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "# Compute scores for 'fact', 'supporting', and 'refuting'\n",
    "final_df = compute_scores(df, 'image_exp_internvl2', 'score_stella_relevancy')\n",
    "#results_df_supporting = compute_scores(df, 'supporting', 'score_stella_supporting')\n",
    "#results_df_refuting = compute_scores(df, 'refuting', 'score_stella_refuting')\n",
    "\n",
    "# Merge the results DataFrames on 'tweet_text'\n",
    "#merged_df = pd.merge(results_df_fact, results_df_supporting, on=\"tweet_text\", how=\"outer\")\n",
    "#merged_df = pd.merge(merged_df, results_df_refuting, on=\"tweet_text\", how=\"outer\")\n",
    "\n",
    "# Take the minimum score across all score columns\n",
    "#merged_df[\"min_score_stella\"] = merged_df[\n",
    "#    [\"score_stella_fact\", \"score_stella_supporting\", \"score_stella_refuting\"]\n",
    "#].mean(axis=1)\n",
    "\n",
    "# Create a new DataFrame with only the necessary columns\n",
    "#results_df_min = merged_df[[\"tweet_text\", \"min_score_stella\"]]\n",
    "\n",
    "\n",
    "# Merge the original DataFrame with the scores DataFrame on 'tweet_text'\n",
    "final_df = pd.merge(df, final_df, on=['text','image_exp_internvl2'], how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "final_df.to_csv(\"updated_file2.csv\", index=False)\n",
    "\n",
    "# Print a sample of the updated DataFrame\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca713e",
   "metadata": {},
   "source": [
    "# Stella Model-400M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723da7a-1fea-4319-a9b5-96a864db9108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Assuming 'model' is already loaded\n",
    "model = SentenceTransformer(\n",
    "    \"dunzhang/stella_en_400M_v5\",\n",
    "    trust_remote_code=True)\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute scores for a given query type\n",
    "def compute_scores(df, query_col, score_col_name):\n",
    "    # Group rows by the query column (e.g., 'fact') and collect corresponding tweets\n",
    "    grouped = df.groupby(query_col)['tweet_text'].apply(list).reset_index()\n",
    "    grouped.columns = [query_col, 'documents']\n",
    "\n",
    "    # Prepare a list to store the results\n",
    "    results_list = []\n",
    "    query_prompt_name = \"s2p_query\"  # Sentence-to-passage query\n",
    "\n",
    "    # Iterate over each query and its associated documents\n",
    "    for _, row in grouped.iterrows():\n",
    "        query = row[query_col]  # Query (e.g., fact, supporting, or refuting)\n",
    "        documents = row['documents']  # List of tweets\n",
    "\n",
    "        # Encode the query and documents\n",
    "        query_embeddings = model.encode(query, convert_to_tensor=True, prompt_name=query_prompt_name, normalize_embeddings=True)\n",
    "        doc_embeddings = model.encode(documents, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "        # Calculate cosine similarity between the query and documents\n",
    "        scores = util.cos_sim(query_embeddings, doc_embeddings)\n",
    "\n",
    "        # Map the scores back to the original DataFrame rows\n",
    "        for idx, score in enumerate(scores[0]):  # Loop through document scores\n",
    "            results_list.append({\n",
    "                query_col: query,\n",
    "                'tweet_text': documents[idx],  # Corresponding tweet\n",
    "                score_col_name: round(score.item(), 4)  # Convert tensor to Python float\n",
    "            })\n",
    "\n",
    "    # Convert results into a DataFrame\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "# Compute scores for 'fact', 'supporting', and 'refuting'\n",
    "results_df_fact = compute_scores(df, 'fact', 'score_stella_fact')\n",
    "results_df_supporting = compute_scores(df, 'supporting', 'score_stella_supporting')\n",
    "results_df_refuting = compute_scores(df, 'refuting', 'score_stella_refuting')\n",
    "\n",
    "# Merge the results DataFrames on 'tweet_text'\n",
    "merged_df = pd.merge(results_df_fact, results_df_supporting, on=\"tweet_text\", how=\"outer\")\n",
    "merged_df = pd.merge(merged_df, results_df_refuting, on=\"tweet_text\", how=\"outer\")\n",
    "\n",
    "# Take the minimum score across all score columns\n",
    "merged_df[\"max_score_stella\"] = merged_df[\n",
    "    [\"score_stella_fact\", \"score_stella_supporting\", \"score_stella_refuting\"]\n",
    "].max(axis=1)\n",
    "\n",
    "# Create a new DataFrame with only the necessary columns\n",
    "results_df_max = merged_df[[\"tweet_text\", \"max_score_stella\"]]\n",
    "\n",
    "# Merge the original DataFrame with the scores DataFrame on 'tweet_text'\n",
    "final_df = pd.merge(df, results_df_max, on='tweet_text', how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "final_df.to_csv(\"updated_stance_results_with_stella_scores_max.csv\", index=False)\n",
    "\n",
    "# Print a sample of the updated DataFrame\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57e378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text  \\\n",
      "0  I'm not sure voter malpractice occurred, but a...   \n",
      "1  Although I believe trump will lose the electio...   \n",
      "2  Michigan - Biden votes came out of nowhere fro...   \n",
      "3  See how Demos add fake voters in WI and MI. ??...   \n",
      "4  For Biden, it is considered that at the moment...   \n",
      "\n",
      "  is tweet-image pair relevant? Author Labeling Author Labeling 2  \\\n",
      "0                           NaN             NaN               NaN   \n",
      "1                           NaN             NaN               NaN   \n",
      "2                           NaN             NaN               NaN   \n",
      "3                      positive        refuting          refuting   \n",
      "4                      positive        refuting          refuting   \n",
      "\n",
      "  Author Labeling 3         storyid  \\\n",
      "0               NaN  story_2+648+28   \n",
      "1               NaN  story_2+648+28   \n",
      "2               NaN  story_2+648+28   \n",
      "3          refuting  story_2+648+28   \n",
      "4          refuting  story_2+648+28   \n",
      "\n",
      "                                          supporting  \\\n",
      "0  The vote spike for Biden in these charts was d...   \n",
      "1  The vote spike for Biden in these charts was d...   \n",
      "2  The vote spike for Biden in these charts was d...   \n",
      "3  The vote spike for Biden in these charts was d...   \n",
      "4  The vote spike for Biden in these charts was d...   \n",
      "\n",
      "                                            refuting  \\\n",
      "0  Early morning election results with sudden spi...   \n",
      "1  Early morning election results with sudden spi...   \n",
      "2  Early morning election results with sudden spi...   \n",
      "3  Early morning election results with sudden spi...   \n",
      "4  Early morning election results with sudden spi...   \n",
      "\n",
      "                                                fact   max_score  ...  \\\n",
      "0  Some graphs online misrepresent normal vote-co...  6864430791  ...   \n",
      "1  Some graphs online misrepresent normal vote-co...  6496571467  ...   \n",
      "2  Some graphs online misrepresent normal vote-co...  5463319356  ...   \n",
      "3  Some graphs online misrepresent normal vote-co...  6654402574  ...   \n",
      "4  Some graphs online misrepresent normal vote-co...  7175901637  ...   \n",
      "\n",
      "  score_stella_1.5b_p max_score_mixedbread max_score_mixedbread_new_val  \\\n",
      "0              0.6311               0.0190                       0.0086   \n",
      "1              0.5095               0.1060                       0.0069   \n",
      "2              0.5677               0.1461                       0.0121   \n",
      "3              0.6168               0.0266                       0.0078   \n",
      "4              0.5832               0.0221                       0.0068   \n",
      "\n",
      "  max_bge_ranker_score_new_val max_bge_ranker_score_llm_new_val  \\\n",
      "0                    -1.425781                         5.457031   \n",
      "1                    -2.605469                         6.441406   \n",
      "2                    -2.156250                         7.644531   \n",
      "3                    -0.304688                         7.953125   \n",
      "4                    -1.161133                         6.585938   \n",
      "\n",
      "  max_score_stella_new_val colbert_max_score_new_val  Author Labeling Binary  \\\n",
      "0                 0.645300                       NaN                     NaN   \n",
      "1                 0.582900                       NaN                     NaN   \n",
      "2                 0.624267                       NaN                     NaN   \n",
      "3                 0.648167                 17.015625                     1.0   \n",
      "4                 0.649333                 19.140625                     1.0   \n",
      "\n",
      "   Stella Predicted Label  min_score_stella  \n",
      "0                       1          0.645300  \n",
      "1                       1          0.582900  \n",
      "2                       1          0.624267  \n",
      "3                       1          0.648167  \n",
      "4                       1          0.649333  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Assuming 'model' is already loaded\n",
    "# model = SentenceTransformer(\"dunzhang/stella_en_400M_v5\", trust_remote_code=True)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Function to compute scores for a given query type\n",
    "def compute_scores(df, query_col, score_col_name):\n",
    "    # Group rows by the query column (e.g., 'fact') and collect corresponding tweets\n",
    "    grouped = df.groupby(query_col)['tweet_text'].apply(list).reset_index()\n",
    "    grouped.columns = [query_col, 'documents']\n",
    "\n",
    "    # Prepare a list to store the results\n",
    "    results_list = []\n",
    "    query_prompt_name = \"s2p_query\"  # Sentence-to-passage query\n",
    "\n",
    "    # Iterate over each query and its associated documents\n",
    "    for _, row in grouped.iterrows():\n",
    "        query = row[query_col]  # Query (e.g., fact, supporting, or refuting)\n",
    "        documents = row['documents']  # List of tweets\n",
    "\n",
    "        # Encode the query and documents\n",
    "        query_embeddings = model.encode(query, convert_to_tensor=True, prompt_name=query_prompt_name, normalize_embeddings=True)\n",
    "        doc_embeddings = model.encode(documents, convert_to_tensor=True, normalize_embeddings=True)\n",
    "\n",
    "        # Calculate cosine similarity between the query and documents\n",
    "        scores = util.cos_sim(query_embeddings, doc_embeddings)\n",
    "\n",
    "        # Map the scores back to the original DataFrame rows\n",
    "        for idx, score in enumerate(scores[0]):  # Loop through document scores\n",
    "            results_list.append({\n",
    "                query_col: query,\n",
    "                'tweet_text': documents[idx],  # Corresponding tweet\n",
    "                score_col_name: round(score.item(), 4)  # Convert tensor to Python float\n",
    "            })\n",
    "\n",
    "    # Convert results into a DataFrame\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "# Compute scores for 'fact', 'supporting', and 'refuting'\n",
    "results_df_fact = compute_scores(df, 'fact', 'score_stella_fact')\n",
    "results_df_supporting = compute_scores(df, 'supporting', 'score_stella_supporting')\n",
    "results_df_refuting = compute_scores(df, 'refuting', 'score_stella_refuting')\n",
    "\n",
    "# Merge the results DataFrames on 'tweet_text'\n",
    "merged_df = pd.merge(results_df_fact, results_df_supporting, on=\"tweet_text\", how=\"outer\")\n",
    "merged_df = pd.merge(merged_df, results_df_refuting, on=\"tweet_text\", how=\"outer\")\n",
    "\n",
    "# Take the minimum score across all score columns\n",
    "merged_df[\"min_score_stella\"] = merged_df[\n",
    "    [\"score_stella_fact\", \"score_stella_supporting\", \"score_stella_refuting\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "# Create a new DataFrame with only the necessary columns\n",
    "results_df_min = merged_df[[\"tweet_text\", \"min_score_stella\"]]\n",
    "\n",
    "\n",
    "# Merge the original DataFrame with the scores DataFrame on 'tweet_text'\n",
    "final_df = pd.merge(df, results_df_min, on='tweet_text', how='left')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "final_df.to_csv(\"updated_stance_results_with_stella_scores_min.csv\", index=False)\n",
    "\n",
    "# Print a sample of the updated DataFrame\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4e5513e-6c03-47ea-be12-d6bd145d23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"updated_stance_results_with_stella_scores_p.csv\")\n",
    "df.rename(columns={\"score_stella_y\": \"score_stella_p\"}, inplace=True)\n",
    "df.rename(columns={\"score_stella_x\": \"score_stella_s\"}, inplace=True)\n",
    "df.to_csv(\"updated_stance_results_with_stella_scores_sp.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc69f678-8f25-4d06-9074-7f87f5f609b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"last_dataset_with_colbert_scores_4.csv\")\n",
    "optimal_threshold =  0.5237686543532102\n",
    "df['Stella Predicted Label'] = (df['max_score_stella_new_val'] >= optimal_threshold).astype(int)\n",
    "df.to_csv(\"last_dataset_with_colbert_scores_4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dc9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold | Precision | Recall | Accuracy | F1-score\n",
      "--------------------------------------------------\n",
      "\n",
      "Best Threshold Found:\n",
      "Optimal Threshold: 0.99951\n",
      "Best Precision: 0.6358\n",
      "Best Recall: 1.0000\n",
      "Best Accuracy: 0.6358\n",
      "Best F1-score: 0.7774\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0  63]\n",
      " [  0 110]]\n",
      "\n",
      "Sample of Classified Data:\n",
      "    max_similarity_score_llama_2  Author Labeling Binary  Predicted Label  \\\n",
      "3                            1.0                     1.0                1   \n",
      "4                            1.0                     1.0                1   \n",
      "6                            1.0                     1.0                1   \n",
      "13                           1.0                     1.0                1   \n",
      "17                           1.0                     1.0                1   \n",
      "\n",
      "   Final Classification  \n",
      "3              relevant  \n",
      "4              relevant  \n",
      "6              relevant  \n",
      "13             relevant  \n",
      "17             relevant  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_recall_fscore_support, accuracy_score, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"ann_dataset_misleading.csv\")\n",
    "\n",
    "# Map labels to binary classes\n",
    "df['Author Labeling Binary'] = df['Final Labeling'].map({\n",
    "    'irrelevant': 0,\n",
    "    'refuting': 1,\n",
    "    'supporting': 1\n",
    "})\n",
    "\n",
    "# Remove NaN values in relevant columns\n",
    "df = df.dropna(subset=['max_similarity_score_llama_2', 'Author Labeling Binary'])\n",
    "\n",
    "# Sweep through thresholds to find the best one based on F1-score\n",
    "thresholds = np.linspace(df['max_similarity_score_llama_2'].min(), df['max_similarity_score_llama_2'].max(), 500)\n",
    "best_threshold = None\n",
    "best_f1 = -1  # Initialize with a low F1-score\n",
    "best_metrics = {}\n",
    "best_accuracy = -1  # Initialize with a low F1-score\n",
    "\n",
    "print(\"Threshold | Precision | Recall | Accuracy | F1-score\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Predict labels based on the threshold\n",
    "    df['Predicted Label'] = (df['max_similarity_score_llama_2'] >= threshold).astype(int)\n",
    "\n",
    "    # Compute precision, recall, F1-score, and accuracy\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        df['Author Labeling Binary'], df['Predicted Label'], average='binary'\n",
    "    )\n",
    "    accuracy = accuracy_score(df['Author Labeling Binary'], df['Predicted Label'])\n",
    "\n",
    "    # Print the metrics for each threshold\n",
    "   # print(f\"{threshold:.5f} | {precision:.4f} | {recall:.4f} | {accuracy:.4f} | {f1:.4f}\")\n",
    "\n",
    "    # Update best threshold if F1-score is improved\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_metrics = {\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1-score\": f1\n",
    "        }\n",
    "\n",
    "# Apply the best threshold for final classification\n",
    "df['Predicted Label'] = (df['max_similarity_score_llama_2'] >= best_threshold).astype(int)\n",
    "df['Final Classification'] = df['Predicted Label'].map({0: 'irrelevant', 1: 'relevant'})\n",
    "\n",
    "# Print the best threshold and its metrics\n",
    "print(\"\\nBest Threshold Found:\")\n",
    "print(f\"Optimal Threshold: {best_threshold:.5f}\")\n",
    "print(f\"Best Precision: {best_metrics['Precision']:.4f}\")\n",
    "print(f\"Best Recall: {best_metrics['Recall']:.4f}\")\n",
    "print(f\"Best Accuracy: {best_metrics['Accuracy']:.4f}\")\n",
    "print(f\"Best F1-score: {best_metrics['F1-score']:.4f}\")\n",
    "\n",
    "# Generate and print the Confusion Matrix\n",
    "y_true = df['Author Labeling Binary']\n",
    "y_pred = df['Predicted Label']\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['irrelevant', 'relevant']).plot()\n",
    "\n",
    "# Save the results\n",
    "#df.to_csv(\"classified_stance_results_temp_2.csv\", index=False)\n",
    "\n",
    "# Display a sample of the classified DataFrame\n",
    "print(\"\\nSample of Classified Data:\")\n",
    "print(df[['max_similarity_score_llama_2', 'Author Labeling Binary', 'Predicted Label', 'Final Classification']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5851c0cf",
   "metadata": {},
   "source": [
    "# Colbertv2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdeef6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('ann_dataset_misleading.csv')\n",
    "\n",
    "# Limit to the first 242 rows\n",
    "subset_df = df.iloc[:242]\n",
    "\n",
    "# Save tweets to collection.tsv\n",
    "with open('collection.tsv', 'w') as f:\n",
    "    for idx, tweet in enumerate(subset_df['tweet_text']):\n",
    "        f.write(f\"{idx}\\t{tweet}\\n\")\n",
    "\n",
    "# Save facts to queries.tsv\n",
    "with open('queries.tsv', 'w') as f:\n",
    "    for idx, query in enumerate(subset_df['fact']):\n",
    "        f.write(f\"{idx}\\t{query}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert import ColBERT\n",
    "\n",
    "from colbert.indexing import Indexer\n",
    "\n",
    "# Load the pre-trained ColBERT model\n",
    "colbert = ColBERT.from_pretrained('colbert-ir/colbertv2.0')\n",
    "\n",
    "# Index the collection\n",
    "indexer = Indexer(colbert, collection_path='collection.tsv', index_path='index/')\n",
    "indexer.index()\n",
    "\n",
    "from colbert.search import Searcher\n",
    "\n",
    "# Initialize the searcher\n",
    "searcher = Searcher(index_path='index/', colbert=colbert)\n",
    "\n",
    "# Query the indexed data\n",
    "queries = pd.read_csv('queries.tsv', sep='\\t', header=None, names=['id', 'query'])\n",
    "for _, row in queries.iterrows():\n",
    "    query_id, query_text = row['id'], row['query']\n",
    "    results = searcher.search(query_text, k=len(unique_queries))\n",
    "    print(f\"Query: {query_text}\")\n",
    "    for passage_id, score in results:\n",
    "        print(f\"  Tweet ID: {passage_id}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff56e76-8e1e-4ad0-ac3d-de90e086c3fe",
   "metadata": {},
   "source": [
    "# Measure of agreement between two dependent categorical samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f0217-c459-4d53-bee9-2712a3af00cf",
   "metadata": {},
   "source": [
    "## Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff759a5-36bb-4d15-a084-f9f1a5a9acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "0      2\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "168    0\n",
      "169    0\n",
      "170    2\n",
      "171    2\n",
      "172    0\n",
      "Name: Annotator 2, Length: 173, dtype: int64\n",
      "173\n",
      "Cohen's kappa score: 0.8459\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"baselines_for_part_a_dataset.json\")\n",
    "\n",
    "df = df[df['Author Labeling 3'].notna() & (df['Author Labeling'] != '')]\n",
    "print(len(df))\n",
    "# Ensure the two annotator columns are present\n",
    "if 'Author Labeling' not in df.columns or 'Author Labeling 3' not in df.columns:\n",
    "    raise ValueError(\"The columns 'Author Labeling' and 'Author Labeling 1' must be present in the dataset.\")\n",
    "# Drop rows where either annotator has missing labels\n",
    "df = df.dropna(subset=['Author Labeling', 'Author Labeling 3'])\n",
    "\n",
    "# Map the labels to numeric values if they are categorical\n",
    "# Example mapping: {'irrelevant': 0, 'supporting': 1, 'refuting': 2}\n",
    "label_mapping = {'irrelevant': 0, 'supporting': 1, 'refuting': 2}\n",
    "df['Annotator 1'] = df['Author Labeling'].map(label_mapping)\n",
    "df['Annotator 2'] = df['Author Labeling 3'].map(label_mapping)\n",
    "print(df['Annotator 2'])\n",
    "df = df.dropna(subset=['Annotator 1', 'Annotator 2'])\n",
    "print(len(df))\n",
    "# Calculate Cohen's kappa score\n",
    "kappa_score = cohen_kappa_score(df['Annotator 1'], df['Annotator 2'])\n",
    "\n",
    "# Print the result\n",
    "print(f\"Cohen's kappa score: {kappa_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8d8293-4fba-4e4e-bf01-925c24ffadcf",
   "metadata": {},
   "source": [
    "# QWEN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c3b8c-1315-40c9-b3f3-4ddae0161fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Assuming you want to use the second GPU (index 1)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\", cache_dir = './', token = hf_token\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", use_fast =True ,cache_dir = './', token =hf_token)\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384.\n",
    "# You can set min_pixels and max_pixels according to your needs, such as a token range of 256-1280, to balance performance and cost.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-72B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)\n",
    "\n",
    "# Prepare the input prompt\n",
    "def prepare_prompt(row):\n",
    "    return f\"\"\"\n",
    "      You will be provided with a tweet text and the image. Indicate if the tweet text is relevant or irrelevant to the given image. \n",
    "        Only respond with one of the following words: [relevant, irrelevant]. Do not provide any explanations or additional information.\n",
    "        Tweet Text: {row['text']}\"\"\"\n",
    "# Generate stance for each row\n",
    "def get_stance(row):\n",
    "    print(f\"Processing index: {row.name}\")  # Print the index of the current row\n",
    "    input_text = prepare_prompt(row)\n",
    "    image_path = row[\"image_path\"]\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": input_text}\n",
    "    ]}\n",
    "    ]\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": input_text},\n",
    "        ],\n",
    "    }\n",
    "    ]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    print(output_text)\n",
    "\n",
    "    return output_text\n",
    "csv_path = \"ann_dataset_misleading.csv\"  # Replace with your CSV file path\n",
    "image_folder = \"CLIP-Dataset/Image Annotation/\"  # Image folder path\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "# Apply stance generation function to the entire DataFrame\n",
    "df[\"stance_qwen_model\"] = df.apply(get_stance, axis=1)\n",
    "\n",
    "# Save the entire DataFrame to one CSV\n",
    "#df.to_csv(\"final_results_pipeline_2.csv\", index=False)\n",
    "print(\"All results saved to final_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7fae2-40d0-49ae-9063-059bae1d4eda",
   "metadata": {},
   "source": [
    "# InternVL2_5-38B-MPO for OOC and Benign Images Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5f551-ac92-4c77-9b1e-f4bcf7e24d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "path = \"OpenGVLab/InternVL2_5-38B-MPO\"\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "def split_model(model_name):\n",
    "    device_map = {}\n",
    "    world_size = torch.cuda.device_count()\n",
    "    num_layers = {\n",
    "        'InternVL2_5-1B': 24, 'InternVL2_5-2B': 24, 'InternVL2_5-4B': 36, 'InternVL2_5-8B': 32,\n",
    "        'InternVL2_5-26B': 48, 'InternVL2_5-38B': 64, 'InternVL2_5-78B': 80}[model_name]\n",
    "    # Since the first GPU will be used for ViT, treat it as half a GPU.\n",
    "    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "    layer_cnt = 0\n",
    "    for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "        for j in range(num_layer):\n",
    "            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "            layer_cnt += 1\n",
    "    device_map['vision_model'] = 0\n",
    "    device_map['mlp1'] = 0\n",
    "    device_map['language_model.model.tok_embeddings'] = 0\n",
    "    device_map['language_model.model.embed_tokens'] = 0\n",
    "    device_map['language_model.output'] = 0\n",
    "    device_map['language_model.model.norm'] = 0\n",
    "    device_map['language_model.model.rotary_emb'] = 0\n",
    "    device_map['language_model.lm_head'] = 0\n",
    "    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "\n",
    "    return device_map\n",
    "\n",
    "# If you set `load_in_8bit=True`, you will need one 80GB GPUs.\n",
    "# If you set `load_in_8bit=False`, you will need at least two 80GB GPUs.\n",
    "path = 'OpenGVLab/InternVL2_5-38B-MPO'\n",
    "device_map = split_model('InternVL2_5-38B')\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    load_in_8bit=False,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True,\n",
    "    cache_dir = './venvs/',\n",
    "    device_map=device_map).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, cache_dir= './venvs/', trust_remote_code=True, use_fast=False)\n",
    "'''\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "def split_model(model_name):\n",
    "    device_map = {}\n",
    "    world_size = torch.cuda.device_count()\n",
    "    num_layers = {\n",
    "        'InternVL2_5-1B': 24, 'InternVL2_5-2B': 24, 'InternVL2_5-4B': 36, 'InternVL2_5-8B': 32,\n",
    "        'InternVL2_5-26B': 48, 'InternVL2_5-38B': 64, 'InternVL2_5-78B': 80}[model_name]\n",
    "    # Since the first GPU will be used for ViT, treat it as half a GPU.\n",
    "    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "    layer_cnt = 0\n",
    "    for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "        for j in range(num_layer):\n",
    "            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "            layer_cnt += 1\n",
    "    device_map['vision_model'] = 0\n",
    "    device_map['mlp1'] = 0\n",
    "    device_map['language_model.model.tok_embeddings'] = 0\n",
    "    device_map['language_model.model.embed_tokens'] = 0\n",
    "    device_map['language_model.output'] = 0\n",
    "    device_map['language_model.model.norm'] = 0\n",
    "    device_map['language_model.model.rotary_emb'] = 0\n",
    "    device_map['language_model.lm_head'] = 0\n",
    "    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "\n",
    "    return device_map\n",
    "\n",
    "# If you set `load_in_8bit=True`, you will need two 80GB GPUs.\n",
    "# If you set `load_in_8bit=False`, you will need at least three 80GB GPUs.\n",
    "path = 'OpenGVLab/InternVL2_5-78B-MPO'\n",
    "device_map = split_model('InternVL2_5-78B')\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    load_in_8bit=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_flash_attn=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=device_map,\n",
    "    cache_dir = './venvs/').eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False, cache_dir='./venvs/')\n",
    "\n",
    "\n",
    "# Prepare the input prompt\n",
    "def prepare_prompt(row):\n",
    "    return f\"\"\"\n",
    "      You will be provided a tweet and the explanation of tweets image pair. Indicate if the tweet text is relevant or irrelevant to the given image explanation.\n",
    "      If the tweet text doesnt have any explanation about the image or the text is slightly relevant to the image, please classify it as irrelevant.\n",
    "      Only respond with one of the following words: [relevant, irrelevant]. Do not provide any explanations or additional information.\n",
    "    Tweet Text: {row['text']}\n",
    "    Image Explanation: {row['image_exp_internvl2']}\"\"\"\n",
    "# Generate stance for each row\n",
    "def get_stance(row):\n",
    "    print(f\"Processing index: {row.name}\")  # Print the index of the current row\n",
    "    input_text = prepare_prompt(row)\n",
    "    image_path = row[\"image_path\"]\n",
    "    # set the max number of tiles in `max_num`\n",
    "    pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "    generation_config = dict(max_new_tokens=1024, do_sample=False)\n",
    "    \n",
    "    \n",
    "    # pure-text conversation (纯文本对话)\n",
    "    question = 'Hello, who are you?'\n",
    "    response, history = model.chat(tokenizer, None, question, generation_config, history=None, return_history=True)\n",
    "    print(f'User: {question}\\nAssistant: {response}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # single-image single-round conversation (单图单轮对话)\n",
    "    question = f'<image>\\n{input_text}'\n",
    "    #question = f'{input_text}'\n",
    "\n",
    "    response = model.chat(tokenizer, pixel_values,  question, generation_config)\n",
    "    print(f'User: {question}\\nAssistant:{response}')\n",
    "\n",
    "    return response\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "\n",
    "# single-image multi-round conversation (单图多轮对话)\n",
    "question = '<image>\\nPlease describe the image in detail.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config, history=None, return_history=True)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "question = 'Please write a poem according to the image.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config, history=history, return_history=True)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "'''\n",
    "'''\n",
    "# multi-image multi-round conversation, combined images (多图多轮对话，拼接图像)\n",
    "pixel_values1 = load_image('./examples/image1.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "pixel_values2 = load_image('./examples/image2.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "pixel_values = torch.cat((pixel_values1, pixel_values2), dim=0)\n",
    "\n",
    "question = '<image>\\nDescribe the two images in detail.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config,\n",
    "                               history=None, return_history=True)\n",
    "print(f'User: {queston}\\nAssistant: {response}')\n",
    "\n",
    "question = 'What are the similarities and differences between these two images.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config,\n",
    "                               history=history, return_history=True)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "# multi-image multi-round conversation, separate images (多图多轮对话，独立图像)\n",
    "pixel_values1 = load_image('./examples/image1.jpg', max_num=12).to(torch.bfloat16).cuda()\n",
    "pixel_values2 = load_image('./examples/image2.jpg', max_num=12).\n",
    "to(torch.bfloat16).cuda()\n",
    "pixel_values = torch.cat((pixel_values1, pixel_values2), dim=0)\n",
    "num_patches_list = [pixel_values1.size(0), pixel_values2.size(0)]\n",
    "\n",
    "question = 'Image-1: <image>\\nImage-2: <image>\\nDescribe the two images in detail.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config,\n",
    "                               num_patches_list=num_patches_list,\n",
    "                               history=None, return_history=True)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "question = 'What are the similarities and differences between these two images.'\n",
    "response, history = model.chat(tokenizer, pixel_values, question, generation_config,\n",
    "                               num_patches_list=num_patches_list,\n",
    "                               history=history, return_history=True)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5749185-f775-43f5-99e6-b383cdcdb111",
   "metadata": {},
   "source": [
    "# Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de998c-3d99-4cd5-a3c1-307a1fb71ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### import csv\n",
    "import os\n",
    "import json\n",
    "from google.cloud import vision\n",
    "import imagehash \n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import logging\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "def are_images_similar(local_path, content_url, hash_type='phash', threshold=5):\n",
    "    try:\n",
    "        local_img = Image.open(local_path).convert(\"RGB\")\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0\"\n",
    "        }\n",
    "        response = requests.get(content_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        imgur_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "        hash_func = getattr(imagehash, hash_type)\n",
    "        hash_local = hash_func(local_img)\n",
    "        hash_imgur = hash_func(imgur_img)\n",
    "\n",
    "        difference = hash_local - hash_imgur\n",
    "        return difference <= threshold, difference\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"⚠️ HTTPError for URL: {content_url} → {e}\")\n",
    "        return False, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error comparing images: {e}\")\n",
    "\n",
    "        return False, None\n",
    "\n",
    "question = \"\"\"<image>\n",
    "### Context\n",
    "You are provided with:\n",
    "- An image\n",
    "- A tweet written by a user\n",
    "\n",
    "Your task is to analyze how the tweet text relates to the image and determine the type of relationship or miscaptioning it might represent.\n",
    "\n",
    "### Definitions\n",
    "\n",
    "1. **Narrative-Based Miscaptioning**:  \n",
    "   The image supports the topic of the tweet, but the **text exaggerates or extends the meaning** by adding claims or context not evident from the image itself. These are often unverifiable, interpretive, or political.\n",
    "\n",
    "2. **Evidence-Based Miscaptioning**:  \n",
    "   The tweet **describes the image incorrectly**, such as misstating the **location, time, people, or objects**. The image is reused out of its original context, and this **factual mismatch can be verified**.\n",
    "\n",
    "3. **None of them**:  \n",
    "   The tweet **accurately refers to the image**, supports or comments on it **without changing its meaning**, and does **not introduce any false or unverifiable information**.\n",
    "\n",
    "4. **Asymmetric**:  \n",
    "   The tweet and image are **not meaningfully related**. The image does **not support or contradict the claim** in the text. Their contributions are disconnected, and no direct relationship can be drawn.\n",
    "\n",
    "### Decision Process\n",
    "\n",
    "- First, ask: **Does the image support or illustrate the tweet text?**\n",
    "  - If **Yes**, consider:  \n",
    "    - Is it adding unverifiable narratives? → **Narrative-Based**  \n",
    "    - Is it factually wrong or out of context? → **Evidence-Based**  \n",
    "    - Is it accurate and benign? → **None of them**\n",
    "  - If **No**, label it as → **Asymmetric**\n",
    "\n",
    "### Response Format\n",
    "\n",
    "Respond with:\n",
    "1. **One of the four labels**: Narrative-Based Miscaptioning, Evidence-Based Miscaptioning, None of them, or Asymmetric  \n",
    "2. A brief reasoning (2–4 sentences) explaining your classification based on the image and tweet content.\n",
    "\"\"\"\n",
    "\n",
    "question3 = \"\"\"<image>\n",
    "### Context\n",
    "You are provided with:\n",
    "- An image\n",
    "- A tweet written by a user\n",
    "\n",
    "Your task is to assess whether the image supports, illustrates, or is meaningfully connected to the claim or main message in the tweet text.\n",
    "\n",
    "### Question\n",
    "Is the image related to the claim in the tweet text?\n",
    "\n",
    "### Response Format\n",
    "Respond with:\n",
    "1. **Yes** or **No**\n",
    "2. A short reasoning (2–4 sentences) explaining why you chose this answer, based on the content of the image and the claim in the tweet.\n",
    "\"\"\"\n",
    "        \n",
    "question2 = \"\"\"<image>\n",
    "###Context\n",
    "You are provided with:\n",
    "\t•\tAn image\n",
    "\t•\tA tweet written by a user\n",
    "\n",
    "Your task is to assess the relationship between the image and the tweet text, considering both:\n",
    "\t1.\tThe visual content of the image\n",
    "\n",
    "###Classification\n",
    "Classify the relationship into one of the following four categories:\n",
    "\t•\tparallel:\n",
    "The image and text independently contribute to the same or a very similar meaning without modifying each other.\n",
    "\t•\tadditive:\n",
    "The image and text amplify or modify each other’s meanings, providing additional context, nuance, or emotional depth when combined.\n",
    "\t•\tdivergent:\n",
    "The image and text meanings pull in opposite directions, contradict, or create a gap between the visual and textual suggestions.\n",
    "\n",
    "###Response Format\n",
    "Respond with:\n",
    "\t1.\tOne of the three labels:  parallel, additive, or divergent\n",
    "\t2.\tA reasoning (2–4 sentences) explaining why you made this classification based on the visual and web entity information.\n",
    "\"\"\"\n",
    "\n",
    "# Open CSV file for writing\n",
    "#image_content_df['intern_vl2_response_title'] = ''\n",
    "i = 0\n",
    "b=0 \n",
    "\n",
    "def fetch_article_content(url):\n",
    "    nltk.download('punkt_tab')\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        # Optional NLP (for keywords & summary)\n",
    "        article.nlp()\n",
    "\n",
    "        print(f\"Keywords: {article.keywords}\")\n",
    "\n",
    "        return article.keywords \n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching article from {url}: {e}\")\n",
    "        return ''\n",
    "\n",
    "def detect_news_links(image_path):\n",
    "    \"\"\"Detects web-related information about an image and fetches relevant news articles.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Read the image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Perform web detection\n",
    "    response = client.web_detection(image=image)\n",
    "    web_detection = response.web_detection\n",
    "\n",
    "\n",
    "    web_entities = []\n",
    "          \n",
    "    if web_detection.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(web_detection.web_entities)))\n",
    "        for entity in web_detection.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "            web_entities.append(entity.description)\n",
    "\n",
    "    return web_entities\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def main():   \n",
    "    updated_tweets = []\n",
    "\n",
    "    # Suppose 'tweet_dict' is your loaded JSON object (a dictionary)\n",
    "    with open('twitter_dataset/filtered_sampled_tweets.json', 'r') as f:\n",
    "        tweet_list = json.load(f)\n",
    "\n",
    "    # Reconstruct the dictionary with the new key after 'raw_img'\n",
    "    new_dict = OrderedDict()\n",
    "    i = 0\n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        new_tweet = OrderedDict()\n",
    "    \n",
    "        # Extract the fields\n",
    "        raw_img = tweet.get('raw_img', '')\n",
    "        image_path = 'twitter_dataset/filtered_images/' + raw_img\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"[SKIP] Image not found: {image_path}\")\n",
    "            continue  # Skip to next tweet\n",
    "        #web_entities = detect_news_links(image_path)\n",
    "        full_text = tweet.get('full_text', '')\n",
    "        prompt = f\"{question}\\nUser Tweet:{full_text}\\nAnswer:\"\n",
    "        pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "        generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "         # Generate model response\n",
    "        response = model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "        \n",
    "        print(f'id : {i}, full text: {full_text}, \\n image_path: {image_path}')\n",
    "        print(f'User: {prompt}\\nAssistant: {response}')\n",
    "        i = i+1  \n",
    "        for key in tweet:\n",
    "            new_tweet[key] = tweet[key]\n",
    "            if key == 'raw_img':\n",
    "                new_tweet['internvl_38_web_entities_response_reasoning_2'] = response\n",
    "        updated_tweets.append(new_tweet)\n",
    "    with open(\"twitter_dataset/updated_filtered_tweets_step_2.json\", \"w\") as f:\n",
    "            json.dump(updated_tweets, f, indent=4)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0f2c2",
   "metadata": {},
   "source": [
    "# Internvl OOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241193f-2a1f-4c57-a2bb-3a36e9665ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import csv\n",
    "import os\n",
    "import json\n",
    "from google.cloud import vision\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import logging\n",
    "from newspaper import Article\n",
    "import nltk\n",
    "\n",
    "def are_images_similar(local_path, content_url, hash_type='phash', threshold=5):\n",
    "    try:\n",
    "        local_img = Image.open(local_path).convert(\"RGB\")\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0\"\n",
    "        }\n",
    "        response = requests.get(content_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        imgur_img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "        hash_func = getattr(imagehash, hash_type)\n",
    "        hash_local = hash_func(local_img)\n",
    "        hash_imgur = hash_func(imgur_img)\n",
    "\n",
    "        difference = hash_local - hash_imgur\n",
    "        return difference <= threshold, difference\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"⚠️ HTTPError for URL: {content_url} → {e}\")\n",
    "        return False, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error comparing images: {e}\")\n",
    "        return False, None\n",
    "        \n",
    "question = \"\"\"<image>\n",
    "## Context ##\n",
    "You are provided with:\n",
    "- An image\n",
    "- A caption written by users  \n",
    "\n",
    "Your task is to assess whether the caption is relevant the image or is out of context considering the given visual\n",
    "Determine if the caption is used in context with the image.\n",
    "\n",
    "## Response Format ##\n",
    "Respond with **only one** of the following words, without any explanation:  \n",
    "- out of context\n",
    "- not out of context\n",
    "\"\"\"\n",
    "image_dir = \"./sample_300_merged_balanced/\"\n",
    "\n",
    "# Open CSV file for writing\n",
    "#image_content_df['intern_vl2_response_title'] = ''\n",
    "i = 0\n",
    "b=0 \n",
    "csv_file = 'image_caption_analysis_intern_vl_78_2_3_vision.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "def fetch_article_content(url):\n",
    "    nltk.download('punkt_tab')\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        # Optional NLP (for keywords & summary)\n",
    "        article.nlp()\n",
    "\n",
    "        print(f\"Keywords: {article.keywords}\")\n",
    "\n",
    "        return article.keywords \n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching article from {url}: {e}\")\n",
    "        return ''\n",
    "\n",
    "def detect_news_links(image_path):\n",
    "    \"\"\"Detects web-related information about an image and fetches relevant news articles.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Read the image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Perform web detection\n",
    "    response = client.web_detection(image=image)\n",
    "    web_detection = response.web_detection\n",
    "\n",
    "    web_entities = []\n",
    "          \n",
    "    if web_detection.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(web_detection.web_entities)))\n",
    "        for entity in web_detection.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "            web_entities.append(entity.description)\n",
    "\n",
    "    return web_entities\n",
    "    \n",
    "for index1, row in df.iterrows():\n",
    "\n",
    "                caption = row[\"Caption\"]\n",
    "                image_path = row[\"Image Path\"]\n",
    "                #image_url = row[\"Image URL\"]\n",
    "                summary = \"\" if pd.isna(row[\"News Content Vision\"]) else row[\"News Content Vision\"]\n",
    "                news_url = row['Content URL Vision']\n",
    "                #keywords = \"\" if pd.isna(news_url) else fetch_article_content(news_url)\n",
    "\n",
    "                '''\n",
    "                if not pd.isna(image_url) :\n",
    "                    is_similar, score = are_images_similar(image_path, image_url)\n",
    "                    print(score)\n",
    "                    if is_similar:\n",
    "                        title = \"\" if pd.isna(row[\"Title\"]) else row[\"Title\"]\n",
    "                        keywords =  \"\" if pd.isna(row[\"Content Keywords\"]) else row[\"Content Keywords\"]\n",
    "                    else:\n",
    "                        title = \"\"\n",
    "                        keywords = \"\"\n",
    "                else:\n",
    "                    title = \"\"\n",
    "                    keywords = \"\"\n",
    "                '''\n",
    "                print(image_path)\n",
    "                #news_links = detect_news_links(image_path)\n",
    "                prompt = f\"{question}\\nCaption:{caption}\\nAnswer:\"\n",
    "                # Process image with the model\n",
    "                \n",
    "                #print(processor.decode(output[0]))\n",
    "                # Decode model output\n",
    "                #response = processor.decode(output[0], skip_special_tokens=True)\n",
    "                #response = response.partition(\"assistant\")[2].strip().lower()\n",
    "                pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "                generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "                falsified = row['falsified_label']\n",
    "                # Generate model response\n",
    "                response = model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "                df.at[index1, 'internvl_38_vision_response'] = response\n",
    "\n",
    "                print(f'id : {i}, caption: {caption}, \\n image_path: {image_path} \\n falsified: {falsified}')\n",
    "                print(f'User: {prompt}\\nAssistant: {response}')\n",
    "                i = i+1\n",
    "\n",
    "output_csv = 'image_caption_analysis_intern_vl_78_2_3_vision.csv'\n",
    "df.to_csv(output_csv, index =False)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33c2fb2-c648-49be-8dbd-2eec29eb691a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from google.cloud import vision\n",
    "import logging\n",
    "\n",
    "json_path = \"./sample_300_merged_balanced/sampled_annotations.json\"  # Adjust path as needed\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Path to JSON annotation file\n",
    "json_path = \"./sample_300_merged_balanced/sampled_annotations.json\"\n",
    "image_dir = \"./sample_300_merged_balanced/\"\n",
    "output_csv = \"merged_balanced_url_path_with_summarized_content_title_labels2.csv\"\n",
    "\n",
    "'''\n",
    "json_path = \"./sample_300_scene/sampled_annotations.json\"  # Adjust path as needed\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Path to JSON annotation file\n",
    "json_path = \"./sample_300_scene/sampled_annotations.json\"\n",
    "image_dir = \"./sample_300_scene/images/\"\n",
    "output_csv = \"image_caption_scene_api_descriptions_with_content.csv\"\n",
    "'''\n",
    "\n",
    "from google.cloud import vision\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set credentials for Google Cloud Vision API\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./tidal-skill-452922-r9-8937cb4e49e5.json\"\n",
    "# Trusted news sources\n",
    "# Expanded Trusted News Sources List\n",
    "TRUSTED_SOURCES = [\n",
    "    \"bbc.com\", \"bbc.co.uk\",\n",
    "    \"theguardian.com\",\n",
    "    \"washingtonpost.com\",\n",
    "    \"usatoday.com\",\n",
    "    \"reuters.com\",\n",
    "    \"nytimes.com\",\n",
    "    \"cnn.com\",\n",
    "    \"npr.org\",\n",
    "    \"apnews.com\",\n",
    "    \"forbes.com\",\n",
    "    \"bloomberg.com\",\n",
    "    \"theatlantic.com\",\n",
    "    \"economist.com\"\n",
    "]\n",
    "def detect_news_links(image_path):\n",
    "    \"\"\"Detects web-related information about an image and fetches relevant news articles.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Read the image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Perform web detection\n",
    "    response = client.web_detection(image=image)\n",
    "    web_detection = response.web_detection\n",
    "\n",
    "\n",
    "    web_entities = []\n",
    "          \n",
    "    if web_detection.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(web_detection.web_entities)))\n",
    "        for entity in web_detection.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "            web_entities.append(entity.description)\n",
    "\n",
    "    return web_entities\n",
    "    \n",
    "def summarize_content(content):\n",
    "        prompt = f\"Give me the summarized version of this news content: {content}\\n\\nAnswer:\"\n",
    "\n",
    "        generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "        response = model.chat(tokenizer, None, prompt, generation_config)\n",
    "        return response\n",
    "question = \"\"\"<image>\n",
    "## Context ##\n",
    "You are provided with:\n",
    "- An image\n",
    "- A caption written by users  \n",
    "\n",
    "Your task is to assess whether the caption is relevant the image or is out of context considering the given visual \n",
    "## Objective ##\n",
    "Determine if the caption is used in context with the image.\n",
    "\n",
    "## Response Format ##\n",
    "Respond with **only one** of the following words, without any explanation:  \n",
    "- out of context\n",
    "- not out of context\n",
    "\"\"\"\n",
    "image_content_df = pd.read_csv('image_caption_analysis_merged_balanced_api_description.csv')\n",
    "# Open CSV file for writing\n",
    "#image_content_df['intern_vl2_response_title'] = ''\n",
    "i = 0\n",
    "b=0 \n",
    "    # Iterate over each annotation\n",
    "for  ann in data[\"annotations\"]:\n",
    "        caption = ann[\"caption\"]\n",
    "        image_path = os.path.join(image_dir, ann[\"image_path\"] + \".jpg\")\n",
    "        original_image_path = '/Users/mirayrdm/Documents/Courses/Research/sample_300_merged_balanced/images/' + image_path[29:]\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image not found at {image_path}\")\n",
    "            b = b+1\n",
    "            continue  # Skip missing images\n",
    "        # Example Usage\n",
    "        news_links = []\n",
    "        print(original_image_path)\n",
    "        # Check if the value exists in the DataFrame\n",
    "        matching_row = image_content_df[image_content_df[\"Original Path\"] == original_image_path]\n",
    "        news_content = ''\n",
    "        keywords = ''\n",
    "        if not matching_row.empty:\n",
    "            news_content = matching_row[\"Title\"].values[0]  \n",
    "            #keywords = matching_row['Content Keywords'].values[0]\n",
    "            if not isinstance(news_content, float) or not pd.isna(news_content):  # Ensure it's not NaN\n",
    "                if len(news_content) != 0:  # Check if content exists\n",
    "                    summarized_content = news_content\n",
    "                else:\n",
    "                    summarized_content = ''\n",
    "            else:\n",
    "                summarized_content = ''\n",
    "        else:\n",
    "            print(\"⚠ No matching 'Original Path' found.\")\n",
    "            \n",
    "        #news_links = detect_news_links(image_path)\n",
    "    \n",
    "        # Construct the prompt\n",
    "        #question = \"<image>Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\"\n",
    "        #prompt = f\"{question}\\nWeb entities:{news_links}\\nThe original content title image belongs to:{summarized_content}\\nCaption:{caption}\\nAnswer:\"\n",
    "        prompt = f\"{question}\\nCaption:{caption}\\nAnswer:\"\n",
    "\n",
    "        # Process image with the model\n",
    "        pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "        generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "        falsified = ann['falsified']\n",
    "        # Generate model response\n",
    "        response = model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "        print(f'id : {i}, caption: {caption}, \\n image_path: {image_path} \\n falsified: {falsified}')\n",
    "        print(f'User: {prompt}\\nAssistant: {response}')\n",
    "\n",
    "        # Write to CSV\n",
    "\n",
    "        image_content_df.loc[image_content_df[\"Original Path\"] == original_image_path, \"intern_vl2_78_response_title\"] = response       \n",
    "        i = i+1\n",
    "        #if i == 218:\n",
    "        #    continue\n",
    "image_content_df.to_csv(output_csv, index=False)\n",
    "print(str(b))\n",
    "print(f\"✅ CSV updated and saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfecd1e-928a-4e33-93c5-28bb5b7d3722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886027ec-668c-47d7-9360-87eee6956fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"<image>\n",
    "## Context ##\n",
    "You are provided with:\n",
    "- An image\n",
    "- The visual entities of the image\n",
    "- A caption written by users  \n",
    "\n",
    "Your task is to assess whether the caption is relevant to the image considering 1.given visual and 2.its entities.\n",
    "\n",
    "## Objective ##\n",
    "Determine if the caption is used in context with the image.\n",
    "\n",
    "## Response Format ##\n",
    "Respond with **only one** of the following words, without any explanation:  \n",
    "- out of context\n",
    "- not out of context\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"{question}\\n\\nOriginal Context Keys:{descriptions}\\nCaption:{caption}\\nAnswer:\"\n",
    "\n",
    "# Process image with the model\n",
    "pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "falsified = ann['falsified']\n",
    "        # Generate model response\n",
    "response = model.chat(tokenizer, pixel_values, prompt, generation_config)\n",
    "print(f'id : {i}, caption: {caption}, \\n image_path: {image_path} \\n falsified: {falsified}')\n",
    "print(f'User: {prompt}\\nAssistant: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2457a58-7696-4723-8747-fbda769dc61e",
   "metadata": {},
   "source": [
    "\n",
    "# GPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad408f-cfe6-4f5a-932c-3554a5f4f78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_300_merged_balanced/guardian_images_0248_812.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 6.475500106811523\n",
      "\tDescription: P. J. Mara\n",
      "\n",
      "\tScore      : 0.5598000288009644\n",
      "\tDescription: Arsenal F.C.\n",
      "\n",
      "\tScore      : 0.5037000179290771\n",
      "\tDescription: Celtic F.C.\n",
      "\n",
      "\tScore      : 0.4963500201702118\n",
      "\tDescription: Manchester City F.C.\n",
      "\n",
      "\tScore      : 0.4688999652862549\n",
      "\tDescription: Ireland\n",
      "\n",
      "\tScore      : 0.4255000054836273\n",
      "\tDescription: Irish Examiner\n",
      "\n",
      "\tScore      : 0.33489999175071716\n",
      "\tDescription: Fianna Fáil\n",
      "\n",
      "\tScore      : 0.33169999718666077\n",
      "\tDescription: Mahon Tribunal\n",
      "\n",
      "\tScore      : 0.3125999867916107\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.06250499933958054\n",
      "\tDescription: Paddy Mccaul\n",
      "id : 188, caption: Heiko Vogel s Basel will reach the Champions League last 16 and knock Manchester United out with a win, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0248_812.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['P. J. Mara', 'Arsenal F.C.', 'Celtic F.C.', 'Manchester City F.C.', 'Ireland', 'Irish Examiner', 'Fianna Fáil', 'Mahon Tribunal', '', 'Paddy Mccaul']\n",
      "Original content title image belongs to:\n",
      "Caption:Heiko Vogel s Basel will reach the Champions League last 16 and knock Manchester United out with a win\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0332_250.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.4855999946594238\n",
      "\tDescription: Sheep\n",
      "\n",
      "\tScore      : 0.7370038032531738\n",
      "\tDescription: Grazing\n",
      "\n",
      "\tScore      : 0.6349999904632568\n",
      "\tDescription: The Dartmoor Sheep Breeders Association\n",
      "\n",
      "\tScore      : 0.6152999997138977\n",
      "\tDescription: Sheep farming\n",
      "\n",
      "\tScore      : 0.5735874772071838\n",
      "\tDescription: Herd\n",
      "\n",
      "\tScore      : 0.5459933876991272\n",
      "\tDescription: Field\n",
      "\n",
      "\tScore      : 0.5060999989509583\n",
      "\tDescription: Agriculture\n",
      "\n",
      "\tScore      : 0.4438000023365021\n",
      "\tDescription: Hay\n",
      "\n",
      "\tScore      : 0.4155000150203705\n",
      "\tDescription: Bighorn sheep\n",
      "\n",
      "\tScore      : 0.3668999969959259\n",
      "\tDescription: Farm\n",
      "id : 189, caption: Lambing season at Great TreRhew Farm in Abergavenney Wales Rural land prices have reached a new high, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0332_250.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Sheep', 'Grazing', 'The Dartmoor Sheep Breeders Association', 'Sheep farming', 'Herd', 'Field', 'Agriculture', 'Hay', 'Bighorn sheep', 'Farm']\n",
      "Original content title image belongs to:A dog attack in a field has left one sheep dead and 27 injured.\n",
      "It happened between 21:00 GMT on 20 February and 13:30 the next day in Charwelton, near Daventry.\n",
      "Northamptonshire Police urged dog owners to keep their pets under control and said farmers were \"legally allowed to shoot a dog to prevent livestock worrying\".\n",
      "The force has appealed for witnesses or anyone who knows the dog owner to get in touch.\n",
      "Caption:Lambing season at Great TreRhew Farm in Abergavenney Wales Rural land prices have reached a new high\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0773_011.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.12214994430542\n",
      "\tDescription: Monastère de la Grande Chartreuse - fermé au public\n",
      "\n",
      "\tScore      : 1.0837500095367432\n",
      "\tDescription: Chartreuse\n",
      "\n",
      "\tScore      : 0.8495999574661255\n",
      "\tDescription: Paul Einbund\n",
      "\n",
      "\tScore      : 0.7350000143051147\n",
      "\tDescription: Liqueur\n",
      "\n",
      "\tScore      : 0.7156999707221985\n",
      "\tDescription: Carthusians\n",
      "\n",
      "\tScore      : 0.6276000142097473\n",
      "\tDescription: Monk\n",
      "\n",
      "\tScore      : 0.6273999810218811\n",
      "\tDescription: Chartreuse\n",
      "\n",
      "\tScore      : 0.5386500358581543\n",
      "\tDescription: Voiron\n",
      "\n",
      "\tScore      : 0.43529999256134033\n",
      "\tDescription: Ingredient\n",
      "\n",
      "\tScore      : 0.4296000003814697\n",
      "\tDescription: Restaurant\n",
      "id : 190, caption: Scientists Gene Olinger left and James Pettit demonstrate laboratory procedures at the US Army Medical Research Institute of Infectious Diseases at Fort Detrick Md, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0773_011.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Monastère de la Grande Chartreuse - fermé au public', 'Chartreuse', 'Paul Einbund', 'Liqueur', 'Carthusians', 'Monk', 'Chartreuse', 'Voiron', 'Ingredient', 'Restaurant']\n",
      "Original content title image belongs to:I was introduced to the joys of Green Chartreuse by a louche uncle.\n",
      "Whereas many drinks made by monks are only incidentally monastic, Chartreuse has a special significance for Roman Catholics.\n",
      "There is a Berry Bros price list from 1909 that guarantees Chartreuse “made by the Chartreuse monks at their Monastery previous to their expulsion from France”.\n",
      "Green Chartreuse too has its wild side.\n",
      "There’s a song by Tom Waits, When the Money Runs Out, containing the line: “With a pint of Green Chartreuse ain’t nothin’ seems right.”That lunch was the first of many boozy meals together.\n",
      "Caption:Scientists Gene Olinger left and James Pettit demonstrate laboratory procedures at the US Army Medical Research Institute of Infectious Diseases at Fort Detrick Md\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0065_061.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.2721000015735626\n",
      "\tDescription: Performance M\n",
      "id : 191, caption: Apple CEO Tim Cook discusses the new Apple Watch during an event at Apple headquarters on Thursday Oct 16 2014 in Cupertino Calif, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0065_061.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Performance M']\n",
      "Original content title image belongs to:\n",
      "Caption:Apple CEO Tim Cook discusses the new Apple Watch during an event at Apple headquarters on Thursday Oct 16 2014 in Cupertino Calif\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0408_959.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.7541974782943726\n",
      "\tDescription: Historic Sanctuary of Machu Picchu\n",
      "\n",
      "\tScore      : 0.5073503255844116\n",
      "\tDescription: Mount Scenery\n",
      "\n",
      "\tScore      : 0.4571751356124878\n",
      "\tDescription: Ruins\n",
      "\n",
      "\tScore      : 0.45158421993255615\n",
      "\tDescription: Wonders of the World\n",
      "\n",
      "\tScore      : 0.37354421615600586\n",
      "\tDescription: World Heritage Site\n",
      "\n",
      "\tScore      : 0.3610000014305115\n",
      "\tDescription: Royalty-free\n",
      "\n",
      "\tScore      : 0.34950000047683716\n",
      "\tDescription: Credit\n",
      "\n",
      "\tScore      : 0.3411000072956085\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.32899999618530273\n",
      "\tDescription: City\n",
      "\n",
      "\tScore      : 0.3264000117778778\n",
      "\tDescription: Photography\n",
      "id : 192, caption: Historian and expedition leader Torgeir Higraff believes the Inca empire established regular links with Polynesia, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0408_959.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Historic Sanctuary of Machu Picchu', 'Mount Scenery', 'Ruins', 'Wonders of the World', 'World Heritage Site', 'Royalty-free', 'Credit', '', 'City', 'Photography']\n",
      "Original content title image belongs to:\n",
      "Caption:Historian and expedition leader Torgeir Higraff believes the Inca empire established regular links with Polynesia\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0222_176.jpg\n",
      "\n",
      "2 Web entities found: \n",
      "\n",
      "\tScore      : 0.32758957147598267\n",
      "\tDescription: Graduation\n",
      "\n",
      "\tScore      : 0.32346686720848083\n",
      "\tDescription: Ceremony\n",
      "id : 193, caption: The new memorial will be in both Russian and Polish and the text will be agreed upon by both sides, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0222_176.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Graduation', 'Ceremony']\n",
      "Original content title image belongs to:\n",
      "Caption:The new memorial will be in both Russian and Polish and the text will be agreed upon by both sides\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0188_610.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.1804100275039673\n",
      "\tDescription: United States Capitol\n",
      "\n",
      "\tScore      : 1.1564850807189941\n",
      "\tDescription: Peace Monument\n",
      "\n",
      "\tScore      : 0.5176616311073303\n",
      "\tDescription: Statue\n",
      "\n",
      "\tScore      : 0.49000000953674316\n",
      "\tDescription: Minority leader\n",
      "\n",
      "\tScore      : 0.46779999136924744\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.4334000051021576\n",
      "\tDescription: United States debt ceiling\n",
      "\n",
      "\tScore      : 0.4318000078201294\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.07455000281333923\n",
      "\tDescription: Mitch McConnell\n",
      "\n",
      "\tScore      : 0.07304999977350235\n",
      "\tDescription: Kevin McCarthy\n",
      "\n",
      "\tScore      : 0.06741000711917877\n",
      "\tDescription: John Boehner\n",
      "id : 194, caption: Figures of Grief and History on the Peace Monument stand near the US Capitol building July 31 2011 in Washington DC, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0188_610.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['United States Capitol', 'Peace Monument', 'Statue', 'Minority leader', 'Image', 'United States debt ceiling', '', 'Mitch McConnell', 'Kevin McCarthy', 'John Boehner']\n",
      "Original content title image belongs to:\n",
      "Caption:Figures of Grief and History on the Peace Monument stand near the US Capitol building July 31 2011 in Washington DC\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0520_196.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 4.812000274658203\n",
      "\tDescription: Mark Getty\n",
      "\n",
      "\tScore      : 1.059000015258789\n",
      "\tDescription: Washington Nationals\n",
      "\n",
      "\tScore      : 0.8477999567985535\n",
      "\tDescription: Nationals Park\n",
      "\n",
      "\tScore      : 0.6720000505447388\n",
      "\tDescription: MLB\n",
      "\n",
      "\tScore      : 0.6406500339508057\n",
      "\tDescription: World Series\n",
      "\n",
      "\tScore      : 0.6169000267982483\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.5656999945640564\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.5656999945640564\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5304999947547913\n",
      "\tDescription: Stock photography\n",
      "\n",
      "\tScore      : 0.5145000219345093\n",
      "\tDescription: Cleveland Guardians\n",
      "id : 195, caption: Trent Cotchin and Jack Riewoldt contemplate their team s defeat to Melbourne last weekend, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0520_196.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Mark Getty', 'Washington Nationals', 'Nationals Park', 'MLB', 'World Series', 'Image', 'Getty Images', '', 'Stock photography', 'Cleveland Guardians']\n",
      "Original content title image belongs to:As Mike Rizzo enters his ninth season as general manager of the Washington Nationals and fifth with the additional title of president of baseball operations, his team has established an excellent regular season reputation.\n",
      "Smoothing the rough edgesAfter eight seasons as general manager, Rizzo is like a shortstop’s glove in its prime: not so broken in that the original shape is lost, but molded over time to fit its owner.\n",
      "AdvertisementWhen former Nationals president Stan Kasten vetted Rizzo for the position of assistant general manager to Jim Bowden in 2006, he heard more than once that all Rizzo wanted was to become a general manager.\n",
      "Kasten, who became the youngest general manager in NBA history with the Atlanta Hawks, saw no reason to deduct points for ambition.\n",
      "Major League Baseball fined him for that involvement, specifically for accosting the umpires on the way to the Citi Field clubhouse in 2011.\n",
      "Caption:Trent Cotchin and Jack Riewoldt contemplate their team s defeat to Melbourne last weekend\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0034_764.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 5.440499782562256\n",
      "\tDescription: David Cameron\n",
      "\n",
      "\tScore      : 0.5798999667167664\n",
      "\tDescription: Brussels\n",
      "\n",
      "\tScore      : 0.573449969291687\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.5386000275611877\n",
      "\tDescription: Reuters\n",
      "\n",
      "\tScore      : 0.46334999799728394\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.3874000012874603\n",
      "\tDescription: Politics\n",
      "\n",
      "\tScore      : 0.3822999894618988\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3528999984264374\n",
      "\tDescription: Foreign policy\n",
      "\n",
      "\tScore      : 0.33239999413490295\n",
      "\tDescription: Reuters\n",
      "\n",
      "\tScore      : 0.33239999413490295\n",
      "\tDescription: \n",
      "id : 196, caption: David Cameron told MPs that the G8 summit had made progress on Syria by reaffirming commitment to a peace conference, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0034_764.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['David Cameron', 'Brussels', 'United Kingdom', 'Reuters', 'United States', 'Politics', '', 'Foreign policy', 'Reuters', '']\n",
      "Original content title image belongs to:\n",
      "Caption:David Cameron told MPs that the G8 summit had made progress on Syria by reaffirming commitment to a peace conference\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0103_580.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.694000244140625\n",
      "\tDescription: Paolo Sorrentino\n",
      "\n",
      "\tScore      : 8.609999656677246\n",
      "\tDescription: Sean Penn\n",
      "\n",
      "\tScore      : 6.922500133514404\n",
      "\tDescription: Judd Hirsch\n",
      "\n",
      "\tScore      : 6.184499740600586\n",
      "\tDescription: Heinz Lieven\n",
      "\n",
      "\tScore      : 6.118500232696533\n",
      "\tDescription: Liron Levo\n",
      "\n",
      "\tScore      : 0.7595999836921692\n",
      "\tDescription: This Must Be the Place\n",
      "\n",
      "\tScore      : 0.7541999816894531\n",
      "\tDescription: Eve Hewson\n",
      "\n",
      "\tScore      : 0.4618000090122223\n",
      "\tDescription: Reuters\n",
      "\n",
      "\tScore      : 0.40720000863075256\n",
      "\tDescription: Film director\n",
      "\n",
      "\tScore      : 0.3312999904155731\n",
      "\tDescription: Il Divo\n",
      "id : 197, caption: All eyes on me Sean Penn during a photocall for Paolo Sorrentino s This Must Be the Place in competition at Cannes 2011 with Lars von Trier s Melanch damn, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0103_580.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Paolo Sorrentino', 'Sean Penn', 'Judd Hirsch', 'Heinz Lieven', 'Liron Levo', 'This Must Be the Place', 'Eve Hewson', 'Reuters', 'Film director', 'Il Divo']\n",
      "Original content title image belongs to:\n",
      "Caption:All eyes on me Sean Penn during a photocall for Paolo Sorrentino s This Must Be the Place in competition at Cannes 2011 with Lars von Trier s Melanch damn\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0593_005.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7951499819755554\n",
      "\tDescription: Table\n",
      "\n",
      "\tScore      : 0.6538340449333191\n",
      "\tDescription: Panettone\n",
      "\n",
      "\tScore      : 0.6520500183105469\n",
      "\tDescription: Coffee\n",
      "\n",
      "\tScore      : 0.6428898572921753\n",
      "\tDescription: Bazlama\n",
      "\n",
      "\tScore      : 0.6165425777435303\n",
      "\tDescription: Breakfast\n",
      "\n",
      "\tScore      : 0.5345345139503479\n",
      "\tDescription: Dinner\n",
      "\n",
      "\tScore      : 0.5184208154678345\n",
      "\tDescription: Brunch\n",
      "\n",
      "\tScore      : 0.49736863374710083\n",
      "\tDescription: Lunch\n",
      "\n",
      "\tScore      : 0.49308210611343384\n",
      "\tDescription: Buffet\n",
      "\n",
      "\tScore      : 0.45896169543266296\n",
      "\tDescription: Supper\n",
      "id : 198, caption: My mum s friend Ani would bake this cake for us whenever we visited her in Romania, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0593_005.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Table', 'Panettone', 'Coffee', 'Bazlama', 'Breakfast', 'Dinner', 'Brunch', 'Lunch', 'Buffet', 'Supper']\n",
      "Original content title image belongs to:Moscow's Red Square at Christmas , taken on a disposable camera by Laura Burrows, who says she studies Russian at the University of Leeds.\n",
      "She says she took this picture (and hundreds more) on a year abroad at Moscow State University.\n",
      "Photograph: Laura Burrows /GuardianWitness\n",
      "Caption:My mum s friend Ani would bake this cake for us whenever we visited her in Romania\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0363_729.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.6518315076828003\n",
      "\tDescription: The Taj Mahal Palace, Mumbai\n",
      "\n",
      "\tScore      : 0.5763000249862671\n",
      "\tDescription: US President\n",
      "\n",
      "\tScore      : 0.5630999803543091\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.5454999804496765\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.4683000147342682\n",
      "\tDescription: Hotel\n",
      "\n",
      "\tScore      : 0.4392000138759613\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.4392000138759613\n",
      "\tDescription: Taj Hotels\n",
      "\n",
      "\tScore      : 0.39969998598098755\n",
      "\tDescription: Tourism\n",
      "\n",
      "\tScore      : 0.37540000677108765\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.35569998621940613\n",
      "\tDescription: First Lady\n",
      "id : 199, caption: The campaign has seen acrimonious exchanges between Mr Modi and the Gandhi family, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0363_729.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['The Taj Mahal Palace, Mumbai', 'US President', 'United States', '', 'Hotel', '', 'Taj Hotels', 'Tourism', '', 'First Lady']\n",
      "Original content title image belongs to:Obama waves to photographers from backstage as he waits to speak at the US-India business council and entrepreneurship summit in MumbaiPhotograph: Jason Reed/Reuters\n",
      "Caption:The campaign has seen acrimonious exchanges between Mr Modi and the Gandhi family\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0518_806.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.4858500361442566\n",
      "\tDescription: World\n",
      "\n",
      "\tScore      : 0.444376677274704\n",
      "\tDescription: Stadium\n",
      "\n",
      "\tScore      : 0.29625412821769714\n",
      "\tDescription: Artificial turf\n",
      "\n",
      "\tScore      : 0.27880001068115234\n",
      "\tDescription: October 6\n",
      "\n",
      "\tScore      : 0.2777000069618225\n",
      "\tDescription: Headquarters\n",
      "\n",
      "\tScore      : 0.2694000005722046\n",
      "\tDescription: Collecting\n",
      "\n",
      "\tScore      : 0.2639000117778778\n",
      "\tDescription: large\n",
      "\n",
      "\tScore      : 0.25769999623298645\n",
      "\tDescription: Muses\n",
      "\n",
      "\tScore      : 0.2289000004529953\n",
      "\tDescription: Idea\n",
      "\n",
      "\tScore      : 0.19939999282360077\n",
      "\tDescription: October\n",
      "id : 200, caption: 2005 Army takes the field to face Navy at Lincoln Financial Field in Philadelphia Navy won 4223, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0518_806.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['World', 'Stadium', 'Artificial turf', 'October 6', 'Headquarters', 'Collecting', 'large', 'Muses', 'Idea', 'October']\n",
      "Original content title image belongs to:\n",
      "Caption:2005 Army takes the field to face Navy at Lincoln Financial Field in Philadelphia Navy won 4223\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0226_698.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.2867554724216461\n",
      "\tDescription: Gentleman\n",
      "id : 201, caption: Intel s perceptual computing chief says that its 3D camera component will start appearing in laptops before the end of 2014, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0226_698.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Gentleman']\n",
      "Original content title image belongs to:\n",
      "Caption:Intel s perceptual computing chief says that its 3D camera component will start appearing in laptops before the end of 2014\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0020_552.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.975889265537262\n",
      "\tDescription: iPhone 6s Plus\n",
      "\n",
      "\tScore      : 0.7013000249862671\n",
      "\tDescription: Mobile Phone\n",
      "\n",
      "\tScore      : 0.6699000000953674\n",
      "\tDescription: Smartphone\n",
      "\n",
      "\tScore      : 0.5835999846458435\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5835999846458435\n",
      "\tDescription: Apple\n",
      "\n",
      "\tScore      : 0.5671391487121582\n",
      "\tDescription: Apple iPhone 6s\n",
      "\n",
      "\tScore      : 0.5579000115394592\n",
      "\tDescription: 128 GB\n",
      "\n",
      "\tScore      : 0.5419999957084656\n",
      "\tDescription: 64 GB\n",
      "\n",
      "\tScore      : 0.5211800336837769\n",
      "\tDescription: iPhone SE\n",
      "\n",
      "\tScore      : 0.4959000051021576\n",
      "\tDescription: Mobile app\n",
      "id : 202, caption: The iPhone 6S is the best smartphone Apple has ever produced but it s marred by poor battery life that will not see you through a day, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0020_552.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['iPhone 6s Plus', 'Mobile Phone', 'Smartphone', '', 'Apple', 'Apple iPhone 6s', '128 GB', '64 GB', 'iPhone SE', 'Mobile app']\n",
      "Original content title image belongs to:In a world of smartphones with screens larger than 5in, the 4.7in iPhone 6S is in the minority.\n",
      "Photograph: Samuel Gibbs/The GuardianThe iPhone 6S is the spitting image of last year’s iPhone 6.\n",
      "Photograph: Samuel Gibbs/The GuardianThe iPhone 6S has the same dual-core A9 processor and 2GB of RAM as the 6S Plus and performs similarly.\n",
      "I found the iPhone 6S became warmer than the iPhone 6S Plus, particularly when downloading or accessing content via the mobile broadband connection rather than Wi-Fi.\n",
      "Photograph: Samuel Gibbs/The GuardianThe iPhone 6S comes with iOS 9 pre-installed; the same software that runs on any iPhone from the 4S and newer.\n",
      "Caption:The iPhone 6S is the best smartphone Apple has ever produced but it s marred by poor battery life that will not see you through a day\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0835_228.jpg\n",
      "\n",
      "9 Web entities found: \n",
      "\n",
      "\tScore      : 8.53950023651123\n",
      "\tDescription: Dieudonné Nzapalainga\n",
      "\n",
      "\tScore      : 4.160999774932861\n",
      "\tDescription: Martin Plaut\n",
      "\n",
      "\tScore      : 0.3793350160121918\n",
      "\tDescription: Bangui\n",
      "\n",
      "\tScore      : 0.3721500039100647\n",
      "\tDescription: Sudan\n",
      "\n",
      "\tScore      : 0.260699987411499\n",
      "\tDescription: Religious Leader\n",
      "\n",
      "\tScore      : 0.24809999763965607\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.23810000717639923\n",
      "\tDescription: January\n",
      "\n",
      "\tScore      : 0.22599999606609344\n",
      "\tDescription: Country\n",
      "\n",
      "\tScore      : 0.02731200121343136\n",
      "\tDescription: Central African Republic\n",
      "id : 203, caption: Central African Republic peace mission the French president Francois Hollande left greets Oumar Kobine Layama right and Dieudonne Nzapalainga before a meeting at the Elysee Palace Photographs AFPGetty, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0835_228.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Dieudonné Nzapalainga', 'Martin Plaut', 'Bangui', 'Sudan', 'Religious Leader', '', 'January', 'Country', 'Central African Republic']\n",
      "Original content title image belongs to:The EU is involved in secret talks with Sudan and Eritrea to prevent an exodus to southern Europe, leaving thousands at the mercy of repressive regimes\n",
      "Caption:Central African Republic peace mission the French president Francois Hollande left greets Oumar Kobine Layama right and Dieudonne Nzapalainga before a meeting at the Elysee Palace Photographs AFPGetty\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0132_690.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 11.072999954223633\n",
      "\tDescription: Julián Castro\n",
      "\n",
      "\tScore      : 0.7073000073432922\n",
      "\tDescription: United States Secretary of Housing and Urban Development\n",
      "\n",
      "\tScore      : 0.6018999814987183\n",
      "\tDescription: Politics\n",
      "\n",
      "\tScore      : 0.5275499820709229\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.43779999017715454\n",
      "\tDescription: Speeches of Barack Obama\n",
      "\n",
      "\tScore      : 0.374099999666214\n",
      "\tDescription: Cuba\n",
      "\n",
      "\tScore      : 0.35510000586509705\n",
      "\tDescription: United States Department of Housing and Urban Development\n",
      "\n",
      "\tScore      : 0.3517000079154968\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.29510000348091125\n",
      "\tDescription: Housing\n",
      "\n",
      "\tScore      : 0.24940000474452972\n",
      "\tDescription: \n",
      "id : 204, caption: President Obama listens as he is introduced by new Housing and Urban Development Secretary Julian Castro on July 31 at the Housing and Urban Development Department in Washington, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0132_690.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Julián Castro', 'United States Secretary of Housing and Urban Development', 'Politics', 'United States', 'Speeches of Barack Obama', 'Cuba', 'United States Department of Housing and Urban Development', '', 'Housing', '']\n",
      "Original content title image belongs to:\n",
      "Caption:President Obama listens as he is introduced by new Housing and Urban Development Secretary Julian Castro on July 31 at the Housing and Urban Development Department in Washington\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0255_100.jpg\n",
      "\n",
      "2 Web entities found: \n",
      "\n",
      "\tScore      : 0.4284000098705292\n",
      "\tDescription: light-hearted\n",
      "\n",
      "\tScore      : 0.3693000078201294\n",
      "\tDescription: CREW M\n",
      "id : 205, caption: Alabama quarterback AJ McCarron and coach Nick Saban celebrate, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0255_100.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['light-hearted', 'CREW M']\n",
      "Original content title image belongs to:\n",
      "Caption:Alabama quarterback AJ McCarron and coach Nick Saban celebrate\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0161_874.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 9.367499351501465\n",
      "\tDescription: Roger Goodell\n",
      "\n",
      "\tScore      : 1.0969500541687012\n",
      "\tDescription: NFL\n",
      "\n",
      "\tScore      : 1.0813499689102173\n",
      "\tDescription: San Francisco 49ers\n",
      "\n",
      "\tScore      : 0.8674499988555908\n",
      "\tDescription: Las Vegas Raiders\n",
      "\n",
      "\tScore      : 0.7777499556541443\n",
      "\tDescription: Deflategate\n",
      "\n",
      "\tScore      : 0.7012500166893005\n",
      "\tDescription: New England Patriots\n",
      "\n",
      "\tScore      : 0.5441700220108032\n",
      "\tDescription: Super Bowl 50\n",
      "\n",
      "\tScore      : 0.37779998779296875\n",
      "\tDescription: American football\n",
      "\n",
      "\tScore      : 0.3702999949455261\n",
      "\tDescription: Commissioner\n",
      "\n",
      "\tScore      : 0.3000999987125397\n",
      "\tDescription: Oakland Raiders relocation to Las Vegas\n",
      "id : 206, caption: Roger Goodell at Super Bowl XLVII, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0161_874.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Roger Goodell', 'NFL', 'San Francisco 49ers', 'Las Vegas Raiders', 'Deflategate', 'New England Patriots', 'Super Bowl 50', 'American football', 'Commissioner', 'Oakland Raiders relocation to Las Vegas']\n",
      "Original content title image belongs to:DeflateGate would be more of a ‘Gate’ if the league had proven that the balls were in fact deflated.\n",
      "The gauges gave significantly different readings; one read much higher than the other and showed the balls were legally inflated.\n",
      "Nevertheless the NFL decided the “preponderance of the evidence” showed Brady and the Patriots manipulated the game balls.\n",
      "Rodgers has large hands and likes an extremely hard ball.\n",
      "But you don’t establish your authority by handing down a phony hanging-judge sentence in a case that doesn’t merit it.\n",
      "Caption:Roger Goodell at Super Bowl XLVII\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0634_214.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.5960999727249146\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5960999727249146\n",
      "\tDescription: Golf\n",
      "\n",
      "\tScore      : 0.5751528739929199\n",
      "\tDescription: Putter\n",
      "\n",
      "\tScore      : 0.5342993140220642\n",
      "\tDescription: Four-ball golf\n",
      "\n",
      "\tScore      : 0.509343147277832\n",
      "\tDescription: Match play\n",
      "\n",
      "\tScore      : 0.5004302859306335\n",
      "\tDescription: Speed golf\n",
      "\n",
      "\tScore      : 0.49884912371635437\n",
      "\tDescription: Hickory golf\n",
      "\n",
      "\tScore      : 0.4859430193901062\n",
      "\tDescription: Stroke play\n",
      "\n",
      "\tScore      : 0.4757058620452881\n",
      "\tDescription: Golfer\n",
      "\n",
      "\tScore      : 0.4547458291053772\n",
      "\tDescription: Foursomes\n",
      "id : 207, caption: Tiger Woods eyes his putt on the 18th hole during the third round of the WGCBridgestone Invitational golf tournament at Firestone Country Club South Course, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0634_214.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['', 'Golf', 'Putter', 'Four-ball golf', 'Match play', 'Speed golf', 'Hickory golf', 'Stroke play', 'Golfer', 'Foursomes']\n",
      "Original content title image belongs to:\n",
      "Caption:Tiger Woods eyes his putt on the 18th hole during the third round of the WGCBridgestone Invitational golf tournament at Firestone Country Club South Course\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0389_446.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.989500045776367\n",
      "\tDescription: Jerry Hall\n",
      "\n",
      "\tScore      : 0.5762587189674377\n",
      "\tDescription: Model\n",
      "\n",
      "\tScore      : 0.4309000074863434\n",
      "\tDescription: Actor\n",
      "\n",
      "\tScore      : 0.3469499945640564\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.25369998812675476\n",
      "\tDescription: The Guardian\n",
      "\n",
      "\tScore      : 0.23759999871253967\n",
      "\tDescription: create\n",
      "\n",
      "\tScore      : 0.23183120787143707\n",
      "\tDescription: Photo shoot\n",
      "\n",
      "\tScore      : 0.2312999963760376\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.10757999867200851\n",
      "\tDescription: Mick Jagger\n",
      "\n",
      "\tScore      : 0.08422499895095825\n",
      "\tDescription: Polly Vernon\n",
      "id : 208, caption: Jerry Hall lured away from Bryan Ferry, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0389_446.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Jerry Hall', 'Model', 'Actor', 'United Kingdom', 'The Guardian', 'create', 'Photo shoot', '', 'Mick Jagger', 'Polly Vernon']\n",
      "Original content title image belongs to:I'd thought it was good business.\n",
      "My mother always used to make us eat before we went out so we'd act like ladies and not look like pigs.\n",
      "When I was 17, I was at La Coupole brasserie and Jean-Paul Sartre and Simone de Beauvoir asked me to join them at their table.\n",
      "They were fascinated that I'd watched their programme on existentialism back home and wanted to understand nothingness and being.\n",
      "My Life in Pictures by Jerry Hall is out now\n",
      "Caption:Jerry Hall lured away from Bryan Ferry\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0601_630.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.6099777221679688\n",
      "\tDescription: Kirkwood Community College\n",
      "\n",
      "\tScore      : 0.5062999725341797\n",
      "\tDescription: live\n",
      "\n",
      "\tScore      : 0.4375999867916107\n",
      "\tDescription: opening\n",
      "\n",
      "\tScore      : 0.4156000018119812\n",
      "\tDescription: Higher Education School\n",
      "\n",
      "\tScore      : 0.41103625297546387\n",
      "\tDescription: Corporate headquarters\n",
      "\n",
      "\tScore      : 0.3753444254398346\n",
      "\tDescription: Headquarters\n",
      "\n",
      "\tScore      : 0.36395689845085144\n",
      "\tDescription: Brutalist architecture\n",
      "\n",
      "\tScore      : 0.34689998626708984\n",
      "\tDescription: Architecture\n",
      "\n",
      "\tScore      : 0.3434999883174896\n",
      "\tDescription: School\n",
      "\n",
      "\tScore      : 0.3353999853134155\n",
      "\tDescription: Community\n",
      "id : 209, caption: Media members run after Clinton s motorcade as it arrives at Kirkwood Community College in Monticello Iowa before a small roundtable discussion, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0601_630.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Kirkwood Community College', 'live', 'opening', 'Higher Education School', 'Corporate headquarters', 'Headquarters', 'Brutalist architecture', 'Architecture', 'School', 'Community']\n",
      "Original content title image belongs to:\n",
      "Caption:Media members run after Clinton s motorcade as it arrives at Kirkwood Community College in Monticello Iowa before a small roundtable discussion\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0259_498.jpg\n",
      "\n",
      "3 Web entities found: \n",
      "\n",
      "\tScore      : 0.43456095457077026\n",
      "\tDescription: iPhone\n",
      "\n",
      "\tScore      : 0.42537862062454224\n",
      "\tDescription: Feature phone\n",
      "\n",
      "\tScore      : 0.3529999852180481\n",
      "\tDescription: Mobile Phone\n",
      "id : 210, caption: Indian drivers for Uber show mobiles phones given to them by the company, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0259_498.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['iPhone', 'Feature phone', 'Mobile Phone']\n",
      "Original content title image belongs to:\n",
      "Caption:Indian drivers for Uber show mobiles phones given to them by the company\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0064_675.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.4953429400920868\n",
      "\tDescription: Speech\n",
      "\n",
      "\tScore      : 0.385699987411499\n",
      "\tDescription: Public speaking\n",
      "\n",
      "\tScore      : 0.3624694049358368\n",
      "\tDescription: Orator\n",
      "\n",
      "\tScore      : 0.35209399461746216\n",
      "\tDescription: Spokesperson\n",
      "\n",
      "\tScore      : 0.32580000162124634\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.32580000162124634\n",
      "\tDescription: Google\n",
      "\n",
      "\tScore      : 0.321399986743927\n",
      "\tDescription: popular\n",
      "\n",
      "\tScore      : 0.30660000443458557\n",
      "\tDescription: Google\n",
      "\n",
      "\tScore      : 0.29649999737739563\n",
      "\tDescription: Fact-checking\n",
      "\n",
      "\tScore      : 0.2903999984264374\n",
      "\tDescription: USA Today\n",
      "id : 211, caption: Donald Trump reacts Friday as reporters yell questions after he declared that he now believes Barack Obama was born in the United States, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0064_675.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Speech', 'Public speaking', 'Orator', 'Spokesperson', '', 'Google', 'popular', 'Google', 'Fact-checking', 'USA Today']\n",
      "Original content title image belongs to:During the presidential debate, Donald Trump used the word “bigly” several times, and many sitting at home took notice.\n",
      "One of the most popular fact check questions about Donald Trump on Google was whether “bigly,” or what we are assuming means “big way or big time,” is an actual word.\n",
      "Many on social media, pointed out that \"bigly\" sounds like \"big league.\"\n",
      "Team big league.\n",
      "In 2015, campaign spokeswoman Hop Hicks told Slate, it's “big league,\" not bigly.\n",
      "Caption:Donald Trump reacts Friday as reporters yell questions after he declared that he now believes Barack Obama was born in the United States\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0020_140.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.831999778747559\n",
      "\tDescription: Angelina Jolie\n",
      "\n",
      "\tScore      : 11.047500610351562\n",
      "\tDescription: Brad Pitt\n",
      "\n",
      "\tScore      : 0.7064999938011169\n",
      "\tDescription: Wedding\n",
      "\n",
      "\tScore      : 0.673799991607666\n",
      "\tDescription: Mr. & Mrs. Smith\n",
      "\n",
      "\tScore      : 0.5941500067710876\n",
      "\tDescription: Chateau Miraval\n",
      "\n",
      "\tScore      : 0.5909000039100647\n",
      "\tDescription: Brangelina\n",
      "\n",
      "\tScore      : 0.511650025844574\n",
      "\tDescription: Seven\n",
      "\n",
      "\tScore      : 0.4521999955177307\n",
      "\tDescription: Actor\n",
      "\n",
      "\tScore      : 0.44600000977516174\n",
      "\tDescription: Wedding Dress\n",
      "\n",
      "\tScore      : 0.4072999954223633\n",
      "\tDescription: Supercouple\n",
      "id : 212, caption: Wax models of actors Brad Pitt and Angelina Jolie at Madame Tussauds attraction in Sydney, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0020_140.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Angelina Jolie', 'Brad Pitt', 'Wedding', 'Mr. & Mrs. Smith', 'Chateau Miraval', 'Brangelina', 'Seven', 'Actor', 'Wedding Dress', 'Supercouple']\n",
      "Original content title image belongs to:Angelina has longstanding relationships with the big guns of couture, rotating through Valentino, Atelier Versace and Elie Saab.\n",
      "With that in mind, here are six things we do know about Angelina’s wedding dress:She did wear a dressAccording to E!\n",
      "The dress was possibly oldWe also know the dress was “antique lace and silk”.\n",
      "And ‘comfortable’Again, this is according to sources in attendance at the wedding, so really just complete speculation.\n",
      "And they both wore ringsIt’s thought their wedding rings were designed by friend, Robert Procop.\n",
      "Caption:Wax models of actors Brad Pitt and Angelina Jolie at Madame Tussauds attraction in Sydney\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0227_333.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.669635534286499\n",
      "\tDescription: Rugby sevens\n",
      "\n",
      "\tScore      : 0.668350100517273\n",
      "\tDescription: Rugby league\n",
      "\n",
      "\tScore      : 0.5648486614227295\n",
      "\tDescription: Australian rules football\n",
      "\n",
      "\tScore      : 0.5617577433586121\n",
      "\tDescription: Rugby league sevens\n",
      "\n",
      "\tScore      : 0.5223163962364197\n",
      "\tDescription: Rugby tens\n",
      "\n",
      "\tScore      : 0.5158166289329529\n",
      "\tDescription: Rugby league nines\n",
      "\n",
      "\tScore      : 0.48161739110946655\n",
      "\tDescription: Touch\n",
      "\n",
      "\tScore      : 0.47850000858306885\n",
      "\tDescription: Rugby football\n",
      "\n",
      "\tScore      : 0.46700000762939453\n",
      "\tDescription: Kick american football\n",
      "\n",
      "\tScore      : 0.4666999876499176\n",
      "\tDescription: STXE 600 IND.ENE.NR DL\n",
      "id : 213, caption: Bath s Horatio Agulla cheers his try James Haskell gets ready for the beach and Saracens s Chris Ashton celebrates, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0227_333.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Rugby sevens', 'Rugby league', 'Australian rules football', 'Rugby league sevens', 'Rugby tens', 'Rugby league nines', 'Touch', 'Rugby football', 'Kick american football', 'STXE 600 IND.ENE.NR DL']\n",
      "Original content title image belongs to:\n",
      "Caption:Bath s Horatio Agulla cheers his try James Haskell gets ready for the beach and Saracens s Chris Ashton celebrates\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0599_184.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.9112499952316284\n",
      "\tDescription: Colorado River\n",
      "\n",
      "\tScore      : 0.7703850269317627\n",
      "\tDescription: Hoover Dam Visitor Center & Tours\n",
      "\n",
      "\tScore      : 0.7125999927520752\n",
      "\tDescription: Dam\n",
      "\n",
      "\tScore      : 0.7091000080108643\n",
      "\tDescription: Arizona–Nevada border\n",
      "\n",
      "\tScore      : 0.6464999914169312\n",
      "\tDescription: Las Vegas\n",
      "\n",
      "\tScore      : 0.6080999970436096\n",
      "\tDescription: Arch–gravity dam\n",
      "\n",
      "\tScore      : 0.593999981880188\n",
      "\tDescription: Concrete\n",
      "\n",
      "\tScore      : 0.5371000170707703\n",
      "\tDescription: Civil Engineering\n",
      "\n",
      "\tScore      : 0.502810001373291\n",
      "\tDescription: \"High Scaler\" Statue\n",
      "\n",
      "\tScore      : 0.4050000309944153\n",
      "\tDescription: Lake Mead\n",
      "id : 214, caption: From the center of Hoover Dam at the NevadaArizona border this view shows the Colorado River and the new bypass bridge that is under construction, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0599_184.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Colorado River', 'Hoover Dam Visitor Center & Tours', 'Dam', 'Arizona–Nevada border', 'Las Vegas', 'Arch–gravity dam', 'Concrete', 'Civil Engineering', '\"High Scaler\" Statue', 'Lake Mead']\n",
      "Original content title image belongs to:CNN —With dancing fountains, a thundering volcano, a pyramid-shaped flashlight and singing gondoliers, Las Vegas Boulevard could be the most happening street in the West.\n",
      "Seven Magic MountainsBeyond the Strip: For an alternative to the Las Vegas Strip casinos and nightclubs, there are jackpots to be won at some of the region's hotspots farther afield.\n",
      "Sydney Martinez/Travel Nevada Lake Las Vegas: About 40 minutes from Vegas, this lake community is a popular destination for day trippers who want to kayak, paddleboard or spend time on rowboats.\n",
      "Spring Mountains National Recreation Area, 4701 N. Torrey Pines Dr., Las Vegas, NV, 89130; +1 702/872-5486; admission is free4.\n",
      "Perhaps the most treacherous portion of the trail comes between Lake Las Vegas and Henderson – three successive hills, each taller and more challenging than the last.\n",
      "Caption:From the center of Hoover Dam at the NevadaArizona border this view shows the Colorado River and the new bypass bridge that is under construction\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0461_204.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7008000016212463\n",
      "\tDescription: Normandy landings\n",
      "\n",
      "\tScore      : 0.361299991607666\n",
      "\tDescription: 1944\n",
      "\n",
      "\tScore      : 0.3357999920845032\n",
      "\tDescription: Grave\n",
      "\n",
      "\tScore      : 0.2902500033378601\n",
      "\tDescription: Car\n",
      "\n",
      "\tScore      : 0.2793999910354614\n",
      "\tDescription: finished\n",
      "\n",
      "\tScore      : 0.25690001249313354\n",
      "\tDescription: Royal Hampshire Regiment\n",
      "\n",
      "\tScore      : 0.2565000057220459\n",
      "\tDescription: Regiment\n",
      "\n",
      "\tScore      : 0.24289999902248383\n",
      "\tDescription: Find a Grave\n",
      "\n",
      "\tScore      : 0.19429999589920044\n",
      "\tDescription: 1916\n",
      "\n",
      "\tScore      : 0.19269999861717224\n",
      "\tDescription: Image\n",
      "id : 215, caption: Charles was picked to be secondincommand of the 1st Battalion of the Hampshire Regiment, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0461_204.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Normandy landings', '1944', 'Grave', 'Car', 'finished', 'Royal Hampshire Regiment', 'Regiment', 'Find a Grave', '1916', 'Image']\n",
      "Original content title image belongs to:\n",
      "Caption:Charles was picked to be secondincommand of the 1st Battalion of the Hampshire Regiment\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0398_666.jpg\n",
      "\n",
      "9 Web entities found: \n",
      "\n",
      "\tScore      : 0.590215802192688\n",
      "\tDescription: Infantry\n",
      "\n",
      "\tScore      : 0.538366973400116\n",
      "\tDescription: Airsoft\n",
      "\n",
      "\tScore      : 0.4735499918460846\n",
      "\tDescription: Russia\n",
      "\n",
      "\tScore      : 0.39259999990463257\n",
      "\tDescription: SVD\n",
      "\n",
      "\tScore      : 0.37955525517463684\n",
      "\tDescription: Practical shooting\n",
      "\n",
      "\tScore      : 0.37459999322891235\n",
      "\tDescription: left\n",
      "\n",
      "\tScore      : 0.3156999945640564\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.30093061923980713\n",
      "\tDescription: Troop\n",
      "\n",
      "\tScore      : 0.2992999851703644\n",
      "\tDescription: Gun\n",
      "id : 216, caption: Gasparyan with other Vostok fighters, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0398_666.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Infantry', 'Airsoft', 'Russia', 'SVD', 'Practical shooting', 'left', '', 'Troop', 'Gun']\n",
      "Original content title image belongs to:They took us to a camp – some small homes near a creek and a forest – I don't know where.\n",
      "Even now I don't know the names of most of the guys who were killed beside me in that hell.\n",
      "I don't know.\n",
      "At that point, I still didn't know we'd been attacked by our own forces.\n",
      "I don't know.\n",
      "Caption:Gasparyan with other Vostok fighters\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0257_952.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 3.7664999961853027\n",
      "\tDescription: Paula Deen\n",
      "\n",
      "\tScore      : 1.4995499849319458\n",
      "\tDescription: LA Clippers\n",
      "\n",
      "\tScore      : 1.0762499570846558\n",
      "\tDescription: NBA\n",
      "\n",
      "\tScore      : 1.055400013923645\n",
      "\tDescription: Donald Sterling\n",
      "\n",
      "\tScore      : 0.5494999885559082\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.4584999978542328\n",
      "\tDescription: Basketball\n",
      "\n",
      "\tScore      : 0.42579999566078186\n",
      "\tDescription: Commissioner of the NBA\n",
      "\n",
      "\tScore      : 0.3703500032424927\n",
      "\tDescription: Chicago Bulls\n",
      "\n",
      "\tScore      : 0.33855801820755005\n",
      "\tDescription: Courtside Residence Suites\n",
      "\n",
      "\tScore      : 0.28519999980926514\n",
      "\tDescription: just\n",
      "id : 217, caption: Donald Sterling with V Stiviano, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0257_952.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Paula Deen', 'LA Clippers', 'NBA', 'Donald Sterling', '', 'Basketball', 'Commissioner of the NBA', 'Chicago Bulls', 'Courtside Residence Suites', 'just']\n",
      "Original content title image belongs to:The week is done, and in seven days Donald Sterling, who prefers segregation in matters of housing and NBA arenas, has become the most vilified human being in sports since Jerry Sandusky, a convicted pedophile.\n",
      "Clippers owner Donald Sterling banned for life from NBA + 11 Los Angeles Clippers owner Donald Sterling was banned for life from the NBA, Commissioner Adam Silver announced Tuesday, because of an audio recording in which he made racially charged comments to his girlfriend.\n",
      "Magic owner Rich DeVos, once asked about the backlash he received for serving on President Reagan's heartless HIV/AIDS commission, essentially responded, \"Hate the sinner and the sin.\"\n",
      "\"I wish I had just paid her off,\" a remorseless Sterling told DuJour magazine in a quote from an exclusive interview released Friday.\n",
      "More on Donald Sterling:\n",
      "Caption:Donald Sterling with V Stiviano\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0717_658.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.521439254283905\n",
      "\tDescription: Six-man football\n",
      "\n",
      "\tScore      : 0.5116162300109863\n",
      "\tDescription: Eight-man football\n",
      "\n",
      "\tScore      : 0.5044999718666077\n",
      "\tDescription: American football\n",
      "\n",
      "\tScore      : 0.46709999442100525\n",
      "\tDescription: Kick american football\n",
      "\n",
      "\tScore      : 0.4610861539840698\n",
      "\tDescription: Arena football\n",
      "\n",
      "\tScore      : 0.45774170756340027\n",
      "\tDescription: Canadian football\n",
      "\n",
      "\tScore      : 0.41909998655319214\n",
      "\tDescription: Canada\n",
      "\n",
      "\tScore      : 0.35915082693099976\n",
      "\tDescription: Sprint football\n",
      "\n",
      "\tScore      : 0.2793999910354614\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.23479999601840973\n",
      "\tDescription: Kick\n",
      "id : 218, caption: Rams cornerback Cortland Finnegan intercepts a Robert Griffin pass intended for Fred Davis, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0717_658.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Six-man football', 'Eight-man football', 'American football', 'Kick american football', 'Arena football', 'Canadian football', 'Canada', 'Sprint football', '', 'Kick']\n",
      "Original content title image belongs to:\n",
      "Caption:Rams cornerback Cortland Finnegan intercepts a Robert Griffin pass intended for Fred Davis\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0658_824.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.902000427246094\n",
      "\tDescription: Saul Bellow\n",
      "\n",
      "\tScore      : 1.3631999492645264\n",
      "\tDescription: The Adventures of Augie March\n",
      "\n",
      "\tScore      : 0.856950044631958\n",
      "\tDescription: 寫在課本留白處\n",
      "\n",
      "\tScore      : 0.8429999351501465\n",
      "\tDescription: 第九味\n",
      "\n",
      "\tScore      : 0.7307999730110168\n",
      "\tDescription: 煮字為藥\n",
      "\n",
      "\tScore      : 0.6474999785423279\n",
      "\tDescription: Book\n",
      "\n",
      "\tScore      : 0.527899980545044\n",
      "\tDescription: Great American Novel\n",
      "\n",
      "\tScore      : 0.5250999927520752\n",
      "\tDescription: Novel\n",
      "\n",
      "\tScore      : 0.4814999997615814\n",
      "\tDescription: Publishing\n",
      "\n",
      "\tScore      : 0.4781999886035919\n",
      "\tDescription: Writer\n",
      "id : 219, caption: Saul Bellow in the 1950s after writing The Adventures of Augie March, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0658_824.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Saul Bellow', 'The Adventures of Augie March', '寫在課本留白處', '第九味', '煮字為藥', 'Book', 'Great American Novel', 'Novel', 'Publishing', 'Writer']\n",
      "Original content title image belongs to:This, says Martin Amis, one of many writers under Bellow’s spell, is “the Great American Novel.\n",
      "No question: the great American postwar fiction boom starts here.\n",
      "Augie is “the by-blow of a travelling man”, and his adventures, loosely patterned after Bellow’s experience, are picaresque.\n",
      "The Adventures of Augie March encountered only one serious pre-publication critique (from Bellow’s British editor, John Lehmann, the celebrated founder of Penguin New Writing).\n",
      "The Adventures of Augie March is available in Penguin paperback, £12.\n",
      "Caption:Saul Bellow in the 1950s after writing The Adventures of Augie March\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0616_278.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 5.857500076293945\n",
      "\tDescription: Chris Smalling\n",
      "\n",
      "\tScore      : 0.5117999911308289\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.4602457880973816\n",
      "\tDescription: Footballer\n",
      "\n",
      "\tScore      : 0.44369998574256897\n",
      "\tDescription: Suicide attack\n",
      "\n",
      "\tScore      : 0.37466615438461304\n",
      "\tDescription: Athlete\n",
      "\n",
      "\tScore      : 0.34119999408721924\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3125999867916107\n",
      "\tDescription: Clothing\n",
      "\n",
      "\tScore      : 0.3001999855041504\n",
      "\tDescription: Dress-up\n",
      "\n",
      "\tScore      : 0.29429998993873596\n",
      "\tDescription: 2014\n",
      "\n",
      "\tScore      : 0.28369998931884766\n",
      "\tDescription: Costume party\n",
      "id : 220, caption: Chris Smalling was pictured in the Sun appearing to wear an army vest with alcohol bottles and a mock circuit board attached, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0616_278.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Chris Smalling', 'United Kingdom', 'Footballer', 'Suicide attack', 'Athlete', '', 'Clothing', 'Dress-up', '2014', 'Costume party']\n",
      "Original content title image belongs to:Chris Smalling's decision to dress up as a suicide bomber for a fancy dress party has been described as \"thoughtless\" by a survivor of the 7 July bombings in London.\n",
      "Jacqui Putnam, who survived the Edgware Road blast in 2005, said people should \"think twice\" before making light of terrorism.\n",
      "The Manchester United and England defender has apologised for his \"insensitive\" decision to wear the costume.\n",
      "\"I am sure that he did not mean to offend anyone but I wish people would think twice.\n",
      "If people could only think twice about the pain this could cause to people who have lost loved ones in these circumstances it would be appreciated by survivors and the bereaved alike.\"\n",
      "Caption:Chris Smalling was pictured in the Sun appearing to wear an army vest with alcohol bottles and a mock circuit board attached\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0379_333.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 4.565999984741211\n",
      "\tDescription: Valeriya Novodvorskaya\n",
      "\n",
      "\tScore      : 1.4329500198364258\n",
      "\tDescription: Ukraine\n",
      "\n",
      "\tScore      : 0.7202000021934509\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.6549000144004822\n",
      "\tDescription: 2014 Crimean crisis\n",
      "\n",
      "\tScore      : 0.5998499989509583\n",
      "\tDescription: Russia\n",
      "\n",
      "\tScore      : 0.49755001068115234\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.4916999936103821\n",
      "\tDescription: Ukrainians\n",
      "\n",
      "\tScore      : 0.4884999990463257\n",
      "\tDescription: Russian\n",
      "\n",
      "\tScore      : 0.4884999990463257\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.43769997358322144\n",
      "\tDescription: John Kerry\n",
      "id : 221, caption: Germany fans during the game against Algeria, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0379_333.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Valeriya Novodvorskaya', 'Ukraine', '', '2014 Crimean crisis', 'Russia', 'United States', 'Ukrainians', 'Russian', '', 'John Kerry']\n",
      "Original content title image belongs to:Advertisement“There’s another path available” for Russia, “and we hope that President [Vladimir] Putin is willing to seize that path,” Obama said.\n",
      "Even as they continued to offer Russia a diplomatic exit, officials made clear that they doubt Putin intends to take it.\n",
      "Instead, both the administration and leading Western governments were closely coordinating sanctions they plan to impose as early as Monday, immediately after the Crimea referendum.\n",
      "and the United States plan to freeze assets of Ukrainian and Russian \"individuals and entities\" deemed responsible for political upheaval and corruption in Ukraine.\n",
      "“Crimea is an integral part of Ukraine,” he said during a speech at the Atlantic Council after his meeting with Obama.\n",
      "Caption:Germany fans during the game against Algeria\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0083_471.jpg\n",
      "\n",
      "4 Web entities found: \n",
      "\n",
      "\tScore      : 0.39809998869895935\n",
      "\tDescription: senior\n",
      "\n",
      "\tScore      : 0.382999986410141\n",
      "\tDescription: citizenM\n",
      "\n",
      "\tScore      : 0.382999986410141\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3019999861717224\n",
      "\tDescription: CitizenM\n",
      "id : 222, caption: Presidential hopeful Bernie Sanders waves to a crowd of supports on caucus night Monday Feb 1 2016 in Des Moines, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0083_471.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['senior', 'citizenM', '', 'CitizenM']\n",
      "Original content title image belongs to:\n",
      "Caption:Presidential hopeful Bernie Sanders waves to a crowd of supports on caucus night Monday Feb 1 2016 in Des Moines\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0599_220.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.287200003862381\n",
      "\tDescription: Meter\n",
      "id : 223, caption: Lucy Maxwell should work for the Florida tourist board She s certain her stark poster would do the trick It convinces me Every day Photomontage Lucy Maxwell, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0599_220.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Meter']\n",
      "Original content title image belongs to:\n",
      "Caption:Lucy Maxwell should work for the Florida tourist board She s certain her stark poster would do the trick It convinces me Every day Photomontage Lucy Maxwell\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0255_686.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.6205484867095947\n",
      "\tDescription: Gao\n",
      "\n",
      "\tScore      : 0.5198000073432922\n",
      "\tDescription: Malian Armed Forces\n",
      "\n",
      "\tScore      : 0.4203000068664551\n",
      "\tDescription: Mali War\n",
      "\n",
      "\tScore      : 0.3874000012874603\n",
      "\tDescription: Soldier\n",
      "\n",
      "\tScore      : 0.3648972511291504\n",
      "\tDescription: Infantry\n",
      "\n",
      "\tScore      : 0.3529999852180481\n",
      "\tDescription: The Shikoku Shimbun\n",
      "\n",
      "\tScore      : 0.3427974283695221\n",
      "\tDescription: Armored car\n",
      "\n",
      "\tScore      : 0.3393000066280365\n",
      "\tDescription: Car\n",
      "\n",
      "\tScore      : 0.28380000591278076\n",
      "\tDescription: March\n",
      "\n",
      "\tScore      : 0.2694000005722046\n",
      "\tDescription: Armed forces\n",
      "id : 224, caption: Rebels loyal to leader Minni Minnawi ride into ElFasher the administrative capital of north Darfur, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0255_686.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Gao', 'Malian Armed Forces', 'Mali War', 'Soldier', 'Infantry', 'The Shikoku Shimbun', 'Armored car', 'Car', 'March', 'Armed forces']\n",
      "Original content title image belongs to:\n",
      "Caption:Rebels loyal to leader Minni Minnawi ride into ElFasher the administrative capital of north Darfur\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0522_343.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.9313499927520752\n",
      "\tDescription: Auto Club Speedway\n",
      "\n",
      "\tScore      : 0.9163500070571899\n",
      "\tDescription: NASCAR Cup Series\n",
      "\n",
      "\tScore      : 0.8731499910354614\n",
      "\tDescription: Indianapolis Motor Speedway\n",
      "\n",
      "\tScore      : 0.8689500093460083\n",
      "\tDescription: Team Penske\n",
      "\n",
      "\tScore      : 0.5792999863624573\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5648999810218811\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5648999810218811\n",
      "\tDescription: NASCAR\n",
      "\n",
      "\tScore      : 0.4607999920845032\n",
      "\tDescription: Nascar\n",
      "\n",
      "\tScore      : 0.3979499936103821\n",
      "\tDescription: Rochester Hills\n",
      "\n",
      "\tScore      : 0.3043000102043152\n",
      "\tDescription: 1984\n",
      "id : 225, caption: Brad Keselowski celebrates in victory lane after winning the AAA 400, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0522_343.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Auto Club Speedway', 'NASCAR Cup Series', 'Indianapolis Motor Speedway', 'Team Penske', '', '', 'NASCAR', 'Nascar', 'Rochester Hills', '1984']\n",
      "Original content title image belongs to:NASCAR Brad Keselowski Add TopicNASCAR driver Brad Keselowski through the yearsUSA TODAYBrad Keselowski, born Feb. 12, 1984 in Rochester Hills, Mich., made his first NASCAR Cup Series start in 2008 and went on to win the 2012 championship.\n",
      "Amber Searls, USA TODAY SportsBrad Keselowski celebrates after winning the Coca-Cola 600 at Charlotte Motor Speedway on May 24, 2020.\n",
      "Adam Hagy, USA TODAY SportsBrad Keselowski qualified for the third round of the playoffs Oct. 15, 2017, with his fifth win at Talladega Superspeedway.\n",
      "Jasen Vinlove, USA TODAY SportsBrad Keselowski led 383 of 400 laps to win at Richmond International Raceway in September 2014.\n",
      "Raj Mehta, USA TODAY SportsBrad Keselowski chugs a huge beer in front of NASCAR chairman and CEO Brian France at Homestead-Miami Speedway after winning the 2012 NASCAR Sprint Cup championship.\n",
      "Caption:Brad Keselowski celebrates in victory lane after winning the AAA 400\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0683_732.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.968500137329102\n",
      "\tDescription: Brad Pitt\n",
      "\n",
      "\tScore      : 10.780500411987305\n",
      "\tDescription: Angelina Jolie\n",
      "\n",
      "\tScore      : 0.8065500259399414\n",
      "\tDescription: Jennifer Aniston\n",
      "\n",
      "\tScore      : 0.7879500389099121\n",
      "\tDescription: A Mighty Heart\n",
      "\n",
      "\tScore      : 0.7786500453948975\n",
      "\tDescription: Mr. & Mrs. Smith\n",
      "\n",
      "\tScore      : 0.718410074710846\n",
      "\tDescription: Ocean's Thirteen\n",
      "\n",
      "\tScore      : 0.5242999792098999\n",
      "\tDescription: Brangelina\n",
      "\n",
      "\tScore      : 0.4487000107765198\n",
      "\tDescription: Actor\n",
      "\n",
      "\tScore      : 0.4270070195198059\n",
      "\tDescription: Premiere\n",
      "\n",
      "\tScore      : 0.3566364645957947\n",
      "\tDescription: Red carpet\n",
      "id : 226, caption: Brad Pitt and Angelina Jolie at the New York premiere of A Mighty Heart in June 2007, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0683_732.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Brad Pitt', 'Angelina Jolie', 'Jennifer Aniston', 'A Mighty Heart', 'Mr. & Mrs. Smith', \"Ocean's Thirteen\", 'Brangelina', 'Actor', 'Premiere', 'Red carpet']\n",
      "Original content title image belongs to:Matt Sayles, APAnd so it began ... Brangelina was sparked when Brad Pitt and Angelina Jolie steamed up screens in 2005's 'Mr.\n",
      "Stephen Vaughan, 20th Century FoxAngelina Jolie and Brad Pitt, dodging rumors of a romance, kept their distance as they promoted 'Mr.\n",
      "APBrad Pitt and Angelina Jolie, here with her son Maddox, arrive at Narita International Airport in Tokyo, in November 2005.\n",
      "Grant Lamos IV, FilmMagicBrad Pitt (as Roland) comforts Angelina Jolie Pitt (as Vanessa) in 'By the Sea,' which she directed.\n",
      "Universal Pictures Via APAngelina Jolie Pitt and Brad Pitt arrive at AFI Fest 2015's opening night gala premiere of 'By the Sea' in Los Angeles.\n",
      "Caption:Brad Pitt and Angelina Jolie at the New York premiere of A Mighty Heart in June 2007\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0693_671.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 7.641000270843506\n",
      "\tDescription: Jeremy Corbyn\n",
      "\n",
      "\tScore      : 7.4760003089904785\n",
      "\tDescription: John Woodcock, Baron Walney\n",
      "\n",
      "\tScore      : 0.684149980545044\n",
      "\tDescription: Barrow and Furness\n",
      "\n",
      "\tScore      : 0.5968241691589355\n",
      "\tDescription: Human\n",
      "\n",
      "\tScore      : 0.5163000226020813\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5163000226020813\n",
      "\tDescription: Labour Party\n",
      "\n",
      "\tScore      : 0.4016000032424927\n",
      "\tDescription: All-party parliamentary group\n",
      "\n",
      "\tScore      : 0.3353999853134155\n",
      "\tDescription: Political party\n",
      "\n",
      "\tScore      : 0.3262999951839447\n",
      "\tDescription: citizenM\n",
      "\n",
      "\tScore      : 0.3262999951839447\n",
      "\tDescription: \n",
      "id : 227, caption: Jeremy Corbyn at the Labour conference in Brighton Rob Campbell principal of Impington Village college hopes the party leader will be able to shake things up, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0693_671.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Jeremy Corbyn', 'John Woodcock, Baron Walney', 'Barrow and Furness', 'Human', '', 'Labour Party', 'All-party parliamentary group', 'Political party', 'citizenM', '']\n",
      "Original content title image belongs to:\n",
      "Caption:Jeremy Corbyn at the Labour conference in Brighton Rob Campbell principal of Impington Village college hopes the party leader will be able to shake things up\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0036_125.jpg\n",
      "\n",
      "5 Web entities found: \n",
      "\n",
      "\tScore      : 0.7178000211715698\n",
      "\tDescription: Gun\n",
      "\n",
      "\tScore      : 0.7055000066757202\n",
      "\tDescription: Self-defense\n",
      "\n",
      "\tScore      : 0.6790000200271606\n",
      "\tDescription: Handgun\n",
      "\n",
      "\tScore      : 0.6546000242233276\n",
      "\tDescription: Right to keep and bear arms\n",
      "\n",
      "\tScore      : 0.604200005531311\n",
      "\tDescription: Magazine\n",
      "id : 228, caption: The Scottish Police Federation wants to see more armed officers carrying weapons in public in Scotland, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0036_125.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Gun', 'Self-defense', 'Handgun', 'Right to keep and bear arms', 'Magazine']\n",
      "Original content title image belongs to:\n",
      "Caption:The Scottish Police Federation wants to see more armed officers carrying weapons in public in Scotland\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0064_325.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7984499931335449\n",
      "\tDescription: Al Gore\n",
      "\n",
      "\tScore      : 0.6612045168876648\n",
      "\tDescription: Miami Dade College\n",
      "\n",
      "\tScore      : 0.4693000018596649\n",
      "\tDescription: Presidential nominee\n",
      "\n",
      "\tScore      : 0.447299987077713\n",
      "\tDescription: past\n",
      "\n",
      "\tScore      : 0.43428000807762146\n",
      "\tDescription: Miami Dade College Kendall Campus\n",
      "\n",
      "\tScore      : 0.4316999912261963\n",
      "\tDescription: succeeding\n",
      "\n",
      "\tScore      : 0.41929998993873596\n",
      "\tDescription: Climate change\n",
      "\n",
      "\tScore      : 0.3195638656616211\n",
      "\tDescription: Ceremony\n",
      "\n",
      "\tScore      : 0.2946000099182129\n",
      "\tDescription: Campus\n",
      "\n",
      "\tScore      : 0.1697751134634018\n",
      "\tDescription: Miami\n",
      "id : 229, caption: Democratic presidential nominee Hillary Clinton and former vice president Al Gore wave to supporters following a rally at Miami Dade College Kendall Campus on Tuesday in Miami, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0064_325.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Al Gore', 'Miami Dade College', 'Presidential nominee', 'past', 'Miami Dade College Kendall Campus', 'succeeding', 'Climate change', 'Ceremony', 'Campus', 'Miami']\n",
      "Original content title image belongs to:Trump has famously referred to climate change as a hoax perpetrated by the Chinese.\n",
      "“Your vote really, really, really counts,” Gore told the audience assembled in a gym here.\n",
      "Like Gore, Clinton said that the effects of Hurricane Matthew on Florida had been worse because of the ongoing effects of climate change.\n",
      "“Let’s focus on what’s really important in this election,” Clinton told the audience as one of the hecklers was led out of the gym.\n",
      "“Despite all the terrible things he’s said and done, he’s still trying to win this election,” Clinton told the radio audience.\n",
      "Caption:Democratic presidential nominee Hillary Clinton and former vice president Al Gore wave to supporters following a rally at Miami Dade College Kendall Campus on Tuesday in Miami\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0123_213.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.6953915357589722\n",
      "\tDescription: Church of the Holy Sepulchre\n",
      "\n",
      "\tScore      : 0.427700012922287\n",
      "\tDescription: Palestinian Christians\n",
      "\n",
      "\tScore      : 0.4106999635696411\n",
      "\tDescription: Palestine\n",
      "\n",
      "\tScore      : 0.3469739854335785\n",
      "\tDescription: Barbed wire\n",
      "\n",
      "\tScore      : 0.28619998693466187\n",
      "\tDescription: Diplomat\n",
      "\n",
      "\tScore      : 0.2770000100135803\n",
      "\tDescription: Procession\n",
      "\n",
      "\tScore      : 0.27379998564720154\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.27379998564720154\n",
      "\tDescription: Wire\n",
      "\n",
      "\tScore      : 0.25209999084472656\n",
      "\tDescription: Palestinians\n",
      "\n",
      "\tScore      : 0.028878001496195793\n",
      "\tDescription: Jerusalem\n",
      "id : 230, caption: A man smokes a joint at a promarijuana 420 celebration in front of the state Capitol building April 20 2010 in Denver, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0123_213.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Church of the Holy Sepulchre', 'Palestinian Christians', 'Palestine', 'Barbed wire', 'Diplomat', 'Procession', '', 'Wire', 'Palestinians', 'Jerusalem']\n",
      "Original content title image belongs to:“During the day, many delegations were escorted into the Old City, and the police coordinated and prepared ahead of time with no incidents occurring,” he said.\n",
      "“I saw very few of our local people” coming into the Old City, Twal said.\n",
      "“Maybe there were less permits, maybe they came late, or they gave one to the father but not to the mother.”Restricting Palestinians' access to Jerusalem during Holy Week, Twal said, is \"not fair, not just, not religious.\"\n",
      "“The Israelis do not want to show how many Christians are living here and that they are powerful in the Old City.”AdvertisementMaj.\n",
      "Guy Inbar, spokesman for the Israeli military-run authority that oversees the West Bank, said it was not true that fewer permits had been given out this year to Palestinian Christians wanting to visit Jerusalem.\n",
      "Caption:A man smokes a joint at a promarijuana 420 celebration in front of the state Capitol building April 20 2010 in Denver\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0807_258.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.9511795043945312\n",
      "\tDescription: Marine Corps Air Station Futenma (MCAS Futenma)\n",
      "\n",
      "\tScore      : 1.1267850399017334\n",
      "\tDescription: Okinawa Island\n",
      "\n",
      "\tScore      : 0.9860400557518005\n",
      "\tDescription: Kadena Air Base\n",
      "\n",
      "\tScore      : 0.7135000228881836\n",
      "\tDescription: Military base\n",
      "\n",
      "\tScore      : 0.6315000057220459\n",
      "\tDescription: Naval Base Okinawa\n",
      "\n",
      "\tScore      : 0.4661000072956085\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.4424999952316284\n",
      "\tDescription: Military air base\n",
      "\n",
      "\tScore      : 0.4205999970436096\n",
      "\tDescription: Island\n",
      "\n",
      "\tScore      : 0.41679999232292175\n",
      "\tDescription: United States Marine Corps\n",
      "\n",
      "\tScore      : 0.41679999232292175\n",
      "\tDescription: \n",
      "id : 231, caption: The Futenma marine corps airbase on the southern Japanese island of Okinawa, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0807_258.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Marine Corps Air Station Futenma (MCAS Futenma)', 'Okinawa Island', 'Kadena Air Base', 'Military base', 'Naval Base Okinawa', '', 'Military air base', 'Island', 'United States Marine Corps', '']\n",
      "Original content title image belongs to:U.S. Compensates Marine Exposed To Toxic Chemicals In '80sEnlarge this image toggle caption Courtesy of Lt. Col. Kris Roberts Courtesy of Lt. Col. Kris RobertsThe horror of Agent Orange and its effects on Vietnam war veterans and Vietnamese citizens is well-documented.\n",
      "The Japan Times first wrote about Roberts, who served as a facilities maintenance officer at Marine Corps Air Station Futenma in Okinawa, Japan in 1981.\n",
      "Sponsor Message\"We started digging, then we found some barrels,\" Roberts tells All Things Considered guest host Tess Vigeland.\n",
      "In 2007, Roberts filed a claim to the VA concerning exposure to hazardous chemicals.\n",
      "Look what's happening to the people that were affected by these hazardous chemicals.\"\n",
      "Caption:The Futenma marine corps airbase on the southern Japanese island of Okinawa\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0687_264.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 8.5964994430542\n",
      "\tDescription: Simone Biles\n",
      "\n",
      "\tScore      : 0.973349928855896\n",
      "\tDescription: Olympic Games\n",
      "\n",
      "\tScore      : 0.8774700164794922\n",
      "\tDescription: Olympic Games Rio 2016\n",
      "\n",
      "\tScore      : 0.8023500442504883\n",
      "\tDescription: Kōhei Uchimura\n",
      "\n",
      "\tScore      : 0.7591925859451294\n",
      "\tDescription: Artistic gymnastics\n",
      "\n",
      "\tScore      : 0.7474499940872192\n",
      "\tDescription: Al Trautwig\n",
      "\n",
      "\tScore      : 0.6953999996185303\n",
      "\tDescription: Gymnastics\n",
      "\n",
      "\tScore      : 0.5443000197410583\n",
      "\tDescription: Gymnastics at the Summer Olympics – Artistic individual all-around\n",
      "\n",
      "\tScore      : 0.5325999855995178\n",
      "\tDescription: Gymnastics at the Summer Olympics – Men's artistic individual all-around\n",
      "\n",
      "\tScore      : 0.531672477722168\n",
      "\tDescription: Rhythmic gymnastics\n",
      "id : 232, caption: Serena Williams of the US reacts after winning a point against Maria Sharapova of Russia during their women s singles final match at the Australian Open, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0687_264.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Simone Biles', 'Olympic Games', 'Olympic Games Rio 2016', 'Kōhei Uchimura', 'Artistic gymnastics', 'Al Trautwig', 'Gymnastics', 'Gymnastics at the Summer Olympics – Artistic individual all-around', \"Gymnastics at the Summer Olympics – Men's artistic individual all-around\", 'Rhythmic gymnastics']\n",
      "Original content title image belongs to:Erik Brady, and Rachel AxonUSA TODAYRIO DE JANEIRO — Al Trautwig, NBC’s gymnastics announcer at the Rio Games, apologized Monday for suggesting that Simone Biles’ parents through adoption are not really her parents.\n",
      "To set the record straight, Ron and Nellie are Simone’s parents.”Ron and Nellie Biles adopted Simone and her younger sister, Adria, in 2001.\n",
      "The girls had spent time in foster care as Shanon Biles, their biological mother and Ron’s daughter, struggled with drugs and alcohol.\n",
      "Trautwig referred to Ron and Nellie as Biles’ grandparents on Sunday’s NBC primetime broadcast.\n",
      "Everything’s just been so normal.”Axon reported from Rio de JaneiroPHOTOS: GYMNASTICS AT THE RIO OLYMPICS\n",
      "Caption:Serena Williams of the US reacts after winning a point against Maria Sharapova of Russia during their women s singles final match at the Australian Open\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0543_761.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.904999732971191\n",
      "\tDescription: Elizabeth II\n",
      "\n",
      "\tScore      : 0.6707250475883484\n",
      "\tDescription: Buckingham Palace\n",
      "\n",
      "\tScore      : 0.6593999862670898\n",
      "\tDescription: South Africa\n",
      "\n",
      "\tScore      : 0.5105000138282776\n",
      "\tDescription: Apartheid\n",
      "\n",
      "\tScore      : 0.47759997844696045\n",
      "\tDescription: Coronation of Elizabeth II\n",
      "\n",
      "\tScore      : 0.4415999948978424\n",
      "\tDescription: Commonwealth of Nations\n",
      "\n",
      "\tScore      : 0.4138999879360199\n",
      "\tDescription: State visit\n",
      "\n",
      "\tScore      : 0.3327000141143799\n",
      "\tDescription: Queen mother\n",
      "\n",
      "\tScore      : 0.3325999975204468\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.30570000410079956\n",
      "\tDescription: Throne\n",
      "id : 233, caption: Mandela stands with Britain s Queen Elizabeth II on July 9 1996 at Buckingham Palace, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0543_761.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Elizabeth II', 'Buckingham Palace', 'South Africa', 'Apartheid', 'Coronation of Elizabeth II', 'Commonwealth of Nations', 'State visit', 'Queen mother', '', 'Throne']\n",
      "Original content title image belongs to:LONDON — Monarch since age 25, Queen Elizabeth II died at age 96.\n",
      "1970The first royal walkaboutQueen Elizabeth II takes part in a “walkabout” in Sydney with Mayor Emmet McDermott in May 1970.\n",
      "Queen Elizabeth II meets Maori people in New Zealand in 1977.\n",
      "2012London OlympicsOfficials applaud as Queen Elizabeth II arrives during the Opening Ceremonies of the Summer Olympics in London on July 27, 2012.\n",
      "Britain's Queen Elizabeth II sits alone in St. George's Chapel during the funeral of Prince Philip.\n",
      "Caption:Mandela stands with Britain s Queen Elizabeth II on July 9 1996 at Buckingham Palace\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0273_657.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 11.154001235961914\n",
      "\tDescription: Julia Roberts\n",
      "\n",
      "\tScore      : 10.894499778747559\n",
      "\tDescription: George Clooney\n",
      "\n",
      "\tScore      : 1.1617650985717773\n",
      "\tDescription: Ocean's Twelve\n",
      "\n",
      "\tScore      : 0.5462999939918518\n",
      "\tDescription: Actor\n",
      "\n",
      "\tScore      : 0.47540000081062317\n",
      "\tDescription: BAFTA Film Awards\n",
      "\n",
      "\tScore      : 0.3889000117778778\n",
      "\tDescription: Britannia Awards\n",
      "\n",
      "\tScore      : 0.09367499500513077\n",
      "\tDescription: Matt Damon\n",
      "\n",
      "\tScore      : 0.0901000052690506\n",
      "\tDescription: Ocean's\n",
      "\n",
      "\tScore      : 0.08122500032186508\n",
      "\tDescription: Brad Pitt\n",
      "\n",
      "\tScore      : 0.07971000671386719\n",
      "\tDescription: Benedict Cumberbatch\n",
      "id : 234, caption: Clooney leaves the stage after receiving his award with Julia Roberts, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0273_657.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Julia Roberts', 'George Clooney', \"Ocean's Twelve\", 'Actor', 'BAFTA Film Awards', 'Britannia Awards', 'Matt Damon', \"Ocean's\", 'Brad Pitt', 'Benedict Cumberbatch']\n",
      "Original content title image belongs to:Sacha Baron Cohen and director Judd Apatow.\n",
      "Baron Cohen was given the Chaplin award for comedy.\n",
      "He was presented with a Chaplin-esque cane from wheelchair user Grace Colington, introduced as the oldest living actor who worked with Chaplin.\n",
      "Baron Cohen accepted the cane and broke into the Chaplin walk before tripping and knocking Colington off the stage.\n",
      "This is obviously a tragedy, but on the bright side what a great way to go: giving an award to me!,\" said Baron Cohen.\n",
      "Caption:Clooney leaves the stage after receiving his award with Julia Roberts\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0834_222.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.847350001335144\n",
      "\tDescription: Brent oilfield\n",
      "\n",
      "\tScore      : 0.7246000170707703\n",
      "\tDescription: Petroleum\n",
      "\n",
      "\tScore      : 0.7218000292778015\n",
      "\tDescription: North Sea oil\n",
      "\n",
      "\tScore      : 0.717199981212616\n",
      "\tDescription: Petroleum industry\n",
      "\n",
      "\tScore      : 0.7108500003814697\n",
      "\tDescription: North Sea\n",
      "\n",
      "\tScore      : 0.6889500021934509\n",
      "\tDescription: Oil refinery\n",
      "\n",
      "\tScore      : 0.608299970626831\n",
      "\tDescription: Oil platform\n",
      "\n",
      "\tScore      : 0.5978999733924866\n",
      "\tDescription: Oil Field\n",
      "\n",
      "\tScore      : 0.590399980545044\n",
      "\tDescription: Natural gas\n",
      "\n",
      "\tScore      : 0.571399986743927\n",
      "\tDescription: Oil\n",
      "id : 235, caption: North Sea oil rig Oil and gas industry accused energy secretary Ed Davey of making investment in North Sea less attractive, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0834_222.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Brent oilfield', 'Petroleum', 'North Sea oil', 'Petroleum industry', 'North Sea', 'Oil refinery', 'Oil platform', 'Oil Field', 'Natural gas', 'Oil']\n",
      "Original content title image belongs to:Back in the 1970s, North Sea oil and gas were the great hope for the British economy.\n",
      "Britain would be self-sufficient in energy and the revenues from the North Sea would modernise the economy.\n",
      "Getting on for four decades later, North Sea resources are running dry.\n",
      "Lower North Sea oil production is one reason for Britain's weak economic recovery and makes it harder for Osborne to balance the books.\n",
      "The coal mines have closed; the older nuclear power stations are on their last legs; the gush from the North Sea will soon be a mere dribble.\n",
      "Caption:North Sea oil rig Oil and gas industry accused energy secretary Ed Davey of making investment in North Sea less attractive\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0013_761.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.990999221801758\n",
      "\tDescription: Jack Tweed\n",
      "\n",
      "\tScore      : 0.6462000012397766\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5408999919891357\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.5156000256538391\n",
      "\tDescription: Crime\n",
      "\n",
      "\tScore      : 0.487199991941452\n",
      "\tDescription: Rape\n",
      "\n",
      "\tScore      : 0.45614999532699585\n",
      "\tDescription: Taxi\n",
      "\n",
      "\tScore      : 0.3889000117778778\n",
      "\tDescription: Court\n",
      "\n",
      "\tScore      : 0.36059999465942383\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.351500004529953\n",
      "\tDescription: Television\n",
      "\n",
      "\tScore      : 0.32199999690055847\n",
      "\tDescription: Sexual assault\n",
      "id : 236, caption: Giles Coren has said he would go back to Tatler in an eyeblink because they tolerated all my failings, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0013_761.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Jack Tweed', '', 'United Kingdom', 'Crime', 'Rape', 'Taxi', 'Court', '', 'Television', 'Sexual assault']\n",
      "Original content title image belongs to:Jack Tweed, the widower of reality television contestant Jade Goody, has been found not guilty of rape.\n",
      "The 22-year-old and his friend Anthony Davis, 26, were cleared by a jury at Snaresbrook crown court in east London.\n",
      "Tweed, a club promoter, and Davis, a property developer, had pleaded not guilty, contending that they had consensual sex with the 19-year-old student in September last year.\n",
      "Tweed married Goody in February 2009, a month before she died of cancer.\n",
      "Caption:Giles Coren has said he would go back to Tatler in an eyeblink because they tolerated all my failings\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0742_952.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.0950000286102295\n",
      "\tDescription: Ship\n",
      "\n",
      "\tScore      : 0.7607368230819702\n",
      "\tDescription: Ferry\n",
      "\n",
      "\tScore      : 0.6861000061035156\n",
      "\tDescription: Xue Long\n",
      "\n",
      "\tScore      : 0.670799970626831\n",
      "\tDescription: Antarctica\n",
      "\n",
      "\tScore      : 0.6152019500732422\n",
      "\tDescription: Deck\n",
      "\n",
      "\tScore      : 0.5270000100135803\n",
      "\tDescription: Icebreaker\n",
      "\n",
      "\tScore      : 0.4812000095844269\n",
      "\tDescription: Akademik Shokalskiy\n",
      "\n",
      "\tScore      : 0.41821232438087463\n",
      "\tDescription: Motor ship\n",
      "\n",
      "\tScore      : 0.41581934690475464\n",
      "\tDescription: Sea\n",
      "\n",
      "\tScore      : 0.35659998655319214\n",
      "\tDescription: Drift ice\n",
      "id : 237, caption: Rigs drilling a relief well and preparing the static kill are seen at the site of the Deepwater Horizon well in the Gulf of Mexico, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0742_952.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Ship', 'Ferry', 'Xue Long', 'Antarctica', 'Deck', 'Icebreaker', 'Akademik Shokalskiy', 'Motor ship', 'Sea', 'Drift ice']\n",
      "Original content title image belongs to:Expedition co-leaders Chris Fogwill (left), a glaciologist, and Chris Turney, a climate scientist, both at the University of New South Wales.\n",
      "\"It's great to be back on terra firma and back in warm sunshine,\" Turney told the assembled journalists.\n",
      "\"I'd just like to say a huge thanks to all the friends and family out there who have supported us.\n",
      "But particularly the Australian, Chinese, American and French Antarctic groups who have worked so hard to bring us all home safely\"\n",
      "Caption:Rigs drilling a relief well and preparing the static kill are seen at the site of the Deepwater Horizon well in the Gulf of Mexico\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0259_485.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7254999876022339\n",
      "\tDescription: Thanksgiving dinner\n",
      "\n",
      "\tScore      : 0.7236999869346619\n",
      "\tDescription: Thanksgiving\n",
      "\n",
      "\tScore      : 0.7057999968528748\n",
      "\tDescription: Artist\n",
      "\n",
      "\tScore      : 0.5465215444564819\n",
      "\tDescription: Mashed potato\n",
      "\n",
      "\tScore      : 0.46549999713897705\n",
      "\tDescription: Art\n",
      "\n",
      "\tScore      : 0.4572673439979553\n",
      "\tDescription: Dessert\n",
      "\n",
      "\tScore      : 0.4523341953754425\n",
      "\tDescription: Dinner\n",
      "\n",
      "\tScore      : 0.388857364654541\n",
      "\tDescription: Side dish\n",
      "\n",
      "\tScore      : 0.38450363278388977\n",
      "\tDescription: Salad\n",
      "\n",
      "\tScore      : 0.36739999055862427\n",
      "\tDescription: Plate\n",
      "id : 238, caption: a Jasper Johnsb Rene Magrittec Claude Monet, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0259_485.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Thanksgiving dinner', 'Thanksgiving', 'Artist', 'Mashed potato', 'Art', 'Dessert', 'Dinner', 'Side dish', 'Salad', 'Plate']\n",
      "Original content title image belongs to:\n",
      "Caption:a Jasper Johnsb Rene Magrittec Claude Monet\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0413_401.jpg\n",
      "\n",
      "6 Web entities found: \n",
      "\n",
      "\tScore      : 0.4805000126361847\n",
      "\tDescription: official\n",
      "\n",
      "\tScore      : 0.3684000074863434\n",
      "\tDescription: Public speaking\n",
      "\n",
      "\tScore      : 0.31494608521461487\n",
      "\tDescription: Auditorium\n",
      "\n",
      "\tScore      : 0.2890999913215637\n",
      "\tDescription: Speech\n",
      "\n",
      "\tScore      : 0.2574999928474426\n",
      "\tDescription: Public\n",
      "\n",
      "\tScore      : 0.23639999330043793\n",
      "\tDescription: Audience\n",
      "id : 239, caption: Federal Communications Commission Chairman Tom Wheeler speaks during a news conference Thursday at the FCC headquarters in Washington, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0413_401.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['official', 'Public speaking', 'Auditorium', 'Speech', 'Public', 'Audience']\n",
      "Original content title image belongs to:\n",
      "Caption:Federal Communications Commission Chairman Tom Wheeler speaks during a news conference Thursday at the FCC headquarters in Washington\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0697_172.jpg\n",
      "\n",
      "3 Web entities found: \n",
      "\n",
      "\tScore      : 0.3259512782096863\n",
      "\tDescription: Stallion\n",
      "\n",
      "\tScore      : 0.2937000095844269\n",
      "\tDescription: Flat racing\n",
      "\n",
      "\tScore      : 0.27720001339912415\n",
      "\tDescription: Jockey\n",
      "id : 240, caption: Joel Rosario aboard Redwood Kitten leads the pack during race 7, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0697_172.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Stallion', 'Flat racing', 'Jockey']\n",
      "Original content title image belongs to:\n",
      "Caption:Joel Rosario aboard Redwood Kitten leads the pack during race 7\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0680_123.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.8443499803543091\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.6866000294685364\n",
      "\tDescription: Bilibili\n",
      "\n",
      "\tScore      : 0.5629000067710876\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.44279998540878296\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.39329999685287476\n",
      "\tDescription: US President\n",
      "\n",
      "\tScore      : 0.35760000348091125\n",
      "\tDescription: Liberalism\n",
      "\n",
      "\tScore      : 0.3012000024318695\n",
      "\tDescription: Constitution of the United States\n",
      "\n",
      "\tScore      : 0.3001999855041504\n",
      "\tDescription: Danmaku subtitling\n",
      "\n",
      "\tScore      : 0.29649999737739563\n",
      "\tDescription: United States House of Representatives\n",
      "\n",
      "\tScore      : 0.295199990272522\n",
      "\tDescription: \n",
      "id : 241, caption: President Obama delivers the State of the Union address on Tuesday Jan 20 2015 from the House chamber of the United States Capitol, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0680_123.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['United States', 'Bilibili', '', 'United Kingdom', 'US President', 'Liberalism', 'Constitution of the United States', 'Danmaku subtitling', 'United States House of Representatives', '']\n",
      "Original content title image belongs to:\n",
      "Caption:President Obama delivers the State of the Union address on Tuesday Jan 20 2015 from the House chamber of the United States Capitol\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0582_501.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.707000732421875\n",
      "\tDescription: Stephen Curry\n",
      "\n",
      "\tScore      : 7.729499340057373\n",
      "\tDescription: Shaun Livingston\n",
      "\n",
      "\tScore      : 1.0844999551773071\n",
      "\tDescription: Golden State Warriors\n",
      "\n",
      "\tScore      : 1.0631999969482422\n",
      "\tDescription: Memphis Grizzlies\n",
      "\n",
      "\tScore      : 0.8806500434875488\n",
      "\tDescription: NBA\n",
      "\n",
      "\tScore      : 0.7398999929428101\n",
      "\tDescription: Basketball\n",
      "\n",
      "\tScore      : 0.7059999704360962\n",
      "\tDescription: Ball\n",
      "\n",
      "\tScore      : 0.6708999872207642\n",
      "\tDescription: Point guard\n",
      "\n",
      "\tScore      : 0.6512883305549622\n",
      "\tDescription: Basketball Player\n",
      "\n",
      "\tScore      : 0.5871073603630066\n",
      "\tDescription: Basketball moves\n",
      "id : 242, caption: Curry shoots a threepoint basket over DeAndre Jordan of the Los Angeles Clippers on March 23, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0582_501.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Stephen Curry', 'Shaun Livingston', 'Golden State Warriors', 'Memphis Grizzlies', 'NBA', 'Basketball', 'Ball', 'Point guard', 'Basketball Player', 'Basketball moves']\n",
      "Original content title image belongs to:\n",
      "Caption:Curry shoots a threepoint basket over DeAndre Jordan of the Los Angeles Clippers on March 23\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0366_625.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.979000091552734\n",
      "\tDescription: Nigel Farage\n",
      "\n",
      "\tScore      : 7.895999908447266\n",
      "\tDescription: Rustie Lee\n",
      "\n",
      "\tScore      : 6.127500057220459\n",
      "\tDescription: Kanye West\n",
      "\n",
      "\tScore      : 5.953500270843506\n",
      "\tDescription: Mike Read\n",
      "\n",
      "\tScore      : 5.545500755310059\n",
      "\tDescription: Jamie Oliver\n",
      "\n",
      "\tScore      : 0.7250999808311462\n",
      "\tDescription: Marina Hyde\n",
      "\n",
      "\tScore      : 0.6333000063896179\n",
      "\tDescription: Victoria  Farage\n",
      "\n",
      "\tScore      : 0.5996999740600586\n",
      "\tDescription: Annie Leibovitz\n",
      "\n",
      "\tScore      : 0.5691999793052673\n",
      "\tDescription: Celebrity\n",
      "\n",
      "\tScore      : 0.5325999855995178\n",
      "\tDescription: Reform UK\n",
      "id : 243, caption: Nigel Farage with Jamie Oliver Des Lynam Mike Read Rustie Lee and the Beckhams, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0366_625.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Nigel Farage', 'Rustie Lee', 'Kanye West', 'Mike Read', 'Jamie Oliver', 'Marina Hyde', 'Victoria  Farage', 'Annie Leibovitz', 'Celebrity', 'Reform UK']\n",
      "Original content title image belongs to:What term do you want to search?\n",
      "Search with google\n",
      "Caption:Nigel Farage with Jamie Oliver Des Lynam Mike Read Rustie Lee and the Beckhams\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0594_130.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.282999992370605\n",
      "\tDescription: Oscar de la Renta\n",
      "\n",
      "\tScore      : 5.755500316619873\n",
      "\tDescription: Karlie Kloss\n",
      "\n",
      "\tScore      : 0.5386999845504761\n",
      "\tDescription: Fashion\n",
      "\n",
      "\tScore      : 0.4300000071525574\n",
      "\tDescription: 2014\n",
      "\n",
      "\tScore      : 0.39569997787475586\n",
      "\tDescription: The 71st Annual Golden Globe Awards\n",
      "\n",
      "\tScore      : 0.3650999963283539\n",
      "\tDescription: Designer\n",
      "\n",
      "\tScore      : 0.36489999294281006\n",
      "\tDescription: Dress\n",
      "\n",
      "\tScore      : 0.3506999909877777\n",
      "\tDescription: Oscar party\n",
      "\n",
      "\tScore      : 0.33410000801086426\n",
      "\tDescription: 1932\n",
      "\n",
      "\tScore      : 0.3215999901294708\n",
      "\tDescription: Red carpet\n",
      "id : 244, caption: Oscar de la Renta and Barbara Walters attend Woman s Day magazine s Red Dress Awards in New York on Feb 8 2011, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0594_130.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Oscar de la Renta', 'Karlie Kloss', 'Fashion', '2014', 'The 71st Annual Golden Globe Awards', 'Designer', 'Dress', 'Oscar party', '1932', 'Red carpet']\n",
      "Original content title image belongs to:PEOPLEOscar de la Renta: 1932-2014Designer Oscar de la Renta, who gave the world some of its most unforgettable fashions, died Monday.\n",
      "Here, he and model Karlie Kloss, left, walk the runway at the De La Renta fashion show during Fashion Week on Sept. 9, 2014 in New York City.\n",
      "Carolos Ortega, EpaOscar de la Renta and actress Dolores del Rio in New York on May 7, 1981.\n",
      "Michael Stewart, Getty Images For Bloomingdale'sOscar de la Renta and 'Vogue' editor Anna Wintour at the Oscar De La Renta Fall 2009 fashion show during Mercedes-Benz Fashion Week on Feb. 18, 2009 .\n",
      "Charles Sykes, APOprah Winfrey and Oscar de la Renta at the Metropolitan Museum of Art Costume Institute Gala on May 3, 2010 in New York.\n",
      "Caption:Oscar de la Renta and Barbara Walters attend Woman s Day magazine s Red Dress Awards in New York on Feb 8 2011\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0172_535.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.8093085289001465\n",
      "\tDescription: Lahore\n",
      "\n",
      "\tScore      : 0.6686999797821045\n",
      "\tDescription: Cricket World Cup\n",
      "\n",
      "\tScore      : 0.5805000066757202\n",
      "\tDescription: Tea\n",
      "\n",
      "\tScore      : 0.579300045967102\n",
      "\tDescription: Pakistan national cricket team\n",
      "\n",
      "\tScore      : 0.5712000131607056\n",
      "\tDescription: India national cricket team\n",
      "\n",
      "\tScore      : 0.4797999858856201\n",
      "\tDescription: Cricket\n",
      "\n",
      "\tScore      : 0.4401000142097473\n",
      "\tDescription: finished\n",
      "\n",
      "\tScore      : 0.41175001859664917\n",
      "\tDescription: India\n",
      "\n",
      "\tScore      : 0.3806999921798706\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.2892000079154968\n",
      "\tDescription: \n",
      "id : 245, caption: Cuban doctors have helped bring healthcare to rural parts of Venezuela, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0172_535.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Lahore', 'Cricket World Cup', 'Tea', 'Pakistan national cricket team', 'India national cricket team', 'Cricket', 'finished', 'India', '', '']\n",
      "Original content title image belongs to:It was estimated that over a billion people tuned into the Cricket World Cup game between India and Pakistan.\n",
      "Here are the best pictures of those people watching around the globe• India beat Pakistan to launch title defence\n",
      "Caption:Cuban doctors have helped bring healthcare to rural parts of Venezuela\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0279_626.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7907955050468445\n",
      "\tDescription: Kobanî\n",
      "\n",
      "\tScore      : 0.782550036907196\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.7167999744415283\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.6745499968528748\n",
      "\tDescription: Iraq\n",
      "\n",
      "\tScore      : 0.5744999647140503\n",
      "\tDescription: Syrian civil war\n",
      "\n",
      "\tScore      : 0.5217000246047974\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.4558500051498413\n",
      "\tDescription: International military intervention against ISIL\n",
      "\n",
      "\tScore      : 0.4496999979019165\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.43185001611709595\n",
      "\tDescription: Aircraft\n",
      "\n",
      "\tScore      : 0.425849974155426\n",
      "\tDescription: Israel\n",
      "id : 246, caption: A hypersonic aircraft plunges towards the Pacific during a failed US test China has conducted the first flight of its own version the Pentagon has confirmed, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0279_626.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Kobanî', 'United States', '', 'Iraq', 'Syrian civil war', '', 'International military intervention against ISIL', '', 'Aircraft', 'Israel']\n",
      "Original content title image belongs to:The strikes followed the request by Turkey for intensified U.S. efforts to prevent the predominantly Kurdish town, known as Ayn al-Arab in Arabic, from falling to the Islamic State, Turkish officials said.\n",
      "Intensified airstrikes push some Islamic State militants from Kobane + 42 U.S.-led coalition stepped up airstrikes on members of the Islamic State around the Syrian border town.\n",
      "The conversations were \"broadly about the challenges we're facing with ISIL and also Kobane,\" she said, using an alternative acronym for the Islamic State.\n",
      "Islamic State fighters had reached the center of Kobane by mid-morning, he said, but one of the airstrikes hit a convoy of re­inforcements.\n",
      "“These airstrikes are neutralizing their heavy weapons.”Here's a closer look at the countries fighting the Islamic State and what they have to gain by banding together.\n",
      "Caption:A hypersonic aircraft plunges towards the Pacific during a failed US test China has conducted the first flight of its own version the Pentagon has confirmed\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0268_723.jpg\n",
      "id : 247, caption: Game 5 in Chicago Eddie Vedder of the band Pearl Jam sings Take Me Out to the Ball Game during the seventhinning stretch, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0268_723.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:[]\n",
      "Original content title image belongs to:\n",
      "Caption:Game 5 in Chicago Eddie Vedder of the band Pearl Jam sings Take Me Out to the Ball Game during the seventhinning stretch\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0041_796.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.4989500045776367\n",
      "\tDescription: Indonesian mass killings of 1965–66\n",
      "\n",
      "\tScore      : 1.0813499689102173\n",
      "\tDescription: Indonesia\n",
      "\n",
      "\tScore      : 0.7208999991416931\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5026999711990356\n",
      "\tDescription: Massacre\n",
      "\n",
      "\tScore      : 0.4846999943256378\n",
      "\tDescription: 1965\n",
      "\n",
      "\tScore      : 0.4512999951839447\n",
      "\tDescription: Communist Party of Indonesia\n",
      "\n",
      "\tScore      : 0.41280001401901245\n",
      "\tDescription: 1966\n",
      "\n",
      "\tScore      : 0.4002000093460083\n",
      "\tDescription: past\n",
      "\n",
      "\tScore      : 0.3971000015735626\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.3330000042915344\n",
      "\tDescription: \n",
      "id : 248, caption: Protests continued in front of the CVS that was looted and set alight on Monday at the intersection of W North and Pennsylvania avenues, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0041_796.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Indonesian mass killings of 1965–66', 'Indonesia', '', 'Massacre', '1965', 'Communist Party of Indonesia', '1966', 'past', 'Image', '']\n",
      "Original content title image belongs to:On Wednesday, Indonesia’s President Joko Widodo, often referred to as Jokowi, acknowledged the communist purge alongside 11 other “gross human rights violations” that took place in the country between 1965 and 2003.\n",
      "In the hopes of preventing such atrocities from happening again, Jokowi commissioned a report last year on the country’s history of human rights violations.\n",
      "He said he acknowledged the “gross human rights violations” and “strongly regret[s] that those violations occurred”.\n",
      "Other events he referenced include the kidnapping and killings of activists during protests in the 1990s and rights violations in the Papua region.\n",
      "View image in fullscreen President Joko Widodo has acknowledged the ‘gross human rights violations’ in Indonesia’s past.\n",
      "Caption:Protests continued in front of the CVS that was looted and set alight on Monday at the intersection of W North and Pennsylvania avenues\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0507_753.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.9718000292778015\n",
      "\tDescription: Message\n",
      "\n",
      "\tScore      : 0.6606000065803528\n",
      "\tDescription: Telephone\n",
      "\n",
      "\tScore      : 0.5019000172615051\n",
      "\tDescription: Mobile Phone\n",
      "\n",
      "\tScore      : 0.38909998536109924\n",
      "\tDescription: Text messaging\n",
      "\n",
      "\tScore      : 0.3806000053882599\n",
      "\tDescription: Ringtone\n",
      "\n",
      "\tScore      : 0.28459998965263367\n",
      "\tDescription: Telephone call\n",
      "\n",
      "\tScore      : 0.2597000002861023\n",
      "\tDescription: Silence\n",
      "\n",
      "\tScore      : 0.24199999868869781\n",
      "\tDescription: easy\n",
      "\n",
      "\tScore      : 0.21310000121593475\n",
      "\tDescription: Google Contacts\n",
      "\n",
      "\tScore      : 0.20600000023841858\n",
      "\tDescription: Image\n",
      "id : 249, caption: President Obama speaks at the University of Wisconsin at La Crosse earlier this month, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0507_753.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Message', 'Telephone', 'Mobile Phone', 'Text messaging', 'Ringtone', 'Telephone call', 'Silence', 'easy', 'Google Contacts', 'Image']\n",
      "Original content title image belongs to:\n",
      "Caption:President Obama speaks at the University of Wisconsin at La Crosse earlier this month\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0748_419.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.840499877929688\n",
      "\tDescription: Sophie Wilde\n",
      "\n",
      "\tScore      : 0.7174000144004822\n",
      "\tDescription: Father\n",
      "\n",
      "\tScore      : 0.6743000149726868\n",
      "\tDescription: Granddaughter\n",
      "\n",
      "\tScore      : 0.6083999872207642\n",
      "\tDescription: Daughter\n",
      "\n",
      "\tScore      : 0.4486500024795532\n",
      "\tDescription: Sydney\n",
      "\n",
      "\tScore      : 0.3788999915122986\n",
      "\tDescription: Family\n",
      "\n",
      "\tScore      : 0.3788999915122986\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3612000048160553\n",
      "\tDescription: found\n",
      "\n",
      "\tScore      : 0.33629998564720154\n",
      "\tDescription: Son\n",
      "\n",
      "\tScore      : 0.3077999949455261\n",
      "\tDescription: Actor\n",
      "id : 250, caption: Urgent testimony Louise Mai Newberry and Ferdy Roberts in Lampedusa, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0748_419.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Sophie Wilde', 'Father', 'Granddaughter', 'Daughter', 'Sydney', 'Family', '', 'found', 'Son', 'Actor']\n",
      "Original content title image belongs to:A Sydney father and daughter missing for more than a week since an avalanche in Nepal killed at least 40 people are safe and well.\n",
      "Patrick Wilde, the father of Simon and grandfather of 17-year-old Sophie, said the pair had called, bringing the family relief following the huge snowstorm and avalanche which smashed Nepal’s Annapurna region on 14 October.\n",
      "“[Simon] and Sophie are both OK and they’ll be back in Kathmandu and flying home to Australia on Saturday,” Wilde told the ABC.\n",
      "The Wildes originally planning to return to Sydney by 29 October.\n",
      "Several Australians may still be in the region, the Department of Foreign Affairs and Trade (Dfat) said.\n",
      "Caption:Urgent testimony Louise Mai Newberry and Ferdy Roberts in Lampedusa\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0270_439.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.3815000057220459\n",
      "\tDescription: Stadium\n",
      "id : 251, caption: Donors sit down to a chicken dinner and discuss politics while Mitt and Ann Romney talk on stage during a fundraising event at the Beverly Hilton Hotel in Los Angeles, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0270_439.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Stadium']\n",
      "Original content title image belongs to:\n",
      "Caption:Donors sit down to a chicken dinner and discuss politics while Mitt and Ann Romney talk on stage during a fundraising event at the Beverly Hilton Hotel in Los Angeles\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0584_916.jpg\n",
      "\n",
      "3 Web entities found: \n",
      "\n",
      "\tScore      : 0.3313778340816498\n",
      "\tDescription: Night\n",
      "\n",
      "\tScore      : 0.2896000146865845\n",
      "\tDescription: Riot Games\n",
      "\n",
      "\tScore      : 0.2863999903202057\n",
      "\tDescription: Riot Games\n",
      "id : 252, caption: A woman tries to clear protesters in front of a heavy police presence at North and Pennsylvania avenues, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0584_916.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Night', 'Riot Games', 'Riot Games']\n",
      "Original content title image belongs to:\n",
      "Caption:A woman tries to clear protesters in front of a heavy police presence at North and Pennsylvania avenues\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0133_366.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 13.357500076293945\n",
      "\tDescription: Catherine, Princess of Wales\n",
      "\n",
      "\tScore      : 1.055400013923645\n",
      "\tDescription: Wedding of Prince William and Catherine Middleton\n",
      "\n",
      "\tScore      : 0.7648515701293945\n",
      "\tDescription: Wedding\n",
      "\n",
      "\tScore      : 0.7060499787330627\n",
      "\tDescription: Wedding of Prince Harry and Meghan Markle\n",
      "\n",
      "\tScore      : 0.5925999879837036\n",
      "\tDescription: British royal family\n",
      "\n",
      "\tScore      : 0.5017302632331848\n",
      "\tDescription: Wedding Dress\n",
      "\n",
      "\tScore      : 0.46831682324409485\n",
      "\tDescription: Bride\n",
      "\n",
      "\tScore      : 0.37450000643730164\n",
      "\tDescription: The Knot Worldwide\n",
      "\n",
      "\tScore      : 0.3693000078201294\n",
      "\tDescription: Wedding dress of Catherine Middleton\n",
      "\n",
      "\tScore      : 0.3521000146865845\n",
      "\tDescription: Royal family\n",
      "id : 253, caption: Pippa Middleton was the sensational bridesmaid at the royal wedding of sister Kate Middleton to Prince William in 2011, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0133_366.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Catherine, Princess of Wales', 'Wedding of Prince William and Catherine Middleton', 'Wedding', 'Wedding of Prince Harry and Meghan Markle', 'British royal family', 'Wedding Dress', 'Bride', 'The Knot Worldwide', 'Wedding dress of Catherine Middleton', 'Royal family']\n",
      "Original content title image belongs to:The Royal Wedding: A Crowd's-Eye ViewEnlarge this image toggle caption Julian Finney/Getty Images Julian Finney/Getty ImagesI watched the royal wedding processional from behind a woman with a sequined Union Jack cocktail dress, flag-themed sunglasses, high-heeled boots, a flag she wore like a cape, and a plastic cup that she kept clarifying she was filling with vodka schnapps, not vodka.\n",
      "This was the royal wedding as the commoners of London got to see it, live and in person.\n",
      "Also during the ceremony, one of the passing horses dropped an impressive wedding gift in the street right in front of where I was standing.\n",
      "I looked in the glass carriage and saw the Queen of England waving at me.\n",
      "For the kind of person who camps out for a royal wedding, it's an event when you see the Queen.\n",
      "Caption:Pippa Middleton was the sensational bridesmaid at the royal wedding of sister Kate Middleton to Prince William in 2011\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0656_179.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 8.41349983215332\n",
      "\tDescription: Fara Williams\n",
      "\n",
      "\tScore      : 4.837499618530273\n",
      "\tDescription: Mark Getty\n",
      "\n",
      "\tScore      : 2.1939542293548584\n",
      "\tDescription: Emirates Stadium\n",
      "\n",
      "\tScore      : 1.0697999000549316\n",
      "\tDescription: Arsenal W.F.C.\n",
      "\n",
      "\tScore      : 0.9401999711990356\n",
      "\tDescription: Arsenal F.C.\n",
      "\n",
      "\tScore      : 0.7524000406265259\n",
      "\tDescription: Liverpool F.C.\n",
      "\n",
      "\tScore      : 0.6518999934196472\n",
      "\tDescription: Stuart Macfarlane\n",
      "\n",
      "\tScore      : 0.6488000154495239\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.6488000154495239\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5236999988555908\n",
      "\tDescription: Image\n",
      "id : 254, caption: Fara Williams signs for Arsenal Ladies in the company of their manager Pedro Losa, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0656_179.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Fara Williams', 'Mark Getty', 'Emirates Stadium', 'Arsenal W.F.C.', 'Arsenal F.C.', 'Liverpool F.C.', 'Stuart Macfarlane', 'Getty Images', '', 'Image']\n",
      "Original content title image belongs to:Fara Williams has joined Arsenal Ladies from Liverpool.\n",
      "The 31-year-old central midfielder, who with 148 caps is England’s record appearance holder, wrote on Twitter that she had signed for “the next two years”.\n",
      "The transfer comes shortly after the player was awarded an MBE in the New Year Honours list, largely for being central to England finishing third at the 2015 World Cup.\n",
      "“Fara is a great competitor and a fantastic character, too”, the Arsenal manager, Pedro Martínez Losa, told the club’s website.\n",
      "“She is a player with huge experience at club and international level, and her reading and understanding of games is fantastic.”Williams won the FA Women’s Super League with Liverpool in 2013 and 2014, and has played for Chelsea, Charlton and Everton.\n",
      "Caption:Fara Williams signs for Arsenal Ladies in the company of their manager Pedro Losa\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0543_213.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.8144556283950806\n",
      "\tDescription: Brussels Airport\n",
      "\n",
      "\tScore      : 1.5669533014297485\n",
      "\tDescription: Brussels\n",
      "\n",
      "\tScore      : 1.233655571937561\n",
      "\tDescription: Zaventem\n",
      "\n",
      "\tScore      : 0.7402499914169312\n",
      "\tDescription: 2016 Brussels bombings\n",
      "\n",
      "\tScore      : 0.7020999789237976\n",
      "\tDescription: Airport\n",
      "\n",
      "\tScore      : 0.5658000111579895\n",
      "\tDescription: Ibrahim El Bakraoui\n",
      "\n",
      "\tScore      : 0.5462999939918518\n",
      "\tDescription: Khalid El Bakraoui\n",
      "\n",
      "\tScore      : 0.48539999127388\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3984467685222626\n",
      "\tDescription: Airport terminal\n",
      "\n",
      "\tScore      : 0.3612000048160553\n",
      "\tDescription: City\n",
      "id : 255, caption: Procedures for visiting the UK are more complicated than for the rest of Europe Chinese tourists say, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0543_213.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Brussels Airport', 'Brussels', 'Zaventem', '2016 Brussels bombings', 'Airport', 'Ibrahim El Bakraoui', 'Khalid El Bakraoui', '', 'Airport terminal', 'City']\n",
      "Original content title image belongs to:A plane carrying Transportation Security Administration head Peter Neffenger was nosing up to an arrival gate in Brussels on March 22 when the first of two bombs that killed 16 people exploded in the terminal.\n",
      "“Here’s what we do to make sure that that doesn’t happen here,” said Neffenger, who was arriving in Belgium for a security meeting when the bombs went off.\n",
      "“There’s a lot more patrolling of public areas here than I believe was the case in Brussels.\n",
      "Neffenger is having all of the TSA dogs cross-trained so they can work passenger lines.\n",
      "“They are the ones that are designed to walk up and down a security line and detect for explosive vapor wake, and then they trace it back to its source,” he said.\n",
      "Caption:Procedures for visiting the UK are more complicated than for the rest of Europe Chinese tourists say\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0803_530.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.997000694274902\n",
      "\tDescription: Steve Aoki\n",
      "\n",
      "\tScore      : 1.0855499505996704\n",
      "\tDescription: DJ Steve Aoki\n",
      "\n",
      "\tScore      : 0.8189243674278259\n",
      "\tDescription: DJ\n",
      "\n",
      "\tScore      : 0.7060999870300293\n",
      "\tDescription: Electronic dance music\n",
      "\n",
      "\tScore      : 0.616100013256073\n",
      "\tDescription: House music\n",
      "\n",
      "\tScore      : 0.6014000177383423\n",
      "\tDescription: Electronic music\n",
      "\n",
      "\tScore      : 0.5867000222206116\n",
      "\tDescription: DJ Mag\n",
      "\n",
      "\tScore      : 0.5838000178337097\n",
      "\tDescription: Record Producer\n",
      "\n",
      "\tScore      : 0.5475999712944031\n",
      "\tDescription: Crowd surfing\n",
      "\n",
      "\tScore      : 0.4839000105857849\n",
      "\tDescription: Artist\n",
      "id : 256, caption: Steve Aoki who has risen up the Forbes rankings, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0803_530.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Steve Aoki', 'DJ Steve Aoki', 'DJ', 'Electronic dance music', 'House music', 'Electronic music', 'DJ Mag', 'Record Producer', 'Crowd surfing', 'Artist']\n",
      "Original content title image belongs to:According to Aoki, 37, speaking at the Electronic Music Conference in Sydney, his band This Machine Kills was more hardcore than hard house.\n",
      "After his Sydney speech, Aoki tells me that this era was “definitely the punk side of dance music, because it was too noisy for the commercial space.\n",
      "The acronym stands for electronic dance music, but it’s a misnomer because EDM has come to mean a specific dance music subgenre, distinct from other sounds such as techno, minimal house, disco, funk, drum’n’bass.\n",
      "It captures a period of dance music history in which rave culture finally broke through to the American mainstream, after decades of dominance in Europe, Australia and a few local strongholds including California and Detroit.\n",
      "Music purists love to hate EDM.\n",
      "Caption:Steve Aoki who has risen up the Forbes rankings\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0324_862.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 8.914499282836914\n",
      "\tDescription: Adam Boulton\n",
      "\n",
      "\tScore      : 8.671501159667969\n",
      "\tDescription: Mark Austin\n",
      "\n",
      "\tScore      : 6.706500053405762\n",
      "\tDescription: Richard Armitage\n",
      "\n",
      "\tScore      : 1.4349000453948975\n",
      "\tDescription: The News Hour with Mark Austin\n",
      "\n",
      "\tScore      : 0.5648999810218811\n",
      "\tDescription: The Vicar of Dibley\n",
      "\n",
      "\tScore      : 0.4909000098705292\n",
      "\tDescription: Television\n",
      "\n",
      "\tScore      : 0.48980000615119934\n",
      "\tDescription: Leaders' debate\n",
      "\n",
      "\tScore      : 0.4498000144958496\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3982999920845032\n",
      "\tDescription: Debate\n",
      "\n",
      "\tScore      : 0.05785499885678291\n",
      "\tDescription: Nick Clegg\n",
      "id : 257, caption: Cameron makes a point as he debates with Clegg and Brown, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0324_862.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Adam Boulton', 'Mark Austin', 'Richard Armitage', 'The News Hour with Mark Austin', 'The Vicar of Dibley', 'Television', \"Leaders' debate\", '', 'Debate', 'Nick Clegg']\n",
      "Original content title image belongs to:\n",
      "Caption:Cameron makes a point as he debates with Clegg and Brown\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0783_117.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 6.978000640869141\n",
      "\tDescription: Christopher Marlowe\n",
      "\n",
      "\tScore      : 1.465499997138977\n",
      "\tDescription: The Jew of Malta\n",
      "\n",
      "\tScore      : 0.5460000038146973\n",
      "\tDescription: Costume\n",
      "\n",
      "\tScore      : 0.38701191544532776\n",
      "\tDescription: Cosplay\n",
      "\n",
      "\tScore      : 0.3743000030517578\n",
      "\tDescription: Sketch\n",
      "\n",
      "\tScore      : 0.33666619658470154\n",
      "\tDescription: Cape\n",
      "\n",
      "\tScore      : 0.3330000042915344\n",
      "\tDescription: Hat\n",
      "\n",
      "\tScore      : 0.2980000078678131\n",
      "\tDescription: Stitch\n",
      "\n",
      "\tScore      : 0.28850001096725464\n",
      "\tDescription: Royal Shakespeare Company\n",
      "\n",
      "\tScore      : 0.2750000059604645\n",
      "\tDescription: Image\n",
      "id : 258, caption: The Jew of Malta is at the Swan theatre StratforduponAvon until 8 September 2015, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0783_117.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Christopher Marlowe', 'The Jew of Malta', 'Costume', 'Cosplay', 'Sketch', 'Cape', 'Hat', 'Stitch', 'Royal Shakespeare Company', 'Image']\n",
      "Original content title image belongs to:See designer Lily Arnold’s outfits – on page and stage – for the Royal Shakespeare Company’s production of The Jew of Malta by Christopher Marlowe, directed by Justin Audibert\n",
      "Caption:The Jew of Malta is at the Swan theatre StratforduponAvon until 8 September 2015\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0295_973.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.720300018787384\n",
      "\tDescription: Stock photography\n",
      "\n",
      "\tScore      : 0.7174000144004822\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.7174000144004822\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5964999794960022\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.508400022983551\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.4950000047683716\n",
      "\tDescription: Photograph\n",
      "\n",
      "\tScore      : 0.4373999834060669\n",
      "\tDescription: Mitribah\n",
      "\n",
      "\tScore      : 0.3156999945640564\n",
      "\tDescription: hot\n",
      "\n",
      "\tScore      : 0.3043999969959259\n",
      "\tDescription: just\n",
      "\n",
      "\tScore      : 0.24369999766349792\n",
      "\tDescription: create\n",
      "id : 259, caption: Megan Grant 31 cools off in the Jelleff Pool in Northwest Washington, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0295_973.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Stock photography', 'Getty Images', '', 'Image', 'Getty Images', 'Photograph', 'Mitribah', 'hot', 'just', 'create']\n",
      "Original content title image belongs to:Meanwhile, District officials unveiled the city’s Heat Emergency Plan, a set of heat preparations and services.\n",
      "Officials urged residents and those visiting the region to take the heat emergency seriously and to drink plenty of water.\n",
      "Residents should be on the lookout for signs of heat exhaustion or heat stroke, officials said.\n",
      "Montgomery County officials encouraged people to go to libraries, rec and senior centers or regional county service centers to get relief from the heat.\n",
      "The county will be enforcing regulations that bar pet owners from tethering dogs outside during a weather emergency.\n",
      "Caption:Megan Grant 31 cools off in the Jelleff Pool in Northwest Washington\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0563_906.jpg\n",
      "\n",
      "5 Web entities found: \n",
      "\n",
      "\tScore      : 0.48340874910354614\n",
      "\tDescription: Rock concert\n",
      "\n",
      "\tScore      : 0.4302999973297119\n",
      "\tDescription: Concert\n",
      "\n",
      "\tScore      : 0.40939998626708984\n",
      "\tDescription: Rock\n",
      "\n",
      "\tScore      : 0.4057445526123047\n",
      "\tDescription: Musical ensemble\n",
      "\n",
      "\tScore      : 0.2775000035762787\n",
      "\tDescription: 5hy\n",
      "id : 260, caption: Bruce Springsteen and Jon Bon Jovi perform at the 121212 concert at Madison Square Garden to benefit The Robin Hood Relief Fund to aid the survivors of superstorm Sandy, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0563_906.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Rock concert', 'Concert', 'Rock', 'Musical ensemble', '5hy']\n",
      "Original content title image belongs to:\n",
      "Caption:Bruce Springsteen and Jon Bon Jovi perform at the 121212 concert at Madison Square Garden to benefit The Robin Hood Relief Fund to aid the survivors of superstorm Sandy\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0809_800.jpg\n",
      "\n",
      "2 Web entities found: \n",
      "\n",
      "\tScore      : 0.38420000672340393\n",
      "\tDescription: Stadium\n",
      "\n",
      "\tScore      : 0.29761987924575806\n",
      "\tDescription: Team\n",
      "id : 261, caption: Sebastian Giovinco celebrates his goal against DC United, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0809_800.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Stadium', 'Team']\n",
      "Original content title image belongs to:\n",
      "Caption:Sebastian Giovinco celebrates his goal against DC United\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0698_262.jpg\n",
      "\n",
      "2 Web entities found: \n",
      "\n",
      "\tScore      : 0.4830000102519989\n",
      "\tDescription: official\n",
      "\n",
      "\tScore      : 0.3828291594982147\n",
      "\tDescription: Businessperson\n",
      "id : 262, caption: Hockey s transparent manipulation would be a benefit to Australian public debate if it led to the IGR being abandoned once and for all, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0698_262.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['official', 'Businessperson']\n",
      "Original content title image belongs to:\n",
      "Caption:Hockey s transparent manipulation would be a benefit to Australian public debate if it led to the IGR being abandoned once and for all\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0129_685.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.0300500392913818\n",
      "\tDescription: Train\n",
      "\n",
      "\tScore      : 0.7347000241279602\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.7140210270881653\n",
      "\tDescription: Ethiopia\n",
      "\n",
      "\tScore      : 0.666450023651123\n",
      "\tDescription: Rail transport\n",
      "\n",
      "\tScore      : 0.6422680020332336\n",
      "\tDescription: Tanzania-Zambia Railway Authority - TAZARA\n",
      "\n",
      "\tScore      : 0.5679000020027161\n",
      "\tDescription: China\n",
      "\n",
      "\tScore      : 0.5532450079917908\n",
      "\tDescription: Egypt\n",
      "\n",
      "\tScore      : 0.5425499677658081\n",
      "\tDescription: Scramble for Africa\n",
      "\n",
      "\tScore      : 0.5091000199317932\n",
      "\tDescription: Transport\n",
      "\n",
      "\tScore      : 0.503250002861023\n",
      "\tDescription: Bus\n",
      "id : 263, caption: The new Addis Ababa light rail transit system is the first of its kind in subSaharan Africa It will carry 60000 passengers an hour when fully operational, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0129_685.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Train', '', 'Ethiopia', 'Rail transport', 'Tanzania-Zambia Railway Authority - TAZARA', 'China', 'Egypt', 'Scramble for Africa', 'Transport', 'Bus']\n",
      "Original content title image belongs to:In 2014 alone, China signed more than £56bn in construction contracts across Africa.\n",
      "Is this the dawn of a new colonialism, they wonder, a new scramble for Africa in which the continent is once again left in tatters?\n",
      "Now Gau is a career railway adviser for the massive state owned entity, China Railway Construction Corporation Limited (CRCC).\n",
      "But in 1971 his ability to speak English was crucial to a huge railway project planned between Tanzania and Zambia.\n",
      "They would build a railway line from the Tanzanian port city of Dar es Salaam to Kapiri Mposhi, located in Zambia’s copper belt.\n",
      "Caption:The new Addis Ababa light rail transit system is the first of its kind in subSaharan Africa It will carry 60000 passengers an hour when fully operational\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0432_575.jpg\n",
      "\n",
      "5 Web entities found: \n",
      "\n",
      "\tScore      : 0.5603355765342712\n",
      "\tDescription: Wind Turbine\n",
      "\n",
      "\tScore      : 0.4708673357963562\n",
      "\tDescription: Windmill\n",
      "\n",
      "\tScore      : 0.41130000352859497\n",
      "\tDescription: Turbine\n",
      "\n",
      "\tScore      : 0.410092830657959\n",
      "\tDescription: Wind farm\n",
      "\n",
      "\tScore      : 0.3912000060081482\n",
      "\tDescription: Wind\n",
      "id : 264, caption: A view of Walney Offshore Windfarm located 15km west of Cumbria in the Irish Sea, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0432_575.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Wind Turbine', 'Windmill', 'Turbine', 'Wind farm', 'Wind']\n",
      "Original content title image belongs to:\n",
      "Caption:A view of Walney Offshore Windfarm located 15km west of Cumbria in the Irish Sea\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0019_369.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.09784996509552\n",
      "\tDescription: Miami Dolphins\n",
      "\n",
      "\tScore      : 0.9557999968528748\n",
      "\tDescription: Lamar Miller\n",
      "\n",
      "\tScore      : 0.9484500288963318\n",
      "\tDescription: New York Jets\n",
      "\n",
      "\tScore      : 0.9088499546051025\n",
      "\tDescription: NFL\n",
      "\n",
      "\tScore      : 0.8359499573707581\n",
      "\tDescription: Jay Ajayi\n",
      "\n",
      "\tScore      : 0.7336000204086304\n",
      "\tDescription: Running back\n",
      "\n",
      "\tScore      : 0.6933000087738037\n",
      "\tDescription: Defensive tackle\n",
      "\n",
      "\tScore      : 0.661899983882904\n",
      "\tDescription: American football\n",
      "\n",
      "\tScore      : 0.6414999961853027\n",
      "\tDescription: Quarterback\n",
      "\n",
      "\tScore      : 0.6320000290870667\n",
      "\tDescription: Tackle\n",
      "id : 265, caption: Temple running back Ryquell Armstead is tackled by South Florida cornerback Deatrick Nichols during the first quarter, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0019_369.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Miami Dolphins', 'Lamar Miller', 'New York Jets', 'NFL', 'Jay Ajayi', 'Running back', 'Defensive tackle', 'American football', 'Quarterback', 'Tackle']\n",
      "Original content title image belongs to:\n",
      "Caption:Temple running back Ryquell Armstead is tackled by South Florida cornerback Deatrick Nichols during the first quarter\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0338_647.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.969500541687012\n",
      "\tDescription: Peaches Geldof\n",
      "\n",
      "\tScore      : 10.909500122070312\n",
      "\tDescription: Bob Geldof\n",
      "\n",
      "\tScore      : 10.809000015258789\n",
      "\tDescription: Pixie Geldof\n",
      "\n",
      "\tScore      : 0.7017999887466431\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.7017999887466431\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.6121000051498413\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.5644000172615051\n",
      "\tDescription: Photograph\n",
      "\n",
      "\tScore      : 0.5522000193595886\n",
      "\tDescription: Stock photography\n",
      "\n",
      "\tScore      : 0.5486000180244446\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.4661000072956085\n",
      "\tDescription: TV show host\n",
      "id : 266, caption: Peaches Geldof Bob Geldof and Pixie Geldof at Hyde park in London, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0338_647.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Peaches Geldof', 'Bob Geldof', 'Pixie Geldof', 'Getty Images', '', 'Image', 'Photograph', 'Stock photography', 'Getty Images', 'TV show host']\n",
      "Original content title image belongs to:The daughter of Bob Geldof and Paula Yates has been found dead at her home in Kent.\n",
      "Police are treating her death as unexplained.\n",
      "Her final tweet was a picture of her as a toddler with her mother, who died from an accidental overdose in September 2000\n",
      "Caption:Peaches Geldof Bob Geldof and Pixie Geldof at Hyde park in London\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0469_393.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.8068499565124512\n",
      "\tDescription: Michael Eavis\n",
      "\n",
      "\tScore      : 0.7545450329780579\n",
      "\tDescription: Glastonbury Festival 2016\n",
      "\n",
      "\tScore      : 0.7330499887466431\n",
      "\tDescription: Pilton\n",
      "\n",
      "\tScore      : 0.7235250473022461\n",
      "\tDescription: Glastonbury Festival 2017\n",
      "\n",
      "\tScore      : 0.5774000287055969\n",
      "\tDescription: Festival\n",
      "\n",
      "\tScore      : 0.3603000044822693\n",
      "\tDescription: Guide\n",
      "\n",
      "\tScore      : 0.24009999632835388\n",
      "\tDescription: preceding\n",
      "\n",
      "\tScore      : 0.23180000483989716\n",
      "\tDescription: powered\n",
      "\n",
      "\tScore      : 0.21799999475479126\n",
      "\tDescription: Ticket\n",
      "\n",
      "\tScore      : 0.20829999446868896\n",
      "\tDescription: Carnival / M\n",
      "id : 267, caption: Mud bath Tents were washed away from Glastonbury in 2005 but spirits stood firm, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0469_393.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Michael Eavis', 'Glastonbury Festival 2016', 'Pilton', 'Glastonbury Festival 2017', 'Festival', 'Guide', 'preceding', 'powered', 'Ticket', 'Carnival / M']\n",
      "Original content title image belongs to:\n",
      "Caption:Mud bath Tents were washed away from Glastonbury in 2005 but spirits stood firm\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0286_593.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.835000038146973\n",
      "\tDescription: Ethan Couch\n",
      "\n",
      "\tScore      : 0.5501000285148621\n",
      "\tDescription: Probation\n",
      "\n",
      "\tScore      : 0.45225000381469727\n",
      "\tDescription: Tarrant County\n",
      "\n",
      "\tScore      : 0.44350001215934753\n",
      "\tDescription: Affluenza\n",
      "\n",
      "\tScore      : 0.39879998564720154\n",
      "\tDescription: Punishment\n",
      "\n",
      "\tScore      : 0.3921000063419342\n",
      "\tDescription: Trial\n",
      "\n",
      "\tScore      : 0.3328000009059906\n",
      "\tDescription: Sofa\n",
      "\n",
      "\tScore      : 0.32670000195503235\n",
      "\tDescription: Sentence\n",
      "\n",
      "\tScore      : 0.31779998540878296\n",
      "\tDescription: Law\n",
      "\n",
      "\tScore      : 0.31779998540878296\n",
      "\tDescription: \n",
      "id : 268, caption: Sidney Meyers has his hair dyed the colors of the rainbow flag at Andre Richard s salon a block away from the John C Anderson apartments, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0286_593.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Ethan Couch', 'Probation', 'Tarrant County', 'Affluenza', 'Punishment', 'Trial', 'Sofa', 'Sentence', 'Law', '']\n",
      "Original content title image belongs to:Story highlights Ethan Couch served nearly two years in jail for violating probation Couch's defense during 2013 trial used infamous \"affluenza\" argumentCNN —Ethan Couch, known for his “affluenza” defense in his deadly drunk driving case, was released from a Texas jail Monday after serving nearly two years behind bars for violating his probation.\n",
      "Couch, 20, first made headlines as a teenager when he was sentenced to probation for a drunken driving crash that killed four people and seriously injured two others.\n",
      "Prosecutors in that 2013 case sought 20 years in jail, but Couch received no prison time after a psychologist testified that Couch was a victim of “affluenza,” a product of wealthy, privileged parents who never set limits for him.\n",
      "In 2015, Couch violated the terms of his probation and fled to Mexico with his mother, Tonya Couch.\n",
      "They were found and sent back to the US, where a Texas judge ordered nearly two years of jail time for Couch.\n",
      "Caption:Sidney Meyers has his hair dyed the colors of the rainbow flag at Andre Richard s salon a block away from the John C Anderson apartments\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0351_425.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.865999221801758\n",
      "\tDescription: Abi Morgan\n",
      "\n",
      "\tScore      : 6.337500095367432\n",
      "\tDescription: Ralph Fiennes\n",
      "\n",
      "\tScore      : 1.475849986076355\n",
      "\tDescription: The Invisible Woman\n",
      "\n",
      "\tScore      : 0.7003499865531921\n",
      "\tDescription: The Mistress Contract\n",
      "\n",
      "\tScore      : 0.6848000288009644\n",
      "\tDescription: Playwright\n",
      "\n",
      "\tScore      : 0.646049976348877\n",
      "\tDescription: The Royal Court Theatre\n",
      "\n",
      "\tScore      : 0.6087000370025635\n",
      "\tDescription: Splendour\n",
      "\n",
      "\tScore      : 0.5849999785423279\n",
      "\tDescription: Seven Jewish Children\n",
      "\n",
      "\tScore      : 0.3610000014305115\n",
      "\tDescription: Film director\n",
      "\n",
      "\tScore      : 0.06760500371456146\n",
      "\tDescription: Caryl Churchill\n",
      "id : 269, caption: Gouging reaction Danny Webb and Lydia Wilson in Sarah Kane s Blasted, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0351_425.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Abi Morgan', 'Ralph Fiennes', 'The Invisible Woman', 'The Mistress Contract', 'Playwright', 'The Royal Court Theatre', 'Splendour', 'Seven Jewish Children', 'Film director', 'Caryl Churchill']\n",
      "Original content title image belongs to:Seven Jewish Children, Caryl Churchill's 10-minute history of Israel that ends with the bombing of Gaza, caused huge controversy recently.\n",
      "Art that isn't driven by this basic impulse to create an unbalanced view of the world is probably bad or weak.\n",
      "Dickens didn't have a balanced view of the Victorian Poor Laws.\n",
      "Chekhov, the great \"balanced\" artist who wrote about Russia's vanishing upper class, actually saw his characters' decline as comic.\n",
      "Of course, having a strong point of view is no guarantee of great art.\n",
      "Caption:Gouging reaction Danny Webb and Lydia Wilson in Sarah Kane s Blasted\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0538_050.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 5.253000259399414\n",
      "\tDescription: MC Lyte\n",
      "\n",
      "\tScore      : 0.5356500148773193\n",
      "\tDescription: Grammy Awards Ceremony\n",
      "\n",
      "\tScore      : 0.43880000710487366\n",
      "\tDescription: Grammy Awards\n",
      "\n",
      "\tScore      : 0.42800000309944153\n",
      "\tDescription: light-hearted\n",
      "\n",
      "\tScore      : 0.3621000051498413\n",
      "\tDescription: Warner Music Group\n",
      "\n",
      "\tScore      : 0.3621000051498413\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.27410000562667847\n",
      "\tDescription: Model M keyboard\n",
      "\n",
      "\tScore      : 0.26840001344680786\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.26840001344680786\n",
      "\tDescription: USA Today\n",
      "\n",
      "\tScore      : 0.2651999890804291\n",
      "\tDescription: Thought\n",
      "id : 270, caption: Mad woman Teyonah Paris best known for playing Don Draper s secretary plays a woman leading a sex strike to curb gang violence in Chicago in Chiraq, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0538_050.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['MC Lyte', 'Grammy Awards Ceremony', 'Grammy Awards', 'light-hearted', 'Warner Music Group', '', 'Model M keyboard', '', 'USA Today', 'Thought']\n",
      "Original content title image belongs to:LIFE Grammy Awards Add TopicWho went to the Grammy Awards after-parties?\n",
      "Sometimes the after-parties are more fun than the Grammy Awards ceremony.\n",
      "Amanda Edwards, WireImageAnna Kendrick at the Universal Music Group Grammy After Party at Ace Hotel on Feb. 15, 2016, in Los Angeles.\n",
      "Kevin Mazur, WireImageFrankie Grande couldn't contain himself at the Universal Music Group's After Party at The Ace Hotel\\.\n",
      "Allen Berezovsky, WireImageActress/singer Zendaya went to Universal Music Group's After Party.\n",
      "Caption:Mad woman Teyonah Paris best known for playing Don Draper s secretary plays a woman leading a sex strike to curb gang violence in Chicago in Chiraq\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0583_105.jpg\n",
      "\n",
      "3 Web entities found: \n",
      "\n",
      "\tScore      : 0.4401000142097473\n",
      "\tDescription: light-hearted\n",
      "\n",
      "\tScore      : 0.30970001220703125\n",
      "\tDescription: Event\n",
      "\n",
      "\tScore      : 0.28878897428512573\n",
      "\tDescription: Audience\n",
      "id : 271, caption: Republican presidential candidate former Massachusetts governor Mitt Romney greets supporters at a campaign rally at TriCity Christian Academy in Chandler Ariz Wednesday Feb 22 2012, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0583_105.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['light-hearted', 'Event', 'Audience']\n",
      "Original content title image belongs to:\n",
      "Caption:Republican presidential candidate former Massachusetts governor Mitt Romney greets supporters at a campaign rally at TriCity Christian Academy in Chandler Ariz Wednesday Feb 22 2012\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0788_222.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.644591748714447\n",
      "\tDescription: Gaelic football\n",
      "\n",
      "\tScore      : 0.5474804639816284\n",
      "\tDescription: Rugby sevens\n",
      "\n",
      "\tScore      : 0.4769992530345917\n",
      "\tDescription: Rugby league\n",
      "\n",
      "\tScore      : 0.4545676112174988\n",
      "\tDescription: International rules football\n",
      "\n",
      "\tScore      : 0.4293000102043152\n",
      "\tDescription: Rugby football\n",
      "\n",
      "\tScore      : 0.40760448575019836\n",
      "\tDescription: Women's association football\n",
      "\n",
      "\tScore      : 0.390500009059906\n",
      "\tDescription: Stadium\n",
      "\n",
      "\tScore      : 0.3679707646369934\n",
      "\tDescription: Tackle\n",
      "\n",
      "\tScore      : 0.3571999967098236\n",
      "\tDescription: Rugby union\n",
      "\n",
      "\tScore      : 0.3158999979496002\n",
      "\tDescription: Football player\n",
      "id : 272, caption: Beau Scott of the Newcastle Knights tackles Manu Vatuvei of the New Zealand Warriors at Mount Smart Stadium, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0788_222.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Gaelic football', 'Rugby sevens', 'Rugby league', 'International rules football', 'Rugby football', \"Women's association football\", 'Stadium', 'Tackle', 'Rugby union', 'Football player']\n",
      "Original content title image belongs to:\n",
      "Caption:Beau Scott of the Newcastle Knights tackles Manu Vatuvei of the New Zealand Warriors at Mount Smart Stadium\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0489_320.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 13.956001281738281\n",
      "\tDescription: Condoleezza Rice\n",
      "\n",
      "\tScore      : 10.514999389648438\n",
      "\tDescription: Susan Rice\n",
      "\n",
      "\tScore      : 1.054800033569336\n",
      "\tDescription: China Central Television\n",
      "\n",
      "\tScore      : 0.6457499861717224\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.5591999888420105\n",
      "\tDescription: National Security Advisor of the United States\n",
      "\n",
      "\tScore      : 0.527999997138977\n",
      "\tDescription: Television\n",
      "\n",
      "\tScore      : 0.44859999418258667\n",
      "\tDescription: United States Secretary of State\n",
      "\n",
      "\tScore      : 0.43050000071525574\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.41600000858306885\n",
      "\tDescription: US President\n",
      "\n",
      "\tScore      : 0.08449500054121017\n",
      "\tDescription: George W. Bush\n",
      "id : 273, caption: Canada s Miss World contestant Anastasia Lin was barred on Thursday from entering China to take part in this year s pageant, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0489_320.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Condoleezza Rice', 'Susan Rice', 'China Central Television', 'United States', 'National Security Advisor of the United States', 'Television', 'United States Secretary of State', '', 'US President', 'George W. Bush']\n",
      "Original content title image belongs to:China: CCTV mix up Susan and Condoleezza RiceCondoleezza Rice (left) and Susan Rice are not relatedChina's state broadcaster has welcomed visiting US National Security Advisor Susan Rice by mixing her up with near-namesake former Secretary of State Condoleezza Rice, it seems.\n",
      "A report by English-language news channel China Central Television - or CCTV - which reported Susan Rice's arrival had a picture of Condoleezza Rice on the studio screen, the South China Morning Post newspaper reports.\n",
      "A later video on the same subject uploaded on the broadcaster's site on Monday has the correct pictures of Susan Rice.\n",
      "Said to be one of President Barack Obama's closes aides, Susan Rice was appointed US ambassador to the UN after he was first elected.\n",
      "The wrong Rice - Condoleezza Rice's picture on the CCTV reportUse #NewsfromElsewhere to stay up-to-date with our reports via Twitter.\n",
      "Caption:Canada s Miss World contestant Anastasia Lin was barred on Thursday from entering China to take part in this year s pageant\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0339_034.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.1112000942230225\n",
      "\tDescription: Ship\n",
      "\n",
      "\tScore      : 0.720300018787384\n",
      "\tDescription: HMS Endeavour\n",
      "\n",
      "\tScore      : 0.5603400468826294\n",
      "\tDescription: Australian National Maritime Museum\n",
      "\n",
      "\tScore      : 0.4592999815940857\n",
      "\tDescription: Newport\n",
      "\n",
      "\tScore      : 0.41624999046325684\n",
      "\tDescription: Narragansett Bay\n",
      "\n",
      "\tScore      : 0.3653999865055084\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.35676735639572144\n",
      "\tDescription: Ship replica\n",
      "\n",
      "\tScore      : 0.3557297885417938\n",
      "\tDescription: Full-rigged ship\n",
      "\n",
      "\tScore      : 0.3384687006473541\n",
      "\tDescription: Barque\n",
      "\n",
      "\tScore      : 0.3162915110588074\n",
      "\tDescription: Windjammer\n",
      "id : 274, caption: A replica of the Endeavour lies at anchor after it was removed from a sandbar in Botany Bay Sydney, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0339_034.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Ship', 'HMS Endeavour', 'Australian National Maritime Museum', 'Newport', 'Narragansett Bay', '', 'Ship replica', 'Full-rigged ship', 'Barque', 'Windjammer']\n",
      "Original content title image belongs to:Now marine archaeologists believe they've found it off Rhode Island in Newport Harbor.\n",
      "AdvertisementAfter that first voyage, Cook's ship was sold to a private individual and renamed the Lord Sandwich.\n",
      "It was chartered to the British transport service to carry troops during the American Revolution, according to the Rhode Island Marine Archaeology Project.\n",
      "The Rhode Island Marine Archaeology Project said researchers are working to confirm a fifth shipwreck site and determine which ship is located where.\n",
      "Researchers plan to make the announcement at 1o a.m. Wednesday at the Rhode Island Historical Preservation and Heritage Commission in Providence.\n",
      "Caption:A replica of the Endeavour lies at anchor after it was removed from a sandbar in Botany Bay Sydney\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0262_585.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 8.516999244689941\n",
      "\tDescription: Anna Wintour\n",
      "\n",
      "\tScore      : 0.7023651599884033\n",
      "\tDescription: Red carpet\n",
      "\n",
      "\tScore      : 0.625499963760376\n",
      "\tDescription: Natalie Dormer\n",
      "\n",
      "\tScore      : 0.5169000029563904\n",
      "\tDescription: Carpet\n",
      "\n",
      "\tScore      : 0.4848000109195709\n",
      "\tDescription: Celebrity\n",
      "\n",
      "\tScore      : 0.42309999465942383\n",
      "\tDescription: Paparazzi\n",
      "\n",
      "\tScore      : 0.4131999909877777\n",
      "\tDescription: Fashion\n",
      "\n",
      "\tScore      : 0.38910001516342163\n",
      "\tDescription: Lungo\n",
      "\n",
      "\tScore      : 0.33550000190734863\n",
      "\tDescription: Tatler\n",
      "\n",
      "\tScore      : 0.3255999982357025\n",
      "\tDescription: Photography\n",
      "id : 275, caption: Conde Nast Artistic Director Anna Wintour attends the dinner, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0262_585.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Anna Wintour', 'Red carpet', 'Natalie Dormer', 'Carpet', 'Celebrity', 'Paparazzi', 'Fashion', 'Lungo', 'Tatler', 'Photography']\n",
      "Original content title image belongs to:\n",
      "Caption:Conde Nast Artistic Director Anna Wintour attends the dinner\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0375_751.jpg\n",
      "\n",
      "2 Web entities found: \n",
      "\n",
      "\tScore      : 0.4284000098705292\n",
      "\tDescription: light-hearted\n",
      "\n",
      "\tScore      : 0.32015419006347656\n",
      "\tDescription: Infant\n",
      "id : 276, caption: Haley Ulibarri 27 plays with daughter Ripley in the Shangri La Ranch swimming pool on Friday, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0375_751.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['light-hearted', 'Infant']\n",
      "Original content title image belongs to:\n",
      "Caption:Haley Ulibarri 27 plays with daughter Ripley in the Shangri La Ranch swimming pool on Friday\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0203_171.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.295085072517395\n",
      "\tDescription: Clinton Correctional Facility\n",
      "\n",
      "\tScore      : 0.5349000096321106\n",
      "\tDescription: Prisoner\n",
      "\n",
      "\tScore      : 0.5181000232696533\n",
      "\tDescription: Joyce Mitchell\n",
      "\n",
      "\tScore      : 0.44029998779296875\n",
      "\tDescription: jailer\n",
      "\n",
      "\tScore      : 0.428600013256073\n",
      "\tDescription: Fugitive\n",
      "\n",
      "\tScore      : 0.4032999873161316\n",
      "\tDescription: Convict\n",
      "\n",
      "\tScore      : 0.3328999876976013\n",
      "\tDescription: Governor\n",
      "\n",
      "\tScore      : 0.10546500980854034\n",
      "\tDescription: David  Sweat\n",
      "\n",
      "\tScore      : 0.10306500643491745\n",
      "\tDescription: Richard Matt\n",
      "\n",
      "\tScore      : 0.08822999894618988\n",
      "\tDescription: Dannemora\n",
      "id : 277, caption: State corrections officers check vehicles at checkpoint on Monday in Cadyville New York more than two days after convicted murderers escaped from Clinton Correctional Facility, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0203_171.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Clinton Correctional Facility', 'Prisoner', 'Joyce Mitchell', 'jailer', 'Fugitive', 'Convict', 'Governor', 'David  Sweat', 'Richard Matt', 'Dannemora']\n",
      "Original content title image belongs to:Heavily armed police officers, helicopters, dog teams and state troopers driving all-terrain vehicles swarmed to a rural area near the small town of Friendship, Allegany County, New York, at around 5pm.\n",
      "Earlier, reports said the two fugitives who escaped from Clinton Correctional Facility maximum security prison wing in Dannemora, 350 miles north-east of Friendship, had been spotted in the area.\n",
      "Authorities declared it a “credible report” and began massing in the area near Friendship, searching culverts, roads and railway tracks.\n",
      "New York state police and the US Marshall Service have collectively put up $150,000 in rewards for information leading to the men’s capture.\n",
      "The search near Friendship was taking place on the eve of the summer solstice, the longest day of the year, which would assist the authorities with extra daylight.\n",
      "Caption:State corrections officers check vehicles at checkpoint on Monday in Cadyville New York more than two days after convicted murderers escaped from Clinton Correctional Facility\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0198_521.jpg\n",
      "\n",
      "7 Web entities found: \n",
      "\n",
      "\tScore      : 0.45017769932746887\n",
      "\tDescription: Old-growth forest\n",
      "\n",
      "\tScore      : 0.42401620745658875\n",
      "\tDescription: Spruce–fir forests\n",
      "\n",
      "\tScore      : 0.3921999931335449\n",
      "\tDescription: Spruce\n",
      "\n",
      "\tScore      : 0.36660000681877136\n",
      "\tDescription: Fir\n",
      "\n",
      "\tScore      : 0.351500004529953\n",
      "\tDescription: Forest\n",
      "\n",
      "\tScore      : 0.31781110167503357\n",
      "\tDescription: Autumn\n",
      "\n",
      "\tScore      : 0.2777065634727478\n",
      "\tDescription: Sunlight\n",
      "id : 278, caption: Sofia Bulgaria A worker sweeps leaves in a park, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0198_521.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Old-growth forest', 'Spruce–fir forests', 'Spruce', 'Fir', 'Forest', 'Autumn', 'Sunlight']\n",
      "Original content title image belongs to:\n",
      "Caption:Sofia Bulgaria A worker sweeps leaves in a park\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0422_371.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.2728595733642578\n",
      "\tDescription: Massachusetts Institute of Technology\n",
      "\n",
      "\tScore      : 0.7147499918937683\n",
      "\tDescription: Boston Marathon bombings\n",
      "\n",
      "\tScore      : 0.590999960899353\n",
      "\tDescription: Boston Marathon\n",
      "\n",
      "\tScore      : 0.5096520185470581\n",
      "\tDescription: Boston\n",
      "\n",
      "\tScore      : 0.42924749851226807\n",
      "\tDescription: Times Square\n",
      "\n",
      "\tScore      : 0.35830000042915344\n",
      "\tDescription: Tsarnaev family\n",
      "\n",
      "\tScore      : 0.29789999127388\n",
      "\tDescription: identified\n",
      "\n",
      "\tScore      : 0.2651999890804291\n",
      "\tDescription: Cape Cod Times\n",
      "\n",
      "\tScore      : 0.25029999017715454\n",
      "\tDescription: create\n",
      "\n",
      "\tScore      : 0.2402999997138977\n",
      "\tDescription: long\n",
      "id : 279, caption: Members of the MIT community stand during Collier s memorial service, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0422_371.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Massachusetts Institute of Technology', 'Boston Marathon bombings', 'Boston Marathon', 'Boston', 'Times Square', 'Tsarnaev family', 'identified', 'Cape Cod Times', 'create', 'long']\n",
      "Original content title image belongs to:Authorities foiled the alleged plan by engaging Tamerlan Tsarnaev, 26, in a firefight early Friday in which he was killed and a transit police officer was seriously injured.\n",
      "Dzhokhar Tsarnaev, 19, escaped but was subsequently captured hiding in a boat in Watertown, Mass., Friday evening.\n",
      "AdvertisementTamerlan Tsarnaev was killed last week in a confrontation with police.\n",
      "Tamerlan's younger brother Dzhokhar Tsarnaev, who is in custody, has been charged in connection with the bombing and could receive the death penalty.\n",
      "Dzhokhar Tsarnaev is being treated for injuries sustained during the manhunt that led to his apprehension last week, but police have not yet said how exactly he was hurt.\n",
      "Caption:Members of the MIT community stand during Collier s memorial service\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0138_341.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.4323500394821167\n",
      "\tDescription: University Hospital of Wales\n",
      "\n",
      "\tScore      : 0.6033999919891357\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.6033999919891357\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5900999903678894\n",
      "\tDescription: Stock photography\n",
      "\n",
      "\tScore      : 0.5297999978065491\n",
      "\tDescription: Image\n",
      "\n",
      "\tScore      : 0.5102999806404114\n",
      "\tDescription: Getty Images\n",
      "\n",
      "\tScore      : 0.49480000138282776\n",
      "\tDescription: Photograph\n",
      "\n",
      "\tScore      : 0.4477500021457672\n",
      "\tDescription: Mark Getty\n",
      "\n",
      "\tScore      : 0.44609999656677246\n",
      "\tDescription: Hospital\n",
      "\n",
      "\tScore      : 0.4341999888420105\n",
      "\tDescription: Organ\n",
      "id : 280, caption: Outofhours births are to be handled at Raigmore Hospital in Inverness, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0138_341.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['University Hospital of Wales', 'Getty Images', '', 'Stock photography', 'Image', 'Getty Images', 'Photograph', 'Mark Getty', 'Hospital', 'Organ']\n",
      "Original content title image belongs to:\n",
      "Caption:Outofhours births are to be handled at Raigmore Hospital in Inverness\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0532_343.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.559000015258789\n",
      "\tDescription: Debbie Harry\n",
      "\n",
      "\tScore      : 0.9574500322341919\n",
      "\tDescription: Chris Stein / Negative: Me, Blondie, and the Advent of Punk\n",
      "\n",
      "\tScore      : 0.8061000108718872\n",
      "\tDescription: Death of David Bowie\n",
      "\n",
      "\tScore      : 0.7319999933242798\n",
      "\tDescription: Blondie\n",
      "\n",
      "\tScore      : 0.6388000249862671\n",
      "\tDescription: New wave\n",
      "\n",
      "\tScore      : 0.5311999917030334\n",
      "\tDescription: The Idiot\n",
      "\n",
      "\tScore      : 0.4941999912261963\n",
      "\tDescription: Guitarist\n",
      "\n",
      "\tScore      : 0.47589999437332153\n",
      "\tDescription: Photograph\n",
      "\n",
      "\tScore      : 0.47360000014305115\n",
      "\tDescription: famous\n",
      "\n",
      "\tScore      : 0.3944000005722046\n",
      "\tDescription: Aladdin Sane\n",
      "id : 281, caption: Debbie Harry with David Bowie photogrpahed backstage during 1977 s The Idiot tour by Chris Stein of Blondie, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0532_343.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Debbie Harry', 'Chris Stein / Negative: Me, Blondie, and the Advent of Punk', 'Death of David Bowie', 'Blondie', 'New wave', 'The Idiot', 'Guitarist', 'Photograph', 'famous', 'Aladdin Sane']\n",
      "Original content title image belongs to:Main contentDebbie HarryPhotographs from the book Chris Stein / Negative: Me, Blondie, and the Advent of Punk\n",
      "Caption:Debbie Harry with David Bowie photogrpahed backstage during 1977 s The Idiot tour by Chris Stein of Blondie\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0103_379.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 14.692499160766602\n",
      "\tDescription: Paul Goggins\n",
      "\n",
      "\tScore      : 0.49320000410079956\n",
      "\tDescription: Wythenshawe and Sale East\n",
      "\n",
      "\tScore      : 0.4226999878883362\n",
      "\tDescription: Church Times\n",
      "\n",
      "\tScore      : 0.3587999939918518\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3587999939918518\n",
      "\tDescription: Labour Party\n",
      "\n",
      "\tScore      : 0.33320000767707825\n",
      "\tDescription: past\n",
      "\n",
      "\tScore      : 0.3009999990463257\n",
      "\tDescription: Vicar\n",
      "\n",
      "\tScore      : 0.2896000146865845\n",
      "\tDescription: Diocesan Registrar\n",
      "\n",
      "\tScore      : 0.27950000762939453\n",
      "\tDescription: Death\n",
      "\n",
      "\tScore      : 0.2639000117778778\n",
      "\tDescription: St Peter's Hale\n",
      "id : 282, caption: Roger Witcomb of the CMA says that a transitional price cap should be considered, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0103_379.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Paul Goggins', 'Wythenshawe and Sale East', 'Church Times', '', 'Labour Party', 'past', 'Vicar', 'Diocesan Registrar', 'Death', \"St Peter's Hale\"]\n",
      "Original content title image belongs to:\n",
      "Caption:Roger Witcomb of the CMA says that a transitional price cap should be considered\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0585_378.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.8127974271774292\n",
      "\tDescription: Mustang\n",
      "\n",
      "\tScore      : 0.7127865552902222\n",
      "\tDescription: Przewalski's horse\n",
      "\n",
      "\tScore      : 0.5400999784469604\n",
      "\tDescription: Zoo\n",
      "\n",
      "\tScore      : 0.5261347889900208\n",
      "\tDescription: Foal\n",
      "\n",
      "\tScore      : 0.5198000073432922\n",
      "\tDescription: found\n",
      "\n",
      "\tScore      : 0.4761432111263275\n",
      "\tDescription: Stallion\n",
      "\n",
      "\tScore      : 0.47040000557899475\n",
      "\tDescription: Smithsonian National Zoological Park\n",
      "\n",
      "\tScore      : 0.45385363698005676\n",
      "\tDescription: Mare\n",
      "\n",
      "\tScore      : 0.4533741772174835\n",
      "\tDescription: Pony\n",
      "\n",
      "\tScore      : 0.44339999556541443\n",
      "\tDescription: Front Royal\n",
      "id : 283, caption: Young Nubian goats arrived at Fort Hancock in Sandy Hook NJ in July 2013 to help eradicate the infestation of poison ivy in and around the mortar batteries, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0585_378.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Mustang', \"Przewalski's horse\", 'Zoo', 'Foal', 'found', 'Stallion', 'Smithsonian National Zoological Park', 'Mare', 'Pony', 'Front Royal']\n",
      "Original content title image belongs to:\n",
      "Caption:Young Nubian goats arrived at Fort Hancock in Sandy Hook NJ in July 2013 to help eradicate the infestation of poison ivy in and around the mortar batteries\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0394_262.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 6.944999694824219\n",
      "\tDescription: Chencho Gyeltshen\n",
      "\n",
      "\tScore      : 1.0794000625610352\n",
      "\tDescription: Bhutan national football team\n",
      "\n",
      "\tScore      : 0.9193882942199707\n",
      "\tDescription: Changlimithang Football Stadium\n",
      "\n",
      "\tScore      : 0.5938500165939331\n",
      "\tDescription: World Cup\n",
      "\n",
      "\tScore      : 0.5705999732017517\n",
      "\tDescription: Bhutan Football Federation\n",
      "\n",
      "\tScore      : 0.5587000250816345\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5249999761581421\n",
      "\tDescription: Sports in Bhutan\n",
      "\n",
      "\tScore      : 0.4969499707221985\n",
      "\tDescription: Sri Lanka national football team\n",
      "\n",
      "\tScore      : 0.3772999942302704\n",
      "\tDescription: Football club\n",
      "\n",
      "\tScore      : 0.33893635869026184\n",
      "\tDescription: Footballer\n",
      "id : 284, caption: Bhutan s Chencho Gyeltshen right scores one of his two goals in the win over Sri KLanka having struck in the first leg too AFPGetty Images, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0394_262.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Chencho Gyeltshen', 'Bhutan national football team', 'Changlimithang Football Stadium', 'World Cup', 'Bhutan Football Federation', '', 'Sports in Bhutan', 'Sri Lanka national football team', 'Football club', 'Footballer']\n",
      "Original content title image belongs to:\n",
      "Caption:Bhutan s Chencho Gyeltshen right scores one of his two goals in the win over Sri KLanka having struck in the first leg too AFPGetty Images\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0677_018.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.194930076599121\n",
      "\tDescription: 2014 NBA Finals\n",
      "\n",
      "\tScore      : 1.0950000286102295\n",
      "\tDescription: Miami Heat\n",
      "\n",
      "\tScore      : 1.0892999172210693\n",
      "\tDescription: San Antonio Spurs\n",
      "\n",
      "\tScore      : 1.0724999904632568\n",
      "\tDescription: LeBron James\n",
      "\n",
      "\tScore      : 1.059749960899353\n",
      "\tDescription: NBA\n",
      "\n",
      "\tScore      : 0.9325499534606934\n",
      "\tDescription: The 2014 NBA Finals\n",
      "\n",
      "\tScore      : 0.9304499626159668\n",
      "\tDescription: NBA Playoffs\n",
      "\n",
      "\tScore      : 0.9083999991416931\n",
      "\tDescription: Cleveland Cavaliers\n",
      "\n",
      "\tScore      : 0.6712999939918518\n",
      "\tDescription: Basketball\n",
      "\n",
      "\tScore      : 0.6212000250816345\n",
      "\tDescription: \n",
      "id : 285, caption: LeBron James goes up for a rebound in Game 4 of the NBA Finals against the Golden State Warriors, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0677_018.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['2014 NBA Finals', 'Miami Heat', 'San Antonio Spurs', 'LeBron James', 'NBA', 'The 2014 NBA Finals', 'NBA Playoffs', 'Cleveland Cavaliers', 'Basketball', '']\n",
      "Original content title image belongs to:NBA2014 NBA Finals: San Antonio Spurs vs. Miami HeatGame 5 in San Antonio: Spurs 104, Heat 87 -- Tony Parker, center, hoists the Larry O'Brien Trophy to celebrate the Spurs' fifth championship in franchise history.\n",
      "Steve Mitchell, USA TODAY SportsGame 2 in San Antonio: Heat 98, Spurs 96- Miami Heat forward LeBron James (6) is fouled by San Antonio Spurs forward Kawhi Leonard (2).\n",
      "Soobum Im, USA TODAY SportsGame 1 in San Antonio: Spurs 110, Heat 95-Miami Heat forward LeBron James (6) talks to San Antonio Spurs forward Tim Duncan (21).\n",
      "Soobum Im, USA TODAY SportsGame 1 in San Antonio: Spurs 110, Heat 95- San Antonio Spurs guard Manu Ginobili (20) handles the ball against Miami Heat guard Ray Allen (34).\n",
      "Soobum Im, USA TODAY SportsGame 1 in San Antonio: Spurs 110, Heat 95-Miami Heat guard Ray Allen (34) dunks the ball against San Antonio Spurs guard Danny Green (4).\n",
      "Caption:LeBron James goes up for a rebound in Game 4 of the NBA Finals against the Golden State Warriors\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/washington_post_images_0434_703.jpg\n",
      "\n",
      "8 Web entities found: \n",
      "\n",
      "\tScore      : 0.4882500171661377\n",
      "\tDescription: United States\n",
      "\n",
      "\tScore      : 0.4498424828052521\n",
      "\tDescription: Flag of the United States\n",
      "\n",
      "\tScore      : 0.4018000066280365\n",
      "\tDescription: Flag\n",
      "\n",
      "\tScore      : 0.3934493660926819\n",
      "\tDescription: Memorial Day\n",
      "\n",
      "\tScore      : 0.3303122818470001\n",
      "\tDescription: Flag Day\n",
      "\n",
      "\tScore      : 0.3255000114440918\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.32214298844337463\n",
      "\tDescription: Cemetery\n",
      "\n",
      "\tScore      : 0.25450000166893005\n",
      "\tDescription: Memorial\n",
      "id : 286, caption: Flags mementos and pebbles adorn headstones in Section 60 for those killed in Iraq and Afghanistan, \n",
      " image_path: ./sample_300_merged_balanced/washington_post_images_0434_703.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['United States', 'Flag of the United States', 'Flag', 'Memorial Day', 'Flag Day', '', 'Cemetery', 'Memorial']\n",
      "Original content title image belongs to:\n",
      "Caption:Flags mementos and pebbles adorn headstones in Section 60 for those killed in Iraq and Afghanistan\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0247_873.jpg\n",
      "\n",
      "9 Web entities found: \n",
      "\n",
      "\tScore      : 0.5514000058174133\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5369172692298889\n",
      "\tDescription: Army officer\n",
      "\n",
      "\tScore      : 0.4492262005805969\n",
      "\tDescription: Non-commissioned officer\n",
      "\n",
      "\tScore      : 0.3937000036239624\n",
      "\tDescription: opening\n",
      "\n",
      "\tScore      : 0.39304742217063904\n",
      "\tDescription: Soldier\n",
      "\n",
      "\tScore      : 0.3772999942302704\n",
      "\tDescription: Book\n",
      "\n",
      "\tScore      : 0.37389999628067017\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.3513999879360199\n",
      "\tDescription: World war\n",
      "\n",
      "\tScore      : 0.3499000072479248\n",
      "\tDescription: Casualty\n",
      "id : 287, caption: Charles was picked to be secondincommand of the 1st Battalion of the Hampshire Regiment, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0247_873.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['', 'Army officer', 'Non-commissioned officer', 'opening', 'Soldier', 'Book', '', 'World war', 'Casualty']\n",
      "Original content title image belongs to:Hundreds of messages written by servicemen as they made their way to fight in World War One have been published for the first time.\n",
      "Members of the army, navy and Royal Flying Corps often stopped at a now derelict station in Cambridgeshire.\n",
      "Many wrote in visitor books kept in the tea room at Peterborough East railway station between 1916 and 1917.\n",
      "A team of volunteers transcribed the 570 entries which have been published online.\n",
      "Richard Hunt, archives manager for Vivacity, which recruited the volunteers, said the messages provided a \"unique insight\" into the authors' thoughts and feelings.\n",
      "Caption:Charles was picked to be secondincommand of the 1st Battalion of the Hampshire Regiment\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0331_556.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.838699996471405\n",
      "\tDescription: Torrent file\n",
      "\n",
      "\tScore      : 0.6827826499938965\n",
      "\tDescription: Website\n",
      "\n",
      "\tScore      : 0.49070000648498535\n",
      "\tDescription: UKNova\n",
      "\n",
      "\tScore      : 0.47599831223487854\n",
      "\tDescription: Web page\n",
      "\n",
      "\tScore      : 0.4453499913215637\n",
      "\tDescription: United Kingdom\n",
      "\n",
      "\tScore      : 0.4171999990940094\n",
      "\tDescription: BitTorrent\n",
      "\n",
      "\tScore      : 0.3952825367450714\n",
      "\tDescription: Online advertising\n",
      "\n",
      "\tScore      : 0.3919999897480011\n",
      "\tDescription: WebTorrent\n",
      "\n",
      "\tScore      : 0.30713969469070435\n",
      "\tDescription: Screenshot\n",
      "\n",
      "\tScore      : 0.2969000041484833\n",
      "\tDescription: \n",
      "id : 288, caption: The people behind the game describe themselves as an Indonesianborn MexicanAmerican a white woman and an honesttoGod African, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0331_556.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Torrent file', 'Website', 'UKNova', 'Web page', 'United Kingdom', 'BitTorrent', 'Online advertising', 'WebTorrent', 'Screenshot', '']\n",
      "Original content title image belongs to:\n",
      "Caption:The people behind the game describe themselves as an Indonesianborn MexicanAmerican a white woman and an honesttoGod African\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0443_438.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.722000122070312\n",
      "\tDescription: Muammar Gaddafi\n",
      "\n",
      "\tScore      : 1.0639499425888062\n",
      "\tDescription: Libya\n",
      "\n",
      "\tScore      : 0.605400025844574\n",
      "\tDescription: Libyan Army\n",
      "\n",
      "\tScore      : 0.43549999594688416\n",
      "\tDescription: Arms trafficking\n",
      "\n",
      "\tScore      : 0.39466652274131775\n",
      "\tDescription: Infantry\n",
      "\n",
      "\tScore      : 0.38633543252944946\n",
      "\tDescription: Soldier\n",
      "\n",
      "\tScore      : 0.38580000400543213\n",
      "\tDescription: Smuggling\n",
      "\n",
      "\tScore      : 0.3718999922275543\n",
      "\tDescription: Armed forces\n",
      "\n",
      "\tScore      : 0.3122999966144562\n",
      "\tDescription: Libyan Armed Forces\n",
      "\n",
      "\tScore      : 0.3045673966407776\n",
      "\tDescription: Explosive weapon\n",
      "id : 289, caption: Libyan soldiers who have defected against Moammar Gaddafi guard antiaircraft guns Pearson chief executive Majorie Scardino said the situation in Libya was abhorrent, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0443_438.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Muammar Gaddafi', 'Libya', 'Libyan Army', 'Arms trafficking', 'Infantry', 'Soldier', 'Smuggling', 'Armed forces', 'Libyan Armed Forces', 'Explosive weapon']\n",
      "Original content title image belongs to:Which EU countries armed Libya under Gaddafi?\n",
      "The EU arms sales to Libya statistics, collected by the European Union, are not exactly public knowledge.\n",
      "It covers from 2005 (the first year after the end of the arms embargo in 2004) right up to 2009.\n",
      "How does the EU data compare?\n",
      "Data summaryEU arms exports to Libya Value of export licenses granted.\n",
      "Caption:Libyan soldiers who have defected against Moammar Gaddafi guard antiaircraft guns Pearson chief executive Majorie Scardino said the situation in Libya was abhorrent\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/bbc_images_0510_285.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.287200003862381\n",
      "\tDescription: Meter\n",
      "id : 290, caption: There are growing calls for change in India after the gangrape and death of a student in Delhi a month ago, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0510_285.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Meter']\n",
      "Original content title image belongs to:\n",
      "Caption:There are growing calls for change in India after the gangrape and death of a student in Delhi a month ago\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0145_393.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 8.938499450683594\n",
      "\tDescription: Ian Astbury\n",
      "\n",
      "\tScore      : 0.7585999965667725\n",
      "\tDescription: The Cult\n",
      "\n",
      "\tScore      : 0.7021999955177307\n",
      "\tDescription: Musical ensemble\n",
      "\n",
      "\tScore      : 0.7010999917984009\n",
      "\tDescription: Rock\n",
      "\n",
      "\tScore      : 0.5953999757766724\n",
      "\tDescription: Concert\n",
      "\n",
      "\tScore      : 0.5525000095367432\n",
      "\tDescription: Hindley Street Music Hall\n",
      "\n",
      "\tScore      : 0.4862000048160553\n",
      "\tDescription: Hidden City\n",
      "\n",
      "\tScore      : 0.4830999970436096\n",
      "\tDescription: Choice of Weapon\n",
      "\n",
      "\tScore      : 0.4471000134944916\n",
      "\tDescription: DEATH CULT - 8323\n",
      "\n",
      "\tScore      : 0.4438999891281128\n",
      "\tDescription: Hard rock\n",
      "id : 291, caption: The Cult s 2012 incarnation Billy Duffy Chris Wyse Ian Astbury John Tempesta, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0145_393.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Ian Astbury', 'The Cult', 'Musical ensemble', 'Rock', 'Concert', 'Hindley Street Music Hall', 'Hidden City', 'Choice of Weapon', 'DEATH CULT - 8323', 'Hard rock']\n",
      "Original content title image belongs to:No; he admits he has always been content for the Cult to be a medium-sized fish in a big pond.\n",
      "\"I always thought of the Cult as the Fulham of the Premiership,\" says the diehard Manchester City fan.\n",
      "Ian Astbury is one of those.\"\n",
      "Left to right: Billy Duffy, Ian Astbury, Nigel Preston and Jamie Stewart in 1984.\n",
      "\"For Astbury, it's confirmation that the Cult are almost in a position to join the all-time greats at the top table.\n",
      "Caption:The Cult s 2012 incarnation Billy Duffy Chris Wyse Ian Astbury John Tempesta\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0721_053.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.111050009727478\n",
      "\tDescription: 2011 Christchurch earthquake\n",
      "\n",
      "\tScore      : 1.0925999879837036\n",
      "\tDescription: CTV Building\n",
      "\n",
      "\tScore      : 0.8267101645469666\n",
      "\tDescription: Earthquake\n",
      "\n",
      "\tScore      : 0.6760500073432922\n",
      "\tDescription: 2010 Canterbury earthquake\n",
      "\n",
      "\tScore      : 0.6477735042572021\n",
      "\tDescription: Christchurch\n",
      "\n",
      "\tScore      : 0.5583000183105469\n",
      "\tDescription: Canterbury Television\n",
      "\n",
      "\tScore      : 0.35019999742507935\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.33149999380111694\n",
      "\tDescription: 2011\n",
      "\n",
      "\tScore      : 0.2937000095844269\n",
      "\tDescription: Urban search and rescue\n",
      "\n",
      "\tScore      : 0.2874999940395355\n",
      "\tDescription: Building collapse\n",
      "id : 292, caption: The scene of the demolition of street kiosks and stalls near Sokol metro station in Moscow, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0721_053.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['2011 Christchurch earthquake', 'CTV Building', 'Earthquake', '2010 Canterbury earthquake', 'Christchurch', 'Canterbury Television', '', '2011', 'Urban search and rescue', 'Building collapse']\n",
      "Original content title image belongs to:A six-storey building that collapsed and killed 115 people during last year's New Zealand earthquake did not meet construction standards, according to a government report.\n",
      "The Canterbury Television (CTV) building in Christchurch collapsed during the magnitude-6.1 earthquake on 22 February.\n",
      "New Zealand's department of building and housing found in its report that the CTV building did not meet minimum requirements when it was built in 1986 and would fall far short of the latest standards.\n",
      "The report is the first to find construction flaws in a building that collapsed during the earthquake.\n",
      "But the report concluded the additions were insufficient to make the building strong enough.\n",
      "Caption:The scene of the demolition of street kiosks and stalls near Sokol metro station in Moscow\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0544_534.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.9376033544540405\n",
      "\tDescription: Cafe OTO\n",
      "\n",
      "\tScore      : 0.4567500352859497\n",
      "\tDescription: Glasgow\n",
      "\n",
      "\tScore      : 0.4111500084400177\n",
      "\tDescription: Manchester\n",
      "\n",
      "\tScore      : 0.32710000872612\n",
      "\tDescription: University\n",
      "\n",
      "\tScore      : 0.31209999322891235\n",
      "\tDescription: College town\n",
      "\n",
      "\tScore      : 0.2939000129699707\n",
      "\tDescription: Student\n",
      "\n",
      "\tScore      : 0.28610000014305115\n",
      "\tDescription: The Guardian\n",
      "\n",
      "\tScore      : 0.267300009727478\n",
      "\tDescription: good\n",
      "\n",
      "\tScore      : 0.1565255969762802\n",
      "\tDescription: Dalston\n",
      "\n",
      "\tScore      : 0.13744500279426575\n",
      "\tDescription: East London\n",
      "id : 293, caption: There is always something and somewhere new to eat in San Francisco The industrial Dogpatch area is now attracting diners to restaurants like Just for You Cafe, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0544_534.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Cafe OTO', 'Glasgow', 'Manchester', 'University', 'College town', 'Student', 'The Guardian', 'good', 'Dalston', 'East London']\n",
      "Original content title image belongs to:If you’re starting university in a new city this year, it’s important to be open-minded, get out there, and explore what the nightlife has to offer.\n",
      "The freshness and excitement of that time has stuck with me ever since.”Tesfa Williams, aka UK house DJ T Williams, agrees.\n",
      "“Students get sucked in and inspired by the nightlife.”Locals say the city has always had a vibrant and exciting music scene.\n",
      "But it’s not just house music.\n",
      "“There’s a great live music scene as well.\n",
      "Caption:There is always something and somewhere new to eat in San Francisco The industrial Dogpatch area is now attracting diners to restaurants like Just for You Cafe\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/bbc_images_0523_095.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.4980499744415283\n",
      "\tDescription: Burning of Smyrna\n",
      "\n",
      "\tScore      : 1.091399908065796\n",
      "\tDescription: Greco-Turkish War\n",
      "\n",
      "\tScore      : 0.9516000151634216\n",
      "\tDescription: Anatolia\n",
      "\n",
      "\tScore      : 0.8176499605178833\n",
      "\tDescription: İzmir\n",
      "\n",
      "\tScore      : 0.6650999784469604\n",
      "\tDescription: Smyrna\n",
      "\n",
      "\tScore      : 0.5446499586105347\n",
      "\tDescription: Hellenistic period\n",
      "\n",
      "\tScore      : 0.517799973487854\n",
      "\tDescription: Ship\n",
      "\n",
      "\tScore      : 0.474700003862381\n",
      "\tDescription: City\n",
      "\n",
      "\tScore      : 0.47290000319480896\n",
      "\tDescription: Greeks\n",
      "\n",
      "\tScore      : 0.47290000319480896\n",
      "\tDescription: \n",
      "id : 294, caption: Thousands of Greeks living in Izmir fled during the fighting, \n",
      " image_path: ./sample_300_merged_balanced/bbc_images_0523_095.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Burning of Smyrna', 'Greco-Turkish War', 'Anatolia', 'İzmir', 'Smyrna', 'Hellenistic period', 'Ship', 'City', 'Greeks', '']\n",
      "Original content title image belongs to:\n",
      "Caption:Thousands of Greeks living in Izmir fled during the fighting\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0371_781.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 1.214400053024292\n",
      "\tDescription: Hotel Transylvania 2\n",
      "\n",
      "\tScore      : 1.0616999864578247\n",
      "\tDescription: Adam Sandler\n",
      "\n",
      "\tScore      : 0.9274500608444214\n",
      "\tDescription: Mavis Dracula\n",
      "\n",
      "\tScore      : 0.8792999982833862\n",
      "\tDescription: Count Dracula\n",
      "\n",
      "\tScore      : 0.527899980545044\n",
      "\tDescription: Sony Pictures\n",
      "\n",
      "\tScore      : 0.527899980545044\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5128999948501587\n",
      "\tDescription: Children's film\n",
      "\n",
      "\tScore      : 0.5128999948501587\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.5011000037193298\n",
      "\tDescription: Vampire\n",
      "\n",
      "\tScore      : 0.1203015074133873\n",
      "\tDescription: Hotel Transylvania\n",
      "id : 295, caption: Of monsters and men Hotel Transylvania 2 with Adam Sandler, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0371_781.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Hotel Transylvania 2', 'Adam Sandler', 'Mavis Dracula', 'Count Dracula', 'Sony Pictures', '', \"Children's film\", '', 'Vampire', 'Hotel Transylvania']\n",
      "Original content title image belongs to:Animation Hotel Transylvania 2 has topped the US box office, taking $47.5m (£31.3m) in its debut weekend - the biggest September opening of all time.\n",
      "The sequel breaks a record held by its predecessor Hotel Transylvania, which opened to $42.5m in 2012, according to figures from Rentrak.\n",
      "The story of a hotel for monsters, it features the voices of Adam Sandler, Selena Gomez and Mel Brooks.\n",
      "Hotel Transylvania 2's success was attributed to early excitement for Halloween and the film's broad family appeal, with relatively little competition in the kids' market until The Peanuts Movie is released in November.\n",
      "Its $47.5m takings also far exceeded the studio's expectations and industry projections, which were between $32-37m, according to the LA Times, external.\n",
      "Caption:Of monsters and men Hotel Transylvania 2 with Adam Sandler\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/guardian_images_0155_088.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 10.815000534057617\n",
      "\tDescription: Courtney B. Vance\n",
      "\n",
      "\tScore      : 1.0615500211715698\n",
      "\tDescription: American Crime Story\n",
      "\n",
      "\tScore      : 0.9944999814033508\n",
      "\tDescription: The People v. O. J. Simpson: American Crime Story\n",
      "\n",
      "\tScore      : 0.7021999955177307\n",
      "\tDescription: FX\n",
      "\n",
      "\tScore      : 0.5780999660491943\n",
      "\tDescription: Murder trial of O. J. Simpson\n",
      "\n",
      "\tScore      : 0.48899999260902405\n",
      "\tDescription: Television\n",
      "\n",
      "\tScore      : 0.44600000977516174\n",
      "\tDescription: Actor\n",
      "\n",
      "\tScore      : 0.3984000086784363\n",
      "\tDescription: Episode\n",
      "\n",
      "\tScore      : 0.32670000195503235\n",
      "\tDescription: Celebrity\n",
      "\n",
      "\tScore      : 0.10657500475645065\n",
      "\tDescription: Johnnie Cochran\n",
      "id : 296, caption: Idris Elba as Nelson Mandela in Mandela Long Walk to Freedom, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0155_088.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Courtney B. Vance', 'American Crime Story', 'The People v. O. J. Simpson: American Crime Story', 'FX', 'Murder trial of O. J. Simpson', 'Television', 'Actor', 'Episode', 'Celebrity', 'Johnnie Cochran']\n",
      "Original content title image belongs to:Can you imagine the dreamcatcher we could weave from all the nylon locks left over after they finished shooting The People v OJ Simpson?\n",
      "The People v OJ Simpson, for those of you too busy coughing up cat hairs to turn over to BBC1, is a made-for-television drama that explores one of the 20th-century’s most infamous court cases – the trial of American football star and Naked Gun actor OJ Simpson for the murder of his ex-wife, Nicole Brown Simpson, and waiter Ronald Lyle Goldman, in June 1994.\n",
      "As well as a fiesta of lies, counterclaims, corruption and criminal intent, The People v OJ Simpson is, most importantly, a riot of outstandingly unrealistic hair.\n",
      "So allow me to give you the definitive wig-by-wig breakdown of The People v OJ Simpson.\n",
      "The person: Marcia Clark is the prosecuting attorney who embarked on the OJ Simpson case holding all the aces.\n",
      "Caption:Idris Elba as Nelson Mandela in Mandela Long Walk to Freedom\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0233_227.jpg\n",
      "\n",
      "10 Web entities found: \n",
      "\n",
      "\tScore      : 0.7762755751609802\n",
      "\tDescription: The Royal Court Theatre\n",
      "\n",
      "\tScore      : 0.5379000306129456\n",
      "\tDescription: Victoria and Albert Museum\n",
      "\n",
      "\tScore      : 0.5001000165939331\n",
      "\tDescription: Postwar Britain\n",
      "\n",
      "\tScore      : 0.4921000003814697\n",
      "\tDescription: Post-war\n",
      "\n",
      "\tScore      : 0.48100000619888306\n",
      "\tDescription: Theatre\n",
      "\n",
      "\tScore      : 0.48100000619888306\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.44040000438690186\n",
      "\tDescription: Play\n",
      "\n",
      "\tScore      : 0.3474999964237213\n",
      "\tDescription: Theater\n",
      "\n",
      "\tScore      : 0.33000001311302185\n",
      "\tDescription: \n",
      "\n",
      "\tScore      : 0.32829999923706055\n",
      "\tDescription: important\n",
      "id : 297, caption: Max in Bent 1979 Royal Court Theatre 1979, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0233_227.jpg \n",
      " falsified: False\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['The Royal Court Theatre', 'Victoria and Albert Museum', 'Postwar Britain', 'Post-war', 'Theatre', '', 'Play', 'Theater', '', 'important']\n",
      "Original content title image belongs to:A new app from the V&A draws on its remarkable archive to present the 100 most influential postwar British plays.\n",
      "Ten are shown here.\n",
      "Spanning 65 years – from 1945 to 2010 – the app reveals the dramatic changes British theatre has undergone\n",
      "Caption:Max in Bent 1979 Royal Court Theatre 1979\n",
      "Answer:\n",
      "Assistant: not out of context\n",
      "./sample_300_merged_balanced/usa_today_images_0328_386.jpg\n",
      "\n",
      "4 Web entities found: \n",
      "\n",
      "\tScore      : 0.34947335720062256\n",
      "\tDescription: Logo\n",
      "\n",
      "\tScore      : 0.34226271510124207\n",
      "\tDescription: Art\n",
      "\n",
      "\tScore      : 0.33010491728782654\n",
      "\tDescription: Sketch\n",
      "\n",
      "\tScore      : 0.28299999237060547\n",
      "\tDescription: Meter\n",
      "id : 298, caption: Heartbomb print 21439 MSMG farfetchcom, \n",
      " image_path: ./sample_300_merged_balanced/usa_today_images_0328_386.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Logo', 'Art', 'Sketch', 'Meter']\n",
      "Original content title image belongs to:\n",
      "Caption:Heartbomb print 21439 MSMG farfetchcom\n",
      "Answer:\n",
      "Assistant: out of context\n",
      "./sample_300_merged_balanced/guardian_images_0217_703.jpg\n",
      "\n",
      "1 Web entities found: \n",
      "\n",
      "\tScore      : 0.30772873759269714\n",
      "\tDescription: Speech\n",
      "id : 299, caption: It is only a few minutes before you cease to notice they are men Scott Turnbull left and Sean Campion, \n",
      " image_path: ./sample_300_merged_balanced/guardian_images_0217_703.jpg \n",
      " falsified: True\n",
      "User: <image>\n",
      "## Context ##\n",
      "You are provided with:\n",
      "- An image\n",
      "- Web entities of the image\n",
      "-The original content title image belongs to\n",
      "- A caption written by users  \n",
      "\n",
      "\n",
      "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
      "## Objective ##\n",
      "Determine if the caption is used in context with the image.\n",
      "\n",
      "## Response Format ##\n",
      "Respond with **only one** of the following words, without any explanation:  \n",
      "- out of context\n",
      "- not out of context\n",
      "\n",
      "Web entities:['Speech']\n",
      "Original content title image belongs to:\n",
      "Caption:It is only a few minutes before you cease to notice they are men Scott Turnbull left and Sean Campion\n",
      "Answer:\n",
      "Assistant: out of context\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import base64\n",
    "\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from google.cloud import vision\n",
    "\n",
    "tweet = f'The Democrats orchestrated one of the biggest hoaxes in history against @realDonaldTrump and got caught. The Russianhoax and spying on @POTUS is treason by itself.   Is it so inconceivable that they would attempt to steal this Election2020 ? Protect the integrity of the Vote'\n",
    "# Function to encode the image\n",
    "\n",
    "def prepare_prompt(row):\n",
    "    return f\"\"\"\n",
    "      You will be provided with a tweet text and the image. Indicate if the tweet text is relevant or irrelevant to the given image. \n",
    "        Only respond with one of the following words: [relevant, irrelevant]. Do not provide any explanations or additional information.\n",
    "        Tweet Text: {row['text']}\"\"\"\n",
    "    \n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "question = \"\"\"<image>\n",
    "## Context ##\n",
    "You are provided with:\n",
    "- An image\n",
    "- Web entities of the image\n",
    "-The original content title image belongs to\n",
    "- A caption written by users  \n",
    "\n",
    "\n",
    "Your task is to assess whether the caption is relevant the image or is out of context considering the given 1.visual 2.web entities of the image 3.original content title image belongs to\n",
    "## Objective ##\n",
    "Determine if the caption is used in context with the image.\n",
    "\n",
    "## Response Format ##\n",
    "Respond with **only one** of the following words, without any explanation:  \n",
    "- out of context\n",
    "- not out of context\n",
    "\"\"\"\n",
    "image_dir = \"./sample_300_merged_balanced/\"\n",
    "\n",
    "# Open CSV file for writing\n",
    "#image_content_df['intern_vl2_response_title'] = ''\n",
    "#i = 0\n",
    "b=0 \n",
    "csv_file = 'image_caption_analysis_intern_vl_78_2_3_vision.csv'\n",
    "#df = pd.read_csv(csv_file)\n",
    "def detect_news_links(image_path):\n",
    "    \"\"\"Detects web-related information about an image and fetches relevant news articles.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # Read the image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Perform web detection\n",
    "    response = client.web_detection(image=image)\n",
    "    web_detection = response.web_detection\n",
    "\n",
    "\n",
    "    web_entities = []\n",
    "          \n",
    "    if web_detection.web_entities:\n",
    "        print(\"\\n{} Web entities found: \".format(len(web_detection.web_entities)))\n",
    "        for entity in web_detection.web_entities:\n",
    "            print(f\"\\n\\tScore      : {entity.score}\")\n",
    "            print(f\"\\tDescription: {entity.description}\")\n",
    "            web_entities.append(entity.description)\n",
    "\n",
    "    return web_entities\n",
    "    \n",
    "for index1, row in df.iloc[188:].iterrows():\n",
    "                import time\n",
    "                time.sleep(0.2)  # ~200ms\n",
    "                caption = row[\"Caption\"]\n",
    "                image_path = row[\"Image Path\"]\n",
    "                #image_url = row[\"Image URL\"]\n",
    "                summary = \"\" if pd.isna(row[\"News Content Vision\"]) else row[\"News Content Vision\"]\n",
    "                '''\n",
    "                if not pd.isna(image_url) :\n",
    "                    is_similar, score = are_images_similar(image_path, image_url)\n",
    "                    print(score)\n",
    "                    if is_similar:\n",
    "                        title = \"\" if pd.isna(row[\"Title\"]) else row[\"Title\"]\n",
    "                        keywords =  \"\" if pd.isna(row[\"Content Keywords\"]) else row[\"Content Keywords\"]\n",
    "                    else:\n",
    "                        title = \"\"\n",
    "                        keywords = \"\"\n",
    "                else:\n",
    "                    title = \"\"\n",
    "                    keywords = \"\"\n",
    "                '''\n",
    "    \n",
    "                base64_image = encode_image(image_path)\n",
    "            \n",
    "                print(image_path)\n",
    "                news_links = detect_news_links(image_path)\n",
    "                prompt = f\"{question}\\nWeb entities:{news_links}\\nOriginal content title image belongs to:{summary}\\nCaption:{caption}\\nAnswer:\"\n",
    "                # Process image with the model\n",
    "                #pixel_values = load_image(image_path, max_num=12).to(torch.bfloat16).cuda()\n",
    "                #generation_config = dict(max_new_tokens=256, do_sample=False)\n",
    "                falsified = row['falsified_label']\n",
    "                # Generate model response\n",
    "                response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\" : prompt,\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"image_url\",\n",
    "                                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                                },\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                )\n",
    "                \n",
    "                df.at[index1, 'gpt_web_entities_summary_vision_response'] = response.choices[0].message.content\n",
    "\n",
    "                print(f'id : {index1}, caption: {caption}, \\n image_path: {image_path} \\n falsified: {falsified}')\n",
    "                print(f'User: {prompt}\\nAssistant: {response.choices[0].message.content}')\n",
    "                i = i+1\n",
    "\n",
    "output_csv = 'image_caption_analysis_intern_vl_78_2_3_vision.csv'\n",
    "#df.to_csv(output_csv, index=False)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2997e5-889c-4479-8360-ac5cde8bba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = 'image_caption_analysis_intern_vl_78_2_3.csv'\n",
    "df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acd220e-0f3e-45b3-8207-29e83d81702a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 0, caption: Fans dressed in superhero costumes await the arrival of the actors at the premiere of Avengers Age of Ultron in London, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0417_316.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Fans dressed in superhero costumes await the arrival of the actors at the premiere of Avengers Age of Ultron in London\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Fans dressed in superhero costumes await the arrival of the actors at the premiere of Avengers Age of Ultron in London\n",
      "Answer: The caption accurately describes the content of the image, as it depicts fans dressed in superhero costumes waiting for the arrival of the actors at the premiere of Avengers Age of Ultron in London.\n",
      "id : 1, caption: Obama loosens his tie in the heat before he delivers remarks on the economy in Washington, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0319_323.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama loosens his tie in the heat before he delivers remarks on the economy in Washington\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama loosens his tie in the heat before he delivers remarks on the economy in Washington\n",
      "Answer: Out of context\n",
      "id : 2, caption: Michael Turner left could be out for months according to the Sunderland manager Steve Bruce, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0846_690.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Turner left could be out for months according to the Sunderland manager Steve Bruce\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Turner left could be out for months according to the Sunderland manager Steve Bruce\n",
      "Answer: Yes\n",
      "id : 3, caption: Competitors warm up in the main pool ahead of the preliminary races on day two of the 2013 USA Swimming National Championships and World Championship Trials at Indiana University, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0373_719.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Competitors warm up in the main pool ahead of the preliminary races on day two of the 2013 USA Swimming National Championships and World Championship Trials at Indiana University\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Competitors warm up in the main pool ahead of the preliminary races on day two of the 2013 USA Swimming National Championships and World Championship Trials at Indiana University\n",
      "Answer: Out of context\n",
      "id : 4, caption: Traders work on the floor of the New York Stock Exchange at the start of the trading day in New York New York USA 30 June 2016, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0153_447.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Traders work on the floor of the New York Stock Exchange at the start of the trading day in New York New York USA 30 June 2016\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Traders work on the floor of the New York Stock Exchange at the start of the trading day in New York New York USA 30 June 2016\n",
      "Answer: out of context\n",
      "id : 5, caption: Police have conducted an aroundtheclock guard of the embassy in London s Knightsbridge since June 2012, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0031_690.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Police have conducted an aroundtheclock guard of the embassy in London s Knightsbridge since June 2012\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Police have conducted an aroundtheclock guard of the embassy in London s Knightsbridge since June 2012\n",
      "Answer: Out of context\n",
      "id : 6, caption: New Mexico s Alex Kirk right and Cameron Bairstow look on in disbelief during their game against Stanford The seventhseeded Lobos lost 5853 to No 10 Stanford, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0581_315.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:New Mexico s Alex Kirk right and Cameron Bairstow look on in disbelief during their game against Stanford The seventhseeded Lobos lost 5853 to No 10 Stanford\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:New Mexico s Alex Kirk right and Cameron Bairstow look on in disbelief during their game against Stanford The seventhseeded Lobos lost 5853 to No 10 Stanford\n",
      "Answer: out of context\n",
      "id : 7, caption: Google has unveiled the Nexus 7 tablet The internet company faces stiff competition from Apple Microsoft and Amazon, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0313_159.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Google has unveiled the Nexus 7 tablet The internet company faces stiff competition from Apple Microsoft and Amazon\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Google has unveiled the Nexus 7 tablet The internet company faces stiff competition from Apple Microsoft and Amazon\n",
      "Answer: Yes\n",
      "id : 8, caption: A capital chap Jim Broadbent and Samantha Spiro in Patrick Barlow s adaptation of A Christmas Carol, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0149_606.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A capital chap Jim Broadbent and Samantha Spiro in Patrick Barlow s adaptation of A Christmas Carol\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A capital chap Jim Broadbent and Samantha Spiro in Patrick Barlow s adaptation of A Christmas Carol\n",
      "Answer: Out of context\n",
      "id : 9, caption: Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0572_059.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA\n",
      "Answer: Out of context\n",
      "id : 10, caption: Baroque turns of phrase Russell Kane at the 2013 Edinburgh festival fringe, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0772_597.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Baroque turns of phrase Russell Kane at the 2013 Edinburgh festival fringe\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Baroque turns of phrase Russell Kane at the 2013 Edinburgh festival fringe\n",
      "Answer: Not out of context\n",
      "id : 11, caption: People visit the Vietnam Memorial Wall on the National Mall on Veterans Day Nov 11 2015 in Washington DC, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0316_704.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People visit the Vietnam Memorial Wall on the National Mall on Veterans Day Nov 11 2015 in Washington DC\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People visit the Vietnam Memorial Wall on the National Mall on Veterans Day Nov 11 2015 in Washington DC\n",
      "Answer: Out of context\n",
      "id : 12, caption: The technology was on show at William Hill s lab in Shoreditch, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0639_209.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The technology was on show at William Hill s lab in Shoreditch\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The technology was on show at William Hill s lab in Shoreditch\n",
      "Answer: Out of context\n",
      "id : 13, caption: Balenciaga s anorak Stella McCartney s quilted coat and a Givenchy leopardprint donkey jacket on the catwalk at Paris fashion week, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0333_724.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Balenciaga s anorak Stella McCartney s quilted coat and a Givenchy leopardprint donkey jacket on the catwalk at Paris fashion week\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Balenciaga s anorak Stella McCartney s quilted coat and a Givenchy leopardprint donkey jacket on the catwalk at Paris fashion week\n",
      "Answer: out of context\n",
      "id : 14, caption: Bradley Wiggins lives in Lancashire but he ll be relishing the opportunity to compete across the border, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0610_258.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bradley Wiggins lives in Lancashire but he ll be relishing the opportunity to compete across the border\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bradley Wiggins lives in Lancashire but he ll be relishing the opportunity to compete across the border\n",
      "Answer: Out of context\n",
      "id : 15, caption: Sharonda ColemanSingleton and her son Chris at Goose Creek High School where she taught ColemanSingleton was killed Wednesday in a shooting at Emanuel AME Church in Charleston SC, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0639_614.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sharonda ColemanSingleton and her son Chris at Goose Creek High School where she taught ColemanSingleton was killed Wednesday in a shooting at Emanuel AME Church in Charleston SC\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sharonda ColemanSingleton and her son Chris at Goose Creek High School where she taught ColemanSingleton was killed Wednesday in a shooting at Emanuel AME Church in Charleston SC\n",
      "Answer: out of context\n",
      "id : 16, caption: In Peterborough UKIP gains meant the Conservatives lost overall control, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0493_336.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:In Peterborough UKIP gains meant the Conservatives lost overall control\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:In Peterborough UKIP gains meant the Conservatives lost overall control\n",
      "Answer: Out of context\n",
      "id : 17, caption: Sheeran is currently on a tour of Canada and North America, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0192_363.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sheeran is currently on a tour of Canada and North America\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sheeran is currently on a tour of Canada and North America\n",
      "Answer: Yes, Sheeran is currently on a tour of Canada and North America.\n",
      "id : 18, caption: Old portraits of ancestors Bungo Padi left and Reno Urai right of Datuk Basa nan Tinggi, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0203_021.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Old portraits of ancestors Bungo Padi left and Reno Urai right of Datuk Basa nan Tinggi\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Old portraits of ancestors Bungo Padi left and Reno Urai right of Datuk Basa nan Tinggi\n",
      "Answer: Out of context\n",
      "id : 19, caption: Warner Bros said audiences for Magic Mike XXL were 96 female, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0822_940.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Warner Bros said audiences for Magic Mike XXL were 96 female\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Warner Bros said audiences for Magic Mike XXL were 96 female\n",
      "Answer: Yes\n",
      "id : 20, caption: Pete Miller from Minong Wis looks through a cave opening with his dog on Feb 14 2014, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0459_806.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Pete Miller from Minong Wis looks through a cave opening with his dog on Feb 14 2014\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Pete Miller from Minong Wis looks through a cave opening with his dog on Feb 14 2014\n",
      "Answer: Out of context\n",
      "id : 21, caption: Richard Colton drove the 1967 Ferrari around Europe and it has 78000 miles on the clock, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0217_543.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Richard Colton drove the 1967 Ferrari around Europe and it has 78000 miles on the clock\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Richard Colton drove the 1967 Ferrari around Europe and it has 78000 miles on the clock\n",
      "Answer: Yes, the caption accurately describes the content of the image. Richard Colton drove the 1967 Ferrari around Europe and it has 78000 miles on the clock.\n",
      "id : 22, caption: Christina Milian teamed up with Lil Wayne, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0180_802.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Christina Milian teamed up with Lil Wayne\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Christina Milian teamed up with Lil Wayne\n",
      "Answer: Yes\n",
      "id : 23, caption: Shanghai China A visitor uses a tablet computer to photograph cherry blossoms at a park See more images from cherry blossom season in our gallery, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0133_206.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Shanghai China A visitor uses a tablet computer to photograph cherry blossoms at a park See more images from cherry blossom season in our gallery\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Shanghai China A visitor uses a tablet computer to photograph cherry blossoms at a park See more images from cherry blossom season in our gallery\n",
      "Answer: The caption accurately describes the content of the image, as it depicts a visitor using a tablet computer to photograph cherry blossoms at a park in Shanghai, China.\n",
      "id : 24, caption: Ferguson Mayor James Knowles speaks with resident Juanita Stone after a town hall meeting with local government officials and residents on Tuesday at Our Lady of Guadalupe in Ferguson Mo, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0389_346.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ferguson Mayor James Knowles speaks with resident Juanita Stone after a town hall meeting with local government officials and residents on Tuesday at Our Lady of Guadalupe in Ferguson Mo\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ferguson Mayor James Knowles speaks with resident Juanita Stone after a town hall meeting with local government officials and residents on Tuesday at Our Lady of Guadalupe in Ferguson Mo\n",
      "Answer: Out of context\n",
      "id : 25, caption: Steven Pienaar jinks around Ozil and is brought down No goals but a tasty match nonetheless Halftime 00, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0337_251.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Steven Pienaar jinks around Ozil and is brought down No goals but a tasty match nonetheless Halftime 00\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Steven Pienaar jinks around Ozil and is brought down No goals but a tasty match nonetheless Halftime 00\n",
      "Answer: Yes\n",
      "id : 26, caption: RBS and NatWest customers will get further facilities at 11500 post offices, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0054_159.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:RBS and NatWest customers will get further facilities at 11500 post offices\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:RBS and NatWest customers will get further facilities at 11500 post offices\n",
      "Answer: Yes\n",
      "id : 27, caption: The LisbonDublin Aer Lingus flight was diverted to Cork after a man reportedly bit another passenger and had to be restrained, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0123_811.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The LisbonDublin Aer Lingus flight was diverted to Cork after a man reportedly bit another passenger and had to be restrained\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The LisbonDublin Aer Lingus flight was diverted to Cork after a man reportedly bit another passenger and had to be restrained\n",
      "Answer: Yes\n",
      "id : 28, caption: The conservator was working on Coliseum by Daylight when he discovered literature that showed the museum was meant to hold two paintings of the Coliseum by Wright, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0093_117.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The conservator was working on Coliseum by Daylight when he discovered literature that showed the museum was meant to hold two paintings of the Coliseum by Wright\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The conservator was working on Coliseum by Daylight when he discovered literature that showed the museum was meant to hold two paintings of the Coliseum by Wright\n",
      "Answer: Out of context\n",
      "id : 29, caption: Metal Gear Solid the series updates to 3D for the PlayStation generation, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0390_389.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Metal Gear Solid the series updates to 3D for the PlayStation generation\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Metal Gear Solid the series updates to 3D for the PlayStation generation\n",
      "Answer: Yes, the caption accurately describes the content of the image. The image depicts a scene from the video game Metal Gear Solid, which has been updated to 3D for the PlayStation generation.\n",
      "id : 30, caption: The attack took place near Findon at about 2040 BST on Thursday, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0015_675.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The attack took place near Findon at about 2040 BST on Thursday\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The attack took place near Findon at about 2040 BST on Thursday\n",
      "Answer: The attack took place near Findon at about 2040 BST on Thursday.\n",
      "id : 31, caption: The women of the Juna Akhara now have their own space and facilities at the Kumbh Mela, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0155_422.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The women of the Juna Akhara now have their own space and facilities at the Kumbh Mela\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The women of the Juna Akhara now have their own space and facilities at the Kumbh Mela\n",
      "Answer: Out of context\n",
      "id : 32, caption: Tunisia s midfielder Mohammed Ali Moncer celebrates after scoring a goal against Cape Verde during the 2015 Africa Cup of Nations, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0780_163.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tunisia s midfielder Mohammed Ali Moncer celebrates after scoring a goal against Cape Verde during the 2015 Africa Cup of Nations\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tunisia s midfielder Mohammed Ali Moncer celebrates after scoring a goal against Cape Verde during the 2015 Africa Cup of Nations\n",
      "Answer: out of context\n",
      "id : 33, caption: An unpainted soontobe Oman Air Boeing 737 lands at Boeing Field in Seattle in February 2015, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0531_721.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:An unpainted soontobe Oman Air Boeing 737 lands at Boeing Field in Seattle in February 2015\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:An unpainted soontobe Oman Air Boeing 737 lands at Boeing Field in Seattle in February 2015\n",
      "Answer: out of context\n",
      "id : 34, caption: A waterdumping helicopter flies over a fire at Chum Creek Healseville northeast of Melbourne, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0643_970.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A waterdumping helicopter flies over a fire at Chum Creek Healseville northeast of Melbourne\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A waterdumping helicopter flies over a fire at Chum Creek Healseville northeast of Melbourne\n",
      "Answer: The caption accurately describes the content of the image, as it depicts a waterdumping helicopter flying over a fire at Chum Creek Healesville, northeast of Melbourne.\n",
      "id : 35, caption: Obama s appearance in Florida capped eight days in which the he and Romney have been vying for the Latino vote, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0619_574.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama s appearance in Florida capped eight days in which the he and Romney have been vying for the Latino vote\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama s appearance in Florida capped eight days in which the he and Romney have been vying for the Latino vote\n",
      "Answer: yes\n",
      "id : 36, caption: Republican Kentucky gubernatorial candidate Matt Bevin, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0641_671.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Republican Kentucky gubernatorial candidate Matt Bevin\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Republican Kentucky gubernatorial candidate Matt Bevin\n",
      "Answer: Yes\n",
      "id : 37, caption: Antonio Brown 27 Best known for Playing wide receiver and punt returner for the Pittsburgh Steelers Pro partner Sharna Burgess, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0585_554.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Antonio Brown 27 Best known for Playing wide receiver and punt returner for the Pittsburgh Steelers Pro partner Sharna Burgess\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Antonio Brown 27 Best known for Playing wide receiver and punt returner for the Pittsburgh Steelers Pro partner Sharna Burgess\n",
      "Answer: out of context\n",
      "id : 38, caption: Republican presidential candidate former Massachusetts Gov Mitt Romney, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0703_635.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Republican presidential candidate former Massachusetts Gov Mitt Romney\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Republican presidential candidate former Massachusetts Gov Mitt Romney\n",
      "Answer: yes\n",
      "id : 39, caption: The decision to eject Hazem Abu Ismail left Omar Suleiman center and Khairat elShater right upends first postMubarak presidential contest just weeks before the vote, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0259_414.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The decision to eject Hazem Abu Ismail left Omar Suleiman center and Khairat elShater right upends first postMubarak presidential contest just weeks before the vote\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The decision to eject Hazem Abu Ismail left Omar Suleiman center and Khairat elShater right upends first postMubarak presidential contest just weeks before the vote\n",
      "Answer: out of context\n",
      "id : 40, caption: Brendan Marrocco 26 was treated by surgeons WP Andrew Lee left Jamie Shores Patrick L Basile and Gerald Brandacher at Johns Hopkins Hospital in Baltimore, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0428_528.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brendan Marrocco 26 was treated by surgeons WP Andrew Lee left Jamie Shores Patrick L Basile and Gerald Brandacher at Johns Hopkins Hospital in Baltimore\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brendan Marrocco 26 was treated by surgeons WP Andrew Lee left Jamie Shores Patrick L Basile and Gerald Brandacher at Johns Hopkins Hospital in Baltimore\n",
      "Answer: out of context\n",
      "id : 41, caption: The truce saw soldiers all along the Western Front put down their guns to play football in No Man s Land during World War One, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0350_923.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The truce saw soldiers all along the Western Front put down their guns to play football in No Man s Land during World War One\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The truce saw soldiers all along the Western Front put down their guns to play football in No Man s Land during World War One\n",
      "Answer: The caption accurately describes the content of the image.\n",
      "id : 42, caption: Southampton v Tottenham Hotspur probable starters in bold contenders in light, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0128_648.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Southampton v Tottenham Hotspur probable starters in bold contenders in light\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Southampton v Tottenham Hotspur probable starters in bold contenders in light\n",
      "Answer: Yes\n",
      "id : 43, caption: Caught out fisherman Abu Nayim with his son Khaled and baby grandson Mohammed, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0736_838.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Caught out fisherman Abu Nayim with his son Khaled and baby grandson Mohammed\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Caught out fisherman Abu Nayim with his son Khaled and baby grandson Mohammed\n",
      "Answer: Out of context\n",
      "id : 44, caption: Alex Ferguson looks happy with the progress of the European team He gave them a pretournament pep talk and the players seem to be benefiting from his wisdom this afternoon, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0007_869.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Alex Ferguson looks happy with the progress of the European team He gave them a pretournament pep talk and the players seem to be benefiting from his wisdom this afternoon\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Alex Ferguson looks happy with the progress of the European team He gave them a pretournament pep talk and the players seem to be benefiting from his wisdom this afternoon\n",
      "Answer: Out of context\n",
      "id : 45, caption: Prince William in New Zealand touring areas devastated by the earthquake, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0118_614.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Prince William in New Zealand touring areas devastated by the earthquake\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Prince William in New Zealand touring areas devastated by the earthquake\n",
      "Answer: Out of context\n",
      "id : 46, caption: This building used to be in another country an office in east Berlin s tech district sums up the changes the city has undergone, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0691_797.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:This building used to be in another country an office in east Berlin s tech district sums up the changes the city has undergone\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:This building used to be in another country an office in east Berlin s tech district sums up the changes the city has undergone\n",
      "Answer: out of context\n",
      "id : 47, caption: Blood on the Spinifex by Timmy Timms The Mistake Creek Massacre ochres on linen, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0107_415.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Blood on the Spinifex by Timmy Timms The Mistake Creek Massacre ochres on linen\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Blood on the Spinifex by Timmy Timms The Mistake Creek Massacre ochres on linen\n",
      "Answer: Yes\n",
      "id : 48, caption: Stephen Mitchell joined Northumbria police in 1998 the court heard, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0391_215.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Mitchell joined Northumbria police in 1998 the court heard\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Mitchell joined Northumbria police in 1998 the court heard\n",
      "Answer: Yes\n",
      "id : 49, caption: Cardinals catcher Yadier Molina hits a RBI single against the Red Sox in the first inning at Busch Stadium, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0629_581.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cardinals catcher Yadier Molina hits a RBI single against the Red Sox in the first inning at Busch Stadium\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cardinals catcher Yadier Molina hits a RBI single against the Red Sox in the first inning at Busch Stadium\n",
      "Answer: out of context\n",
      "id : 50, caption: So how does the collaboration work Julia writes the stories first and then Axel spends time developing the illustration of the characters then he develops more detailed drafts and sketches, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0076_588.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:So how does the collaboration work Julia writes the stories first and then Axel spends time developing the illustration of the characters then he develops more detailed drafts and sketches\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:So how does the collaboration work Julia writes the stories first and then Axel spends time developing the illustration of the characters then he develops more detailed drafts and sketches\n",
      "Answer: Out of context\n",
      "id : 51, caption: A letter written July 4 1863 by John Winn Moseley after he was wounded and captured in the Battle of Gettysburg, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0198_623.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A letter written July 4 1863 by John Winn Moseley after he was wounded and captured in the Battle of Gettysburg\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A letter written July 4 1863 by John Winn Moseley after he was wounded and captured in the Battle of Gettysburg\n",
      "Answer: Yes\n",
      "id : 52, caption: James barrels through the Charlotte defense during the second half, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0412_559.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:James barrels through the Charlotte defense during the second half\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:James barrels through the Charlotte defense during the second half\n",
      "Answer: out of context\n",
      "id : 53, caption: The Kurdish YPG militia in Syria is well known for its large numbers of female fighters, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0422_887.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Kurdish YPG militia in Syria is well known for its large numbers of female fighters\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Kurdish YPG militia in Syria is well known for its large numbers of female fighters\n",
      "Answer: Yes\n",
      "id : 54, caption: Officers from the Sumatran Orangutan Foundation and the Orangutan Information Centre rescue a female found isolated in an oil palm plantation in Kuala Musam North Sumatra, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0172_534.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Officers from the Sumatran Orangutan Foundation and the Orangutan Information Centre rescue a female found isolated in an oil palm plantation in Kuala Musam North Sumatra\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Officers from the Sumatran Orangutan Foundation and the Orangutan Information Centre rescue a female found isolated in an oil palm plantation in Kuala Musam North Sumatra\n",
      "Answer: out of context\n",
      "id : 55, caption: The drought has forced thousands to cross borders like these Somalis in Dadaab Kenya, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0370_123.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The drought has forced thousands to cross borders like these Somalis in Dadaab Kenya\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The drought has forced thousands to cross borders like these Somalis in Dadaab Kenya\n",
      "Answer: Yes\n",
      "id : 56, caption: Authorities moved the boat where Boston bomber Dzhokar Tsarnaev was found hiding following a manhunt in April 2013, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0437_712.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Authorities moved the boat where Boston bomber Dzhokar Tsarnaev was found hiding following a manhunt in April 2013\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Authorities moved the boat where Boston bomber Dzhokar Tsarnaev was found hiding following a manhunt in April 2013\n",
      "Answer: Out of context\n",
      "id : 57, caption: Brighton Argus journalists on the picket line this morning Picture Rob James, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0296_678.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brighton Argus journalists on the picket line this morning Picture Rob James\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brighton Argus journalists on the picket line this morning Picture Rob James\n",
      "Answer: Not out of context\n",
      "id : 58, caption: Belk Bowl in Charlotte Louisville vs Georgia ESPN 630, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0603_507.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Belk Bowl in Charlotte Louisville vs Georgia ESPN 630\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Belk Bowl in Charlotte Louisville vs Georgia ESPN 630\n",
      "Answer: Yes\n",
      "id : 59, caption: Before the team are greeted by the fans they are greeted by members of the Spainish royal family at the Zarzuela Palace, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0831_483.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Before the team are greeted by the fans they are greeted by members of the Spainish royal family at the Zarzuela Palace\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Before the team are greeted by the fans they are greeted by members of the Spainish royal family at the Zarzuela Palace\n",
      "Answer: Out of context\n",
      "id : 60, caption: The Asiana Airlines Boeing 777 is engulfed on the tarmac after crashlanding at San Francisco International Airport, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0415_769.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Asiana Airlines Boeing 777 is engulfed on the tarmac after crashlanding at San Francisco International Airport\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Asiana Airlines Boeing 777 is engulfed on the tarmac after crashlanding at San Francisco International Airport\n",
      "Answer: Yes, the caption accurately describes the content of the image. The Asiana Airlines Boeing 777 is engulfed on the tarmac after crashlanding at San Francisco International Airport.\n",
      "id : 61, caption: People work to rescue trapped people inside a temple in Basantapur Durbar Square after a major earthquake hit Kathmandu Nepal on April 25, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0826_805.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People work to rescue trapped people inside a temple in Basantapur Durbar Square after a major earthquake hit Kathmandu Nepal on April 25\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People work to rescue trapped people inside a temple in Basantapur Durbar Square after a major earthquake hit Kathmandu Nepal on April 25\n",
      "Answer: Out of context\n",
      "id : 62, caption: Tim Crouch in An Oak Tree at Warwick Arts Centre this week, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0455_818.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tim Crouch in An Oak Tree at Warwick Arts Centre this week\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tim Crouch in An Oak Tree at Warwick Arts Centre this week\n",
      "Answer: Not out of context\n",
      "id : 63, caption: Brothers Logan Froehler 17 at left and Lukas 11 throw a football while kayaking in their backyard on the Isle of Palms South Carolina, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0370_605.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brothers Logan Froehler 17 at left and Lukas 11 throw a football while kayaking in their backyard on the Isle of Palms South Carolina\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brothers Logan Froehler 17 at left and Lukas 11 throw a football while kayaking in their backyard on the Isle of Palms South Carolina\n",
      "Answer: Out of context\n",
      "id : 64, caption: The BBC Russian Service s Seva Novgorodsev Putin panders to the lowest common denominator, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0614_219.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The BBC Russian Service s Seva Novgorodsev Putin panders to the lowest common denominator\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The BBC Russian Service s Seva Novgorodsev Putin panders to the lowest common denominator\n",
      "Answer: Yes\n",
      "id : 65, caption: Thousands of Roman Catholics in Cuba marked the end of Holy Week by holding religious processions, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0704_257.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thousands of Roman Catholics in Cuba marked the end of Holy Week by holding religious processions\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thousands of Roman Catholics in Cuba marked the end of Holy Week by holding religious processions\n",
      "Answer: Out of context\n",
      "id : 66, caption: Monkeying around a Gabba Gallery mural in LA, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0443_720.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Monkeying around a Gabba Gallery mural in LA\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Monkeying around a Gabba Gallery mural in LA\n",
      "Answer: The caption accurately describes the content of the image, as it features a monkey-themed mural on a building in Los Angeles.\n",
      "id : 67, caption: Simon Harris received a sentence of 17 years four months for abusing vulnerable Kenyan boys, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0416_209.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Simon Harris received a sentence of 17 years four months for abusing vulnerable Kenyan boys\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Simon Harris received a sentence of 17 years four months for abusing vulnerable Kenyan boys\n",
      "Answer: out of context\n",
      "id : 68, caption: A couple at the river Spree during sunset in Berlin Germany July 21 2015 REUTERSFabrizio Bensch, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0372_945.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A couple at the river Spree during sunset in Berlin Germany July 21 2015 REUTERSFabrizio Bensch\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A couple at the river Spree during sunset in Berlin Germany July 21 2015 REUTERSFabrizio Bensch\n",
      "Answer: Out of context\n",
      "id : 69, caption: Blanche s downward spiral brings her face to face with the brutal Stanley Kowalski, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0480_695.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Blanche s downward spiral brings her face to face with the brutal Stanley Kowalski\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Blanche s downward spiral brings her face to face with the brutal Stanley Kowalski\n",
      "Answer: Yes\n",
      "id : 70, caption: For fans of our work with the NSA files Illustration by the Guardian, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0407_356.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:For fans of our work with the NSA files Illustration by the Guardian\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:For fans of our work with the NSA files Illustration by the Guardian\n",
      "Answer: Yes\n",
      "id : 71, caption: Full team ahead Adele along with the managers pluggers and publishers behind her tops our UK Music Power 100, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0290_401.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Full team ahead Adele along with the managers pluggers and publishers behind her tops our UK Music Power 100\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Full team ahead Adele along with the managers pluggers and publishers behind her tops our UK Music Power 100\n",
      "Answer: Out of context\n",
      "id : 72, caption: Hamburg 4 May 1970 Leonard Cohen performs on stage at the Musikhalle, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0417_850.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hamburg 4 May 1970 Leonard Cohen performs on stage at the Musikhalle\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hamburg 4 May 1970 Leonard Cohen performs on stage at the Musikhalle\n",
      "Answer: Not out of context\n",
      "id : 73, caption: Siranjan Kulatilake and Hayley Plack meeting for the first time, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0391_155.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Siranjan Kulatilake and Hayley Plack meeting for the first time\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Siranjan Kulatilake and Hayley Plack meeting for the first time\n",
      "Answer: Yes\n",
      "id : 74, caption: Commuters make a subzero trek to offices in the Loop on Monday in Chicago, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0146_878.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Commuters make a subzero trek to offices in the Loop on Monday in Chicago\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Commuters make a subzero trek to offices in the Loop on Monday in Chicago\n",
      "Answer: Out of context\n",
      "id : 75, caption: A still from the video released by the city of El Paso of the fatal police shooting of bodybuilder Daniel Saenz, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0674_289.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A still from the video released by the city of El Paso of the fatal police shooting of bodybuilder Daniel Saenz\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A still from the video released by the city of El Paso of the fatal police shooting of bodybuilder Daniel Saenz\n",
      "Answer: Out of context\n",
      "id : 76, caption: Bernard Tomic serves during his 5 set victory over Sam Querrey 76 76 36 26 63, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0546_646.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bernard Tomic serves during his 5 set victory over Sam Querrey 76 76 36 26 63\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bernard Tomic serves during his 5 set victory over Sam Querrey 76 76 36 26 63\n",
      "Answer: out of context\n",
      "id : 77, caption: A shop in North Korean shopkeeper in Pyongyang The North Korean capital is more affluent than other parts of the country but what s it like to live there, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0064_080.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A shop in North Korean shopkeeper in Pyongyang The North Korean capital is more affluent than other parts of the country but what s it like to live there\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A shop in North Korean shopkeeper in Pyongyang The North Korean capital is more affluent than other parts of the country but what s it like to live there\n",
      "Answer: Yes, the caption accurately describes the content of the image. It shows a North Korean shopkeeper in Pyongyang, which is the capital city of North Korea.\n",
      "id : 78, caption: British Greenpeace activist Phillip Ball in the Norwegian port of Kirkenes before the Arctic Sunrise s fateful voyage, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0436_090.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:British Greenpeace activist Phillip Ball in the Norwegian port of Kirkenes before the Arctic Sunrise s fateful voyage\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:British Greenpeace activist Phillip Ball in the Norwegian port of Kirkenes before the Arctic Sunrise s fateful voyage\n",
      "Answer: Out of context\n",
      "id : 79, caption: Gary Glitter real name Paul Gadd arrives at Southwark crown court in London, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0719_413.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Gary Glitter real name Paul Gadd arrives at Southwark crown court in London\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Gary Glitter real name Paul Gadd arrives at Southwark crown court in London\n",
      "Answer: Yes, the caption accurately describes the content of the image. Gary Glitter, also known as Paul Gadd, has arrived at Southwark Crown Court in London.\n",
      "id : 80, caption: Nasir alWuhayshi the leader of alQaeda in the Arabian Peninsula in April 2012 In 2013 he was named alQaeda s overall secondincommand, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0001_898.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Nasir alWuhayshi the leader of alQaeda in the Arabian Peninsula in April 2012 In 2013 he was named alQaeda s overall secondincommand\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Nasir alWuhayshi the leader of alQaeda in the Arabian Peninsula in April 2012 In 2013 he was named alQaeda s overall secondincommand\n",
      "Answer: yes\n",
      "id : 81, caption: A sensual thing Gerald Moore with baritone Dietrich FischerDieskau, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0820_052.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A sensual thing Gerald Moore with baritone Dietrich FischerDieskau\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A sensual thing Gerald Moore with baritone Dietrich FischerDieskau\n",
      "Answer: No, the image is not being used out of context.\n",
      "id : 82, caption: PremalShah president of social entrepreneur web site Kivaorg, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0527_599.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:PremalShah president of social entrepreneur web site Kivaorg\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:PremalShah president of social entrepreneur web site Kivaorg\n",
      "Answer: yes\n",
      "id : 83, caption: The UN s Darfur mission is one of the largest in the world, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0734_247.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The UN s Darfur mission is one of the largest in the world\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The UN s Darfur mission is one of the largest in the world\n",
      "Answer: Yes, the caption accurately describes the content of the image. The UN's Darfur mission is one of the largest in the world.\n",
      "id : 84, caption: Marilyn J Mosby state s attorney for Baltimore City speaks at a news conference in Baltimore announcing the charges, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0378_115.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marilyn J Mosby state s attorney for Baltimore City speaks at a news conference in Baltimore announcing the charges\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marilyn J Mosby state s attorney for Baltimore City speaks at a news conference in Baltimore announcing the charges\n",
      "Answer: out of context\n",
      "id : 85, caption: Jan 6 2014 Twolves point guard Ricky Rubio makes his latest highlight reel pass around 76ers center Spencer Hawes during Minnesota s 12695 win, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0698_700.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jan 6 2014 Twolves point guard Ricky Rubio makes his latest highlight reel pass around 76ers center Spencer Hawes during Minnesota s 12695 win\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jan 6 2014 Twolves point guard Ricky Rubio makes his latest highlight reel pass around 76ers center Spencer Hawes during Minnesota s 12695 win\n",
      "Answer: out of context\n",
      "id : 86, caption: No 16 Louisville 34 South Florida 3, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0288_191.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:No 16 Louisville 34 South Florida 3\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:No 16 Louisville 34 South Florida 3\n",
      "Answer: The image shows a football game between the University of Louisville Cardinals and the South Florida Bulls at Papa John's Cardinal Stadium in Louisville, Kentucky. The Cardinals won the game by a score of 34-3.\n",
      "Warning: Image not found at ./sample_300_semantics_text_image/usa_today_images_0263_804.jpg\n",
      "id : 87, caption: Life the Vote volunteers at the Trump rally in Panama City Beach, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0652_063.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Life the Vote volunteers at the Trump rally in Panama City Beach\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Life the Vote volunteers at the Trump rally in Panama City Beach\n",
      "Answer: Out of context\n",
      "id : 88, caption: ACDC Performing at the Grammys on 8 February, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0772_782.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:ACDC Performing at the Grammys on 8 February\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:ACDC Performing at the Grammys on 8 February\n",
      "Answer: Yes, the Rolling Stones are performing at the Grammys on 8 February.\n",
      "id : 89, caption: Guy Fieri s American Kitchen Bar Cancun serves his typical mix of burgers barbecue and comfort food at Terminal 3 in the Cancun International Airport, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0575_994.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Guy Fieri s American Kitchen Bar Cancun serves his typical mix of burgers barbecue and comfort food at Terminal 3 in the Cancun International Airport\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Guy Fieri s American Kitchen Bar Cancun serves his typical mix of burgers barbecue and comfort food at Terminal 3 in the Cancun International Airport\n",
      "Answer: Out of context\n",
      "id : 90, caption: Oliver Goss of Australia points to his ball after teeing off on the second hole during the final round of the Masters, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0527_109.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Oliver Goss of Australia points to his ball after teeing off on the second hole during the final round of the Masters\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Oliver Goss of Australia points to his ball after teeing off on the second hole during the final round of the Masters\n",
      "Answer: Out of context\n",
      "id : 91, caption: The project mapped the surges along the Cley to Salthouse gravel barrier in north Norfolk, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0059_070.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The project mapped the surges along the Cley to Salthouse gravel barrier in north Norfolk\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The project mapped the surges along the Cley to Salthouse gravel barrier in north Norfolk\n",
      "Answer: Out of context\n",
      "id : 92, caption: Ozzie bounds out of a cage and takes flight at Dick Pritchett Real Estate in North Fort Myers earlier this year He died Wednesday, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0181_110.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ozzie bounds out of a cage and takes flight at Dick Pritchett Real Estate in North Fort Myers earlier this year He died Wednesday\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ozzie bounds out of a cage and takes flight at Dick Pritchett Real Estate in North Fort Myers earlier this year He died Wednesday\n",
      "Answer: out of context\n",
      "id : 93, caption: 1910 poster by Albert Gantner criticising a Swiss ban on absinthe, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0643_825.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:1910 poster by Albert Gantner criticising a Swiss ban on absinthe\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:1910 poster by Albert Gantner criticising a Swiss ban on absinthe\n",
      "Answer: Yes\n",
      "id : 94, caption: The closure of Lewisham A E and maternity services will result in better quality care in south east London it is claimed, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0329_790.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The closure of Lewisham A E and maternity services will result in better quality care in south east London it is claimed\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The closure of Lewisham A E and maternity services will result in better quality care in south east London it is claimed\n",
      "Answer: Out of context\n",
      "id : 95, caption: n this June 27 2012 file photo Vic Gundotra Google s former senior vice president of engineering talks about Google Plus at the Google IO conference in San Francisco, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0674_732.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:n this June 27 2012 file photo Vic Gundotra Google s former senior vice president of engineering talks about Google Plus at the Google IO conference in San Francisco\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:n this June 27 2012 file photo Vic Gundotra Google s former senior vice president of engineering talks about Google Plus at the Google IO conference in San Francisco\n",
      "Answer: out of context\n",
      "id : 96, caption: The shark has been on the house since 1986 the 41st anniversary of the Nagasaki atomic bombing, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0066_439.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The shark has been on the house since 1986 the 41st anniversary of the Nagasaki atomic bombing\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The shark has been on the house since 1986 the 41st anniversary of the Nagasaki atomic bombing\n",
      "Answer: Yes\n",
      "id : 97, caption: At the end of every day or at least at the end of every week I feel I made a change says Bess Dopkeen who works at the Pentagon, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0131_272.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:At the end of every day or at least at the end of every week I feel I made a change says Bess Dopkeen who works at the Pentagon\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:At the end of every day or at least at the end of every week I feel I made a change says Bess Dopkeen who works at the Pentagon\n",
      "Answer: yes\n",
      "id : 98, caption: Skywalk gets Metro riders over busy Route 123, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0255_378.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Skywalk gets Metro riders over busy Route 123\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Skywalk gets Metro riders over busy Route 123\n",
      "Answer: Out of context\n",
      "id : 99, caption: Myles Jack was left undrafted after Round 1 but was taken early in the second by the Jaguars, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0494_196.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Myles Jack was left undrafted after Round 1 but was taken early in the second by the Jaguars\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Myles Jack was left undrafted after Round 1 but was taken early in the second by the Jaguars\n",
      "Answer: out of context\n",
      "id : 100, caption: The band appeared with Apple chief executive Tim Cook in September to launch the album, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0485_626.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The band appeared with Apple chief executive Tim Cook in September to launch the album\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The band appeared with Apple chief executive Tim Cook in September to launch the album\n",
      "Answer: Out of context\n",
      "id : 101, caption: Iain Cunningham As a boy I saw Irene in everything from a thistle seed blown by the wind to a door creaking open, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0320_316.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Iain Cunningham As a boy I saw Irene in everything from a thistle seed blown by the wind to a door creaking open\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Iain Cunningham As a boy I saw Irene in everything from a thistle seed blown by the wind to a door creaking open\n",
      "Answer: The man in the image is Iain Cunningham.\n",
      "id : 102, caption: Opposition rally at Bolotnaya Ploshchad against the results of the State Duma elections, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0823_768.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Opposition rally at Bolotnaya Ploshchad against the results of the State Duma elections\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Opposition rally at Bolotnaya Ploshchad against the results of the State Duma elections\n",
      "Answer: Opposition rally at Bolotnaya Ploshchad against the results of the State Duma elections\n",
      "id : 103, caption: Despite introducing several bright young talents England are collectively no better than they were when Martin Johnson arrived in 2008, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0167_071.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Despite introducing several bright young talents England are collectively no better than they were when Martin Johnson arrived in 2008\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Despite introducing several bright young talents England are collectively no better than they were when Martin Johnson arrived in 2008\n",
      "Answer: Not out of context\n",
      "id : 104, caption: Liam Cunningham as Davos Seaworth in HBO s Game of Thrones, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0171_334.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Liam Cunningham as Davos Seaworth in HBO s Game of Thrones\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Liam Cunningham as Davos Seaworth in HBO s Game of Thrones\n",
      "Answer: Out of context\n",
      "id : 105, caption: Google s restrictions on the use of Android by manufacturers regarding its apps and search is being investigated by the Russian antimonopoly watchdog, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0291_920.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Google s restrictions on the use of Android by manufacturers regarding its apps and search is being investigated by the Russian antimonopoly watchdog\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Google s restrictions on the use of Android by manufacturers regarding its apps and search is being investigated by the Russian antimonopoly watchdog\n",
      "Answer: out of context\n",
      "id : 106, caption: The Asian common toad may have hopped a ride in a shipping container to get to Madagascar, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0543_619.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Asian common toad may have hopped a ride in a shipping container to get to Madagascar\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Asian common toad may have hopped a ride in a shipping container to get to Madagascar\n",
      "Answer: out of context\n",
      "id : 107, caption: The letter from Horsforth School asked parents to pay a 250 deposit by 19 June for the Barbados trip, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0294_795.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The letter from Horsforth School asked parents to pay a 250 deposit by 19 June for the Barbados trip\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The letter from Horsforth School asked parents to pay a 250 deposit by 19 June for the Barbados trip\n",
      "Answer: yes\n",
      "id : 108, caption: A Christian can never be an antisemite especially because of the Jewish roots of Christianity the document said, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0427_519.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Christian can never be an antisemite especially because of the Jewish roots of Christianity the document said\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Christian can never be an antisemite especially because of the Jewish roots of Christianity the document said\n",
      "Answer: Out of context\n",
      "id : 109, caption: Angela Raiola the biggerthanlife Mob Wives star better Big Ang lost her battle with throat cancer Wednesday She was 55 years old, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0020_756.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Angela Raiola the biggerthanlife Mob Wives star better Big Ang lost her battle with throat cancer Wednesday She was 55 years old\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Angela Raiola the biggerthanlife Mob Wives star better Big Ang lost her battle with throat cancer Wednesday She was 55 years old\n",
      "Answer: out of context\n",
      "id : 110, caption: Spanish newspapers feature pictures of nurse Teresa Romero who was diagnosed with Ebola, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0325_524.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Spanish newspapers feature pictures of nurse Teresa Romero who was diagnosed with Ebola\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Spanish newspapers feature pictures of nurse Teresa Romero who was diagnosed with Ebola\n",
      "Answer: Out of context\n",
      "id : 111, caption: Cambridge University graduate William Jacques who has been dubbed the tome raider for stealing rare books from libraries pictured in 2001, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0115_191.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cambridge University graduate William Jacques who has been dubbed the tome raider for stealing rare books from libraries pictured in 2001\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cambridge University graduate William Jacques who has been dubbed the tome raider for stealing rare books from libraries pictured in 2001\n",
      "Answer: out of context\n",
      "id : 112, caption: Workers put up a preelection poster featuring Vladimir Putin and Dmitry Medvedev in Krasnodar Russia, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0216_178.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Workers put up a preelection poster featuring Vladimir Putin and Dmitry Medvedev in Krasnodar Russia\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Workers put up a preelection poster featuring Vladimir Putin and Dmitry Medvedev in Krasnodar Russia\n",
      "Answer: Yes\n",
      "id : 113, caption: It s staged in a purposebuilt venue dreamed up by Jon Bausor the set designer of the 2012 Paralympics opening ceremony, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0450_314.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:It s staged in a purposebuilt venue dreamed up by Jon Bausor the set designer of the 2012 Paralympics opening ceremony\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:It s staged in a purposebuilt venue dreamed up by Jon Bausor the set designer of the 2012 Paralympics opening ceremony\n",
      "Answer: Out of context\n",
      "id : 114, caption: Devin Sykes 24 of Rochester Hills Mich works on the underside of a 1969 Corvette Stingray at Automotive Performance Industries in Troy Mich, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0076_062.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Devin Sykes 24 of Rochester Hills Mich works on the underside of a 1969 Corvette Stingray at Automotive Performance Industries in Troy Mich\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Devin Sykes 24 of Rochester Hills Mich works on the underside of a 1969 Corvette Stingray at Automotive Performance Industries in Troy Mich\n",
      "Answer: Out of context\n",
      "id : 115, caption: Mignolet saves at the feet of Real Madrid s Karim Benzema, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0139_510.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mignolet saves at the feet of Real Madrid s Karim Benzema\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mignolet saves at the feet of Real Madrid s Karim Benzema\n",
      "Answer: out of context\n",
      "id : 116, caption: Indigenous dancers in a traditional healing ceremony for Mother Earth in San Salvador, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0029_372.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Indigenous dancers in a traditional healing ceremony for Mother Earth in San Salvador\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Indigenous dancers in a traditional healing ceremony for Mother Earth in San Salvador\n",
      "Answer: The caption accurately describes the content of the image, as it depicts indigenous dancers participating in a traditional healing ceremony for Mother Earth in San Salvador.\n",
      "id : 117, caption: Posters line a wall in an ultrasound exam room at a Planned Parenthood location in Boston, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0059_508.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Posters line a wall in an ultrasound exam room at a Planned Parenthood location in Boston\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Posters line a wall in an ultrasound exam room at a Planned Parenthood location in Boston\n",
      "Answer: The caption accurately describes the content of the image, as it shows posters lining a wall in an ultrasound exam room at a Planned Parenthood location in Boston.\n",
      "id : 118, caption: Sheryl Sandberg the COO of Facebook gets comfort from her selfhelp book of choice, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0439_733.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sheryl Sandberg the COO of Facebook gets comfort from her selfhelp book of choice\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sheryl Sandberg the COO of Facebook gets comfort from her selfhelp book of choice\n",
      "Answer: Yes\n",
      "id : 119, caption: I m not here to provide answers but to provoke more questions Victoria Melody with Major Tom the Basset hound, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0513_837.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:I m not here to provide answers but to provoke more questions Victoria Melody with Major Tom the Basset hound\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:I m not here to provide answers but to provoke more questions Victoria Melody with Major Tom the Basset hound\n",
      "Answer: yes\n",
      "id : 120, caption: FareShare volunteers pack food and groceries to deliver to charities around London, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0509_927.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:FareShare volunteers pack food and groceries to deliver to charities around London\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:FareShare volunteers pack food and groceries to deliver to charities around London\n",
      "Answer: Not out of context\n",
      "id : 121, caption: The former Chinese gymnast Li Ning carries the Olympic flame around the top of the stadium, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0342_123.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The former Chinese gymnast Li Ning carries the Olympic flame around the top of the stadium\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The former Chinese gymnast Li Ning carries the Olympic flame around the top of the stadium\n",
      "Answer: Out of context\n",
      "id : 122, caption: Hockey fans hold up signs before Game 4 of the Eastern Conference finals between the New York Rangers and Tampa Bay Lightning, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0658_978.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hockey fans hold up signs before Game 4 of the Eastern Conference finals between the New York Rangers and Tampa Bay Lightning\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hockey fans hold up signs before Game 4 of the Eastern Conference finals between the New York Rangers and Tampa Bay Lightning\n",
      "Answer: Out of context\n",
      "id : 123, caption: Former USA TODAY employee Matt Trott participates in Monday s parade in Washington DC with his service dog Claren as part of the group Canine Companions for Independence, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0046_954.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former USA TODAY employee Matt Trott participates in Monday s parade in Washington DC with his service dog Claren as part of the group Canine Companions for Independence\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former USA TODAY employee Matt Trott participates in Monday s parade in Washington DC with his service dog Claren as part of the group Canine Companions for Independence\n",
      "Answer: Out of context\n",
      "id : 124, caption: Ian Hogarth says he was influenced by his year living and working in Silicon Valley, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0340_692.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ian Hogarth says he was influenced by his year living and working in Silicon Valley\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ian Hogarth says he was influenced by his year living and working in Silicon Valley\n",
      "Answer: out of context\n",
      "id : 125, caption: A very clear antiausterity message for the IMF ECB and EU from Syriza supporters, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0309_446.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A very clear antiausterity message for the IMF ECB and EU from Syriza supporters\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A very clear antiausterity message for the IMF ECB and EU from Syriza supporters\n",
      "Answer: Out of context\n",
      "id : 126, caption: Belinda Hollyer was born in New Zealand where she worked as a teacherlibrarian She moved to London in the 1970s and found work in publishing starting at the Macdonald group, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0004_150.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Belinda Hollyer was born in New Zealand where she worked as a teacherlibrarian She moved to London in the 1970s and found work in publishing starting at the Macdonald group\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Belinda Hollyer was born in New Zealand where she worked as a teacherlibrarian She moved to London in the 1970s and found work in publishing starting at the Macdonald group\n",
      "Answer: Not out of context\n",
      "id : 127, caption: Obama s meeting with Putin to focus on Ukraine, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0221_373.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama s meeting with Putin to focus on Ukraine\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Obama s meeting with Putin to focus on Ukraine\n",
      "Answer: Yes\n",
      "id : 128, caption: The YMCA location at 17th and Rhode Island Avenue NW in the District will be closing, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0587_477.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The YMCA location at 17th and Rhode Island Avenue NW in the District will be closing\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The YMCA location at 17th and Rhode Island Avenue NW in the District will be closing\n",
      "Answer: Yes\n",
      "Warning: Image not found at ./sample_300_semantics_text_image/usa_today_images_0054_596.jpg\n",
      "id : 129, caption: Professor Caroline Willkinson at work in Dundee University, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0150_280.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Professor Caroline Willkinson at work in Dundee University\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Professor Caroline Willkinson at work in Dundee University\n",
      "Answer: Yes\n",
      "id : 130, caption: Andrew Hankinson with his father Barry at his home in Darras Hall near Newcastle, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0374_002.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Andrew Hankinson with his father Barry at his home in Darras Hall near Newcastle\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Andrew Hankinson with his father Barry at his home in Darras Hall near Newcastle\n",
      "Answer: Out of context\n",
      "id : 131, caption: Although reinstated as England captain in 2010 ahead of the World Cup a knee injury meant he sat out the majority of the season, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0211_632.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Although reinstated as England captain in 2010 ahead of the World Cup a knee injury meant he sat out the majority of the season\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Although reinstated as England captain in 2010 ahead of the World Cup a knee injury meant he sat out the majority of the season\n",
      "Answer: out of context\n",
      "id : 132, caption: In the town of Tal Abyad a Syrian refugee carries mattresses as he reenters Syria from Turkey after Kurdish People s Protection Units took control of the area, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0559_555.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:In the town of Tal Abyad a Syrian refugee carries mattresses as he reenters Syria from Turkey after Kurdish People s Protection Units took control of the area\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:In the town of Tal Abyad a Syrian refugee carries mattresses as he reenters Syria from Turkey after Kurdish People s Protection Units took control of the area\n",
      "Answer: Yes\n",
      "id : 133, caption: The RSPCA treated injured birds at its centres in Cornwall and Somerset, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0064_635.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The RSPCA treated injured birds at its centres in Cornwall and Somerset\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The RSPCA treated injured birds at its centres in Cornwall and Somerset\n",
      "Answer: Yes, the caption describes the RSPCA treating injured birds at its centres in Cornwall and Somerset.\n",
      "id : 134, caption: Thousands of vehicles each day pass the Memorial Peace Cross a landmark in Prince Georges County, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0288_648.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thousands of vehicles each day pass the Memorial Peace Cross a landmark in Prince Georges County\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thousands of vehicles each day pass the Memorial Peace Cross a landmark in Prince Georges County\n",
      "Answer: Out of context\n",
      "id : 135, caption: Young Chinese worshippers attend the Christmas Eve Mass in China s capital, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0146_021.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Young Chinese worshippers attend the Christmas Eve Mass in China s capital\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Young Chinese worshippers attend the Christmas Eve Mass in China s capital\n",
      "Answer: The caption accurately describes the content of the image.\n",
      "id : 136, caption: Kevin Pietersen will join up with his former Ashes rival Michael Clarke in the Big Bash League later this year, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0737_932.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kevin Pietersen will join up with his former Ashes rival Michael Clarke in the Big Bash League later this year\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kevin Pietersen will join up with his former Ashes rival Michael Clarke in the Big Bash League later this year\n",
      "Answer: out of context\n",
      "id : 137, caption: Adruitha Lee left and Robin Mathews accept the best achievement in makeup and hairstyling award for Dallas Buyers Club, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0162_660.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Adruitha Lee left and Robin Mathews accept the best achievement in makeup and hairstyling award for Dallas Buyers Club\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Adruitha Lee left and Robin Mathews accept the best achievement in makeup and hairstyling award for Dallas Buyers Club\n",
      "Answer: out of context\n",
      "id : 138, caption: Court sketch of Nathan Matthews crying in the dock at Bristol crown court before being convicted of Becky Watts s murder, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0294_650.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Court sketch of Nathan Matthews crying in the dock at Bristol crown court before being convicted of Becky Watts s murder\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Court sketch of Nathan Matthews crying in the dock at Bristol crown court before being convicted of Becky Watts s murder\n",
      "Answer: Out of context\n",
      "id : 139, caption: Rev Dr Angus Morrison was installed as moderator of the general assembly after withdrawing from the role last year to undergo treatment for cancer, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0071_190.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rev Dr Angus Morrison was installed as moderator of the general assembly after withdrawing from the role last year to undergo treatment for cancer\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rev Dr Angus Morrison was installed as moderator of the general assembly after withdrawing from the role last year to undergo treatment for cancer\n",
      "Answer: Yes\n",
      "id : 140, caption: No 16 Louisville 34 South Florida 3, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0581_332.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:No 16 Louisville 34 South Florida 3\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:No 16 Louisville 34 South Florida 3\n",
      "Answer: Yes\n",
      "id : 141, caption: Charlie Bothuell IV becomes emotional June 25 2014 after learning that Detroit officers found his 12year old son missing for 11 days, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0689_414.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Charlie Bothuell IV becomes emotional June 25 2014 after learning that Detroit officers found his 12year old son missing for 11 days\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Charlie Bothuell IV becomes emotional June 25 2014 after learning that Detroit officers found his 12year old son missing for 11 days\n",
      "Answer: Out of context\n",
      "id : 142, caption: Snapchat CEO Evan Spiegel in Los Angeles, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0532_707.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Snapchat CEO Evan Spiegel in Los Angeles\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Snapchat CEO Evan Spiegel in Los Angeles\n",
      "Answer: Yes\n",
      "id : 143, caption: Five hundred fans watched Weller play tracks from Saturn s Pattern at The Great Escape, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0137_333.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Five hundred fans watched Weller play tracks from Saturn s Pattern at The Great Escape\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Five hundred fans watched Weller play tracks from Saturn s Pattern at The Great Escape\n",
      "Answer: Yes, the caption accurately describes the content of the image.\n",
      "id : 144, caption: The Citigroup tower has been put up for sale with a 1bn price tag by cashstrapped Irish developer Derek Quinlan, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0374_839.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Citigroup tower has been put up for sale with a 1bn price tag by cashstrapped Irish developer Derek Quinlan\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Citigroup tower has been put up for sale with a 1bn price tag by cashstrapped Irish developer Derek Quinlan\n",
      "Answer: Yes\n",
      "id : 145, caption: Spain s Sergio Garcia has criticised Augusta in the past but he thrived on the course during the first round, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0336_917.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Spain s Sergio Garcia has criticised Augusta in the past but he thrived on the course during the first round\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Spain s Sergio Garcia has criticised Augusta in the past but he thrived on the course during the first round\n",
      "Answer: out of context\n",
      "id : 146, caption: Boris Johnson may require six times his previous budget for housing in the next comprehensive spending review to have any chance of meeting London s housing need, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0478_320.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Boris Johnson may require six times his previous budget for housing in the next comprehensive spending review to have any chance of meeting London s housing need\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Boris Johnson may require six times his previous budget for housing in the next comprehensive spending review to have any chance of meeting London s housing need\n",
      "Answer: out of context\n",
      "id : 147, caption: People watch the second presidential debate in front of the Electric Avenue store in Miami, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0568_650.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People watch the second presidential debate in front of the Electric Avenue store in Miami\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People watch the second presidential debate in front of the Electric Avenue store in Miami\n",
      "Answer: Out of context\n",
      "id : 148, caption: Dayton Flyers forward Devin Oliver drives against Florida Gators forward Will Yeguete during the first half, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0155_555.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Dayton Flyers forward Devin Oliver drives against Florida Gators forward Will Yeguete during the first half\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Dayton Flyers forward Devin Oliver drives against Florida Gators forward Will Yeguete during the first half\n",
      "Answer: out of context\n",
      "id : 149, caption: Kid British Thomas Turgoose pictured at home in Grimsby, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0830_817.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kid British Thomas Turgoose pictured at home in Grimsby\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kid British Thomas Turgoose pictured at home in Grimsby\n",
      "Answer: Yes, the boy in the photo is British actor Thomas Turgoose, who is known for his portrayal of Shaun in the 2008 film \"This Is England.\"\n",
      "id : 150, caption: Army Pfc Bradley Manning is escorted into a courthouse at Fort Meade on the third day of his court martial, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0011_375.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Army Pfc Bradley Manning is escorted into a courthouse at Fort Meade on the third day of his court martial\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Army Pfc Bradley Manning is escorted into a courthouse at Fort Meade on the third day of his court martial\n",
      "Answer: The caption accurately describes the content of the image, as it depicts Army Pfc Bradley Manning being escorted into a courthouse at Fort Meade on the third day of his court martial.\n",
      "id : 151, caption: Michael Dye was a mason with Cardiff City council, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0156_879.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Dye was a mason with Cardiff City council\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Dye was a mason with Cardiff City council\n",
      "Answer: Yes\n",
      "id : 152, caption: Supporters of Egypt s ruling military council gather in Cairo, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0226_727.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Supporters of Egypt s ruling military council gather in Cairo\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Supporters of Egypt s ruling military council gather in Cairo\n",
      "Answer: Yes, the caption accurately describes the content of the image.\n",
      "id : 153, caption: The collective shared body Red Coat by Nicola L 1974 part of the The World Goes Pop exhibition at Tate Modern, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0208_031.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The collective shared body Red Coat by Nicola L 1974 part of the The World Goes Pop exhibition at Tate Modern\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The collective shared body Red Coat by Nicola L 1974 part of the The World Goes Pop exhibition at Tate Modern\n",
      "Answer: Out of context\n",
      "id : 154, caption: Avengers Assemble Captain America and co win the battle for US hearts, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0765_691.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Avengers Assemble Captain America and co win the battle for US hearts\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Avengers Assemble Captain America and co win the battle for US hearts\n",
      "Answer: Yes, the caption accurately describes the content of the image.\n",
      "id : 155, caption: Bainbridge at home in London in 2001, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0607_495.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bainbridge at home in London in 2001\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bainbridge at home in London in 2001\n",
      "Answer: Yes, the caption accurately describes the content of the image. The woman in the picture is Beryl Bainbridge, and she is at home in London in 2001.\n",
      "id : 156, caption: Lisa Lantz ad her daughter Ashley Lantz of Dallas sign cards of support at a makeshift memorial at Police head quarters in Dallas Texas, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0649_173.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Lisa Lantz ad her daughter Ashley Lantz of Dallas sign cards of support at a makeshift memorial at Police head quarters in Dallas Texas\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Lisa Lantz ad her daughter Ashley Lantz of Dallas sign cards of support at a makeshift memorial at Police head quarters in Dallas Texas\n",
      "Answer: Out of context\n",
      "id : 157, caption: British pop artist Pauline Boty circa 1963, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0275_988.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:British pop artist Pauline Boty circa 1963\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:British pop artist Pauline Boty circa 1963\n",
      "Answer: Yes, the image is a black and white photograph of British pop artist Pauline Boty from 1963.\n",
      "id : 158, caption: The report says England s bid team often accommodated Mr Warner s wishes, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0353_757.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The report says England s bid team often accommodated Mr Warner s wishes\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The report says England s bid team often accommodated Mr Warner s wishes\n",
      "Answer: yes\n",
      "id : 159, caption: The Syrian government team travelled to the UN headquarters in Geneva, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0371_983.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Syrian government team travelled to the UN headquarters in Geneva\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Syrian government team travelled to the UN headquarters in Geneva\n",
      "Answer: Yes, the caption accurately describes the content of the image. The Syrian government team traveled to the UN headquarters in Geneva.\n",
      "id : 160, caption: A South Korean manager left consults with North Korean workers at the ShinWon garment factory on Sept 21 2012 at the Kaesong industrial complex, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0468_612.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A South Korean manager left consults with North Korean workers at the ShinWon garment factory on Sept 21 2012 at the Kaesong industrial complex\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A South Korean manager left consults with North Korean workers at the ShinWon garment factory on Sept 21 2012 at the Kaesong industrial complex\n",
      "Answer: Out of context\n",
      "id : 161, caption: China cabinet still have room There are dukeandduchess dishes far beyond the mug Royal baby fine bone china tableware set about 63 at MillyGreencom, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0089_276.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:China cabinet still have room There are dukeandduchess dishes far beyond the mug Royal baby fine bone china tableware set about 63 at MillyGreencom\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:China cabinet still have room There are dukeandduchess dishes far beyond the mug Royal baby fine bone china tableware set about 63 at MillyGreencom\n",
      "Answer: Not out of context\n",
      "id : 162, caption: Wagner Moura bringing a Brazilian touch to Pablo Escobar in Netflix s drama Narcos, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0762_873.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Wagner Moura bringing a Brazilian touch to Pablo Escobar in Netflix s drama Narcos\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Wagner Moura bringing a Brazilian touch to Pablo Escobar in Netflix s drama Narcos\n",
      "Answer: out of context\n",
      "id : 163, caption: Stephen Fry revealed the details to a 14yearold interviewer in a Radio Times special, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0615_442.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Fry revealed the details to a 14yearold interviewer in a Radio Times special\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Fry revealed the details to a 14yearold interviewer in a Radio Times special\n",
      "Answer: out of context\n",
      "id : 164, caption: Final preparations of the Republican National Convention in downtown in Cleveland Ohio, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0317_058.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Final preparations of the Republican National Convention in downtown in Cleveland Ohio\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Final preparations of the Republican National Convention in downtown in Cleveland Ohio\n",
      "Answer: The caption accurately describes the content of the image, as it depicts final preparations for the Republican National Convention in downtown Cleveland, Ohio.\n",
      "id : 165, caption: Qatari Emir Sheikh Hamad bin Khalifa Qatar owns Al Jazeera, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0100_942.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Qatari Emir Sheikh Hamad bin Khalifa Qatar owns Al Jazeera\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Qatari Emir Sheikh Hamad bin Khalifa Qatar owns Al Jazeera\n",
      "Answer: yes\n",
      "id : 166, caption: The Prince of Wales Duchess of Cornwall and Catherine s parents and sister visited on Sunday, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0165_375.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Prince of Wales Duchess of Cornwall and Catherine s parents and sister visited on Sunday\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Prince of Wales Duchess of Cornwall and Catherine s parents and sister visited on Sunday\n",
      "Answer: Out of context\n",
      "id : 167, caption: Democratic Presidential nominee Hillary Clinton greets convention goers, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0693_553.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Democratic Presidential nominee Hillary Clinton greets convention goers\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Democratic Presidential nominee Hillary Clinton greets convention goers\n",
      "Answer: Yes\n",
      "id : 168, caption: Michael Schumacher s return to Formula One is the latest of many bigname comebacks, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0418_669.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Schumacher s return to Formula One is the latest of many bigname comebacks\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Michael Schumacher s return to Formula One is the latest of many bigname comebacks\n",
      "Answer: Yes\n",
      "id : 169, caption: Could UK politicians learn something from House of Cards President Underwood and his stance on baby boomers, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0281_637.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Could UK politicians learn something from House of Cards President Underwood and his stance on baby boomers\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Could UK politicians learn something from House of Cards President Underwood and his stance on baby boomers\n",
      "Answer: Yes\n",
      "id : 170, caption: This seasons Bachelor Ben Higgins on a date with Caila and Kevin Hart, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0239_328.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:This seasons Bachelor Ben Higgins on a date with Caila and Kevin Hart\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:This seasons Bachelor Ben Higgins on a date with Caila and Kevin Hart\n",
      "Answer: Out of context\n",
      "id : 171, caption: Judge Mike Porter inspects a Malay, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0600_853.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Judge Mike Porter inspects a Malay\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Judge Mike Porter inspects a Malay\n",
      "Answer: Yes, the caption accurately describes the content of the image. Judge Mike Porter is inspecting a Malay rooster.\n",
      "id : 172, caption: Quokkas at Rottnest Island in Western Australia The animals are listed as a vulnerable species Mainland colonies were all but wiped out after European settlement, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0711_443.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Quokkas at Rottnest Island in Western Australia The animals are listed as a vulnerable species Mainland colonies were all but wiped out after European settlement\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Quokkas at Rottnest Island in Western Australia The animals are listed as a vulnerable species Mainland colonies were all but wiped out after European settlement\n",
      "Answer: out of context\n",
      "id : 173, caption: Holocaust survivor Joseph Just 96 of New Rochelle photographed as a young man before World War II, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0847_251.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Holocaust survivor Joseph Just 96 of New Rochelle photographed as a young man before World War II\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Holocaust survivor Joseph Just 96 of New Rochelle photographed as a young man before World War II\n",
      "Answer: Out of context\n",
      "id : 174, caption: The planned BBC One 1 channel does not represent public service value the committee said, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0140_037.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The planned BBC One 1 channel does not represent public service value the committee said\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The planned BBC One 1 channel does not represent public service value the committee said\n",
      "Answer: Yes\n",
      "id : 175, caption: Elliot and Pete in Pete s Dragon, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0237_211.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elliot and Pete in Pete s Dragon\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elliot and Pete in Pete s Dragon\n",
      "Answer: No, the caption does not accurately describe the content of the image. The image features a young boy holding a lizard, but there is no mention of Elliot and Pete in Pete's Dragon in the caption.\n",
      "id : 176, caption: Thirtyfive of the 46 women who have accused Bill Cosby of sexual assault appear in New York magazine s cover story Read it here, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0019_074.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thirtyfive of the 46 women who have accused Bill Cosby of sexual assault appear in New York magazine s cover story Read it here\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thirtyfive of the 46 women who have accused Bill Cosby of sexual assault appear in New York magazine s cover story Read it here\n",
      "Answer: Out of context\n",
      "id : 177, caption: Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0816_046.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ed Moloney founder of the Boston College Belfast Project archive and author of A Secret History of the IRA\n",
      "Answer: Yes\n",
      "id : 178, caption: The North Korean leader Kim Jongun visiting a military unit near the border with the South, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0812_852.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The North Korean leader Kim Jongun visiting a military unit near the border with the South\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The North Korean leader Kim Jongun visiting a military unit near the border with the South\n",
      "Answer: Out of context\n",
      "id : 179, caption: Zelda Fitzgerald and F Scott Fitzgerald in the 1930s, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0001_629.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Zelda Fitzgerald and F Scott Fitzgerald in the 1930s\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Zelda Fitzgerald and F Scott Fitzgerald in the 1930s\n",
      "Answer: Yes, the caption accurately describes the content of the image. The image features Zelda Fitzgerald and F Scott Fitzgerald in the 1930s.\n",
      "id : 180, caption: NHS staff need better support for their own health due to the increasing demands put upon them said Stevens, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0827_608.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:NHS staff need better support for their own health due to the increasing demands put upon them said Stevens\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:NHS staff need better support for their own health due to the increasing demands put upon them said Stevens\n",
      "Answer: Yes, the caption accurately describes the content of the image. The image shows NHS staff working in a hospital setting, and the caption highlights the need for better support for their own health due to the increasing demands placed upon them.\n",
      "id : 181, caption: Albany cheerleaders during the first half against Oklahoma, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0331_839.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Albany cheerleaders during the first half against Oklahoma\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Albany cheerleaders during the first half against Oklahoma\n",
      "Answer: Not out of context\n",
      "id : 182, caption: Tanit Koch is taking the reins of Bild from Kai Diekmann who will become publisher, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0430_469.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tanit Koch is taking the reins of Bild from Kai Diekmann who will become publisher\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tanit Koch is taking the reins of Bild from Kai Diekmann who will become publisher\n",
      "Answer: Tanit Koch\n",
      "id : 183, caption: Rick Perry at the Hotel Pattee in the aptlynamed town of Perry Iowa, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0321_369.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rick Perry at the Hotel Pattee in the aptlynamed town of Perry Iowa\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rick Perry at the Hotel Pattee in the aptlynamed town of Perry Iowa\n",
      "Answer: Yes, the caption accurately describes the content of the image. Rick Perry is at the Hotel Pattee in the town of Perry, Iowa.\n",
      "id : 184, caption: Actress Uma Thurman laughed off LaBeouf s enigmatic exit, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0123_082.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Actress Uma Thurman laughed off LaBeouf s enigmatic exit\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Actress Uma Thurman laughed off LaBeouf s enigmatic exit\n",
      "Answer: out of context\n",
      "id : 185, caption: Brazil s Market Ipanema opened a New York location in Little Italy this summer, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0344_678.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brazil s Market Ipanema opened a New York location in Little Italy this summer\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brazil s Market Ipanema opened a New York location in Little Italy this summer\n",
      "Answer: Not out of context\n",
      "id : 186, caption: Former Minnesota Gov Tim Pawlenty discusses his endorsement of Republican presidential candidate Mitt Romney during a news conference Monday in North Charleston SC, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0427_078.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former Minnesota Gov Tim Pawlenty discusses his endorsement of Republican presidential candidate Mitt Romney during a news conference Monday in North Charleston SC\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former Minnesota Gov Tim Pawlenty discusses his endorsement of Republican presidential candidate Mitt Romney during a news conference Monday in North Charleston SC\n",
      "Answer: yes\n",
      "id : 187, caption: Flooded street in Xiangshan county in Zhejiang province, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0515_168.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Flooded street in Xiangshan county in Zhejiang province\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Flooded street in Xiangshan county in Zhejiang province\n",
      "Answer: The image shows a flooded street in Xiangshan county in Zhejiang province.\n",
      "id : 188, caption: A boy wades through water in the flooded neighborhood of La Puya in Santo Domingo on Oct 4 after Hurricane Matthew passed through Hispaniola, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0445_230.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A boy wades through water in the flooded neighborhood of La Puya in Santo Domingo on Oct 4 after Hurricane Matthew passed through Hispaniola\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A boy wades through water in the flooded neighborhood of La Puya in Santo Domingo on Oct 4 after Hurricane Matthew passed through Hispaniola\n",
      "Answer: Out of context\n",
      "id : 189, caption: President Obama left Sen Charles E Schumer, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0487_342.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Obama left Sen Charles E Schumer\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Obama left Sen Charles E Schumer\n",
      "Answer: Yes\n",
      "id : 190, caption: Mesa police gather new Dobson Road and Southern Avenue the scene of reported multiple shootings, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0474_098.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mesa police gather new Dobson Road and Southern Avenue the scene of reported multiple shootings\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mesa police gather new Dobson Road and Southern Avenue the scene of reported multiple shootings\n",
      "Answer: Out of context\n",
      "id : 191, caption: A Chinese investor monitors displays of stock information at a brokerage house in Beijing on Tuesday 28 July 2015, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0204_488.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Chinese investor monitors displays of stock information at a brokerage house in Beijing on Tuesday 28 July 2015\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Chinese investor monitors displays of stock information at a brokerage house in Beijing on Tuesday 28 July 2015\n",
      "Answer: Out of context\n",
      "id : 192, caption: Thomas Vermaelen fights for the ball with Milan s KevinPrince Boateng Vermaelen slipped on more than one occastion, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0461_071.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thomas Vermaelen fights for the ball with Milan s KevinPrince Boateng Vermaelen slipped on more than one occastion\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Thomas Vermaelen fights for the ball with Milan s KevinPrince Boateng Vermaelen slipped on more than one occastion\n",
      "Answer: out of context\n",
      "id : 193, caption: Barangaroo development in Sydney The Crown plan has been approved over another plan from Echo Entertainment, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0565_267.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Barangaroo development in Sydney The Crown plan has been approved over another plan from Echo Entertainment\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Barangaroo development in Sydney The Crown plan has been approved over another plan from Echo Entertainment\n",
      "Answer: Barangaroo development in Sydney\n",
      "id : 194, caption: A story told in crises Barbara Flynn as the Queen during the 90s bad news decade, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0048_819.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A story told in crises Barbara Flynn as the Queen during the 90s bad news decade\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A story told in crises Barbara Flynn as the Queen during the 90s bad news decade\n",
      "Answer: Not out of context\n",
      "id : 195, caption: Rashad Pinkney 19 who was fatally shot two years ago at a massive house party in Upper Marlboro, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0639_612.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rashad Pinkney 19 who was fatally shot two years ago at a massive house party in Upper Marlboro\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rashad Pinkney 19 who was fatally shot two years ago at a massive house party in Upper Marlboro\n",
      "Answer: Out of context\n",
      "id : 196, caption: Hailey Brouillette s dog Sassy sits on a box of supplies provided by David Phung, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0200_908.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hailey Brouillette s dog Sassy sits on a box of supplies provided by David Phung\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hailey Brouillette s dog Sassy sits on a box of supplies provided by David Phung\n",
      "Answer: Not out of context\n",
      "id : 197, caption: Reynolds worked on Raiders of the Lost Ark with director Steven Spielberg, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0447_318.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Reynolds worked on Raiders of the Lost Ark with director Steven Spielberg\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Reynolds worked on Raiders of the Lost Ark with director Steven Spielberg\n",
      "Answer: Yes\n",
      "id : 198, caption: Damasak residents lived under Boko Haram s rule until regional troops regain control of the town, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0247_412.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Damasak residents lived under Boko Haram s rule until regional troops regain control of the town\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Damasak residents lived under Boko Haram s rule until regional troops regain control of the town\n",
      "Answer: Out of context\n",
      "id : 199, caption: Martin Allen 15 was last seen at King s Cross Tube station making his way home from school in November 1979, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0308_801.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Martin Allen 15 was last seen at King s Cross Tube station making his way home from school in November 1979\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Martin Allen 15 was last seen at King s Cross Tube station making his way home from school in November 1979\n",
      "Answer: out of context\n",
      "id : 200, caption: Rosimeiri Boxall jumped from a window after being bullied by Hatice Can and Kemi Ajose, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0050_090.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rosimeiri Boxall jumped from a window after being bullied by Hatice Can and Kemi Ajose\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rosimeiri Boxall jumped from a window after being bullied by Hatice Can and Kemi Ajose\n",
      "Answer: out of context\n",
      "id : 201, caption: Black wheels and other details mark the 2016 Ford Mustang GT equipped with the Black Accent Package, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0699_401.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Black wheels and other details mark the 2016 Ford Mustang GT equipped with the Black Accent Package\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Black wheels and other details mark the 2016 Ford Mustang GT equipped with the Black Accent Package\n",
      "Answer: The caption accurately describes the content of the image, which features a red 2016 Ford Mustang GT equipped with the Black Accent Package driving on a road.\n",
      "id : 202, caption: President Fernandez de Kirchner has been fighting the Clarin group since 2008, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0766_580.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Fernandez de Kirchner has been fighting the Clarin group since 2008\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Fernandez de Kirchner has been fighting the Clarin group since 2008\n",
      "Answer: Yes\n",
      "id : 203, caption: From left public defender Ashlie Gibbons Judge Victoria Pratt and Newark city prosecutor Herbert Washington, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0156_527.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:From left public defender Ashlie Gibbons Judge Victoria Pratt and Newark city prosecutor Herbert Washington\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:From left public defender Ashlie Gibbons Judge Victoria Pratt and Newark city prosecutor Herbert Washington\n",
      "Answer: Yes\n",
      "id : 204, caption: AlQaida leader in Afghanistan Mustafa abu alYazid was killed last month in Pakistan security officials believe, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0582_421.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:AlQaida leader in Afghanistan Mustafa abu alYazid was killed last month in Pakistan security officials believe\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:AlQaida leader in Afghanistan Mustafa abu alYazid was killed last month in Pakistan security officials believe\n",
      "Answer: out of context\n",
      "id : 205, caption: David Mitchell author of Cloud Atlas, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0033_926.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:David Mitchell author of Cloud Atlas\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:David Mitchell author of Cloud Atlas\n",
      "Answer: Yes\n",
      "id : 206, caption: Vince Cable was the most high profile MP targeted by the Daily Telegraph, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0386_536.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Vince Cable was the most high profile MP targeted by the Daily Telegraph\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Vince Cable was the most high profile MP targeted by the Daily Telegraph\n",
      "Answer: Out of context\n",
      "id : 207, caption: Photo by Flickr user Coleen Whitfield, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0080_860.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Photo by Flickr user Coleen Whitfield\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Photo by Flickr user Coleen Whitfield\n",
      "Answer: Colorado sold 17 tons of retail marijuana in its first legal year\n",
      "id : 208, caption: Terry Stokes chief executive of the London Advice Services Alliance, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0303_874.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Terry Stokes chief executive of the London Advice Services Alliance\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Terry Stokes chief executive of the London Advice Services Alliance\n",
      "Answer: Terry Stokes is the chief executive of the London Advice Services Alliance (LASA).\n",
      "id : 209, caption: A helicopter drops water on the Waldo Canyon fire burning behind the US Air Force Academy, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0352_086.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A helicopter drops water on the Waldo Canyon fire burning behind the US Air Force Academy\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A helicopter drops water on the Waldo Canyon fire burning behind the US Air Force Academy\n",
      "Answer: Out of context\n",
      "id : 210, caption: The pope with the Rev Monsignor W Ronald Jameson right and Cardinal Donald W Wuerl at the midday prayer service at the Cathedral of St Matthew the Apostle, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0234_485.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The pope with the Rev Monsignor W Ronald Jameson right and Cardinal Donald W Wuerl at the midday prayer service at the Cathedral of St Matthew the Apostle\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The pope with the Rev Monsignor W Ronald Jameson right and Cardinal Donald W Wuerl at the midday prayer service at the Cathedral of St Matthew the Apostle\n",
      "Answer: out of context\n",
      "id : 211, caption: TCU Horned Frogs quarterback Casey Pachall celebrates throwing a touchdown pass with offensive tackle Aviante Collins during the second half at Amon G Carter Stadium, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0649_493.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:TCU Horned Frogs quarterback Casey Pachall celebrates throwing a touchdown pass with offensive tackle Aviante Collins during the second half at Amon G Carter Stadium\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:TCU Horned Frogs quarterback Casey Pachall celebrates throwing a touchdown pass with offensive tackle Aviante Collins during the second half at Amon G Carter Stadium\n",
      "Answer: out of context\n",
      "id : 212, caption: Standard cabins on Harmony feature sofas located between two floortoceiling closets a layout that Royal Caribbean used on the recently unveiled Quantum of the Seas and Anthem of the Seas, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0253_986.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Standard cabins on Harmony feature sofas located between two floortoceiling closets a layout that Royal Caribbean used on the recently unveiled Quantum of the Seas and Anthem of the Seas\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Standard cabins on Harmony feature sofas located between two floortoceiling closets a layout that Royal Caribbean used on the recently unveiled Quantum of the Seas and Anthem of the Seas\n",
      "Answer: Not out of context\n",
      "id : 213, caption: Jenson Button is 62 points behind championship leader Fernando Alonso after taking just six points from the past five races, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0343_389.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jenson Button is 62 points behind championship leader Fernando Alonso after taking just six points from the past five races\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jenson Button is 62 points behind championship leader Fernando Alonso after taking just six points from the past five races\n",
      "Answer: out of context\n",
      "id : 214, caption: Don Bradman left and Bill Brown walk out to bat, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0825_558.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Don Bradman left and Bill Brown walk out to bat\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Don Bradman left and Bill Brown walk out to bat\n",
      "Answer: Yes, the caption accurately describes the content of the image. The two men walking out to bat are Don Bradman and Bill Brown.\n",
      "id : 215, caption: The core group of nations willing to confront Islamic State has no Muslim country except Turkey, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0433_669.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The core group of nations willing to confront Islamic State has no Muslim country except Turkey\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The core group of nations willing to confront Islamic State has no Muslim country except Turkey\n",
      "Answer: Out of context\n",
      "id : 216, caption: Omarosa speaks to the media at Trump Tower to show her support for Donald Trump after he won the New York primary on April 19 2016, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0211_115.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Omarosa speaks to the media at Trump Tower to show her support for Donald Trump after he won the New York primary on April 19 2016\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Omarosa speaks to the media at Trump Tower to show her support for Donald Trump after he won the New York primary on April 19 2016\n",
      "Answer: out of context\n",
      "id : 217, caption: US punk band The Ramones were snapped by Harry Papadopoulos, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0186_367.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:US punk band The Ramones were snapped by Harry Papadopoulos\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:US punk band The Ramones were snapped by Harry Papadopoulos\n",
      "Answer: Yes\n",
      "id : 218, caption: Marzuki Darusman UN special rapporteur on the situation of human rights in North Korea speaks during a news conference in Tokyo on Jan 23, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0108_425.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marzuki Darusman UN special rapporteur on the situation of human rights in North Korea speaks during a news conference in Tokyo on Jan 23\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marzuki Darusman UN special rapporteur on the situation of human rights in North Korea speaks during a news conference in Tokyo on Jan 23\n",
      "Answer: out of context\n",
      "id : 219, caption: Workers tear down the home of Jeff Bush on March 4 in Seffner Fla, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0643_304.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Workers tear down the home of Jeff Bush on March 4 in Seffner Fla\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Workers tear down the home of Jeff Bush on March 4 in Seffner Fla\n",
      "Answer: Out of context\n",
      "id : 220, caption: Tony Abbott and Joe Hockey have been floating the idea of a debt levy to gauge public reaction, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0014_658.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tony Abbott and Joe Hockey have been floating the idea of a debt levy to gauge public reaction\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tony Abbott and Joe Hockey have been floating the idea of a debt levy to gauge public reaction\n",
      "Answer: out of context\n",
      "id : 221, caption: The majority of Iraqis and Syrians think their countries are heading in the wrong direction, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0285_121.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The majority of Iraqis and Syrians think their countries are heading in the wrong direction\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The majority of Iraqis and Syrians think their countries are heading in the wrong direction\n",
      "Answer: Out of context.\n",
      "id : 222, caption: Donald Trump attends Trump Invitational Grand Prix MaraLago Club on Jan 4 in Palm Beach, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0419_749.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Donald Trump attends Trump Invitational Grand Prix MaraLago Club on Jan 4 in Palm Beach\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Donald Trump attends Trump Invitational Grand Prix MaraLago Club on Jan 4 in Palm Beach\n",
      "Answer: Out of context\n",
      "id : 223, caption: A demonstrator raises his fist as police stand in formation as a store burns Monday April 27 2015 during unrest following the funeral of Freddie Gray in Baltimore, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0006_702.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A demonstrator raises his fist as police stand in formation as a store burns Monday April 27 2015 during unrest following the funeral of Freddie Gray in Baltimore\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A demonstrator raises his fist as police stand in formation as a store burns Monday April 27 2015 during unrest following the funeral of Freddie Gray in Baltimore\n",
      "Answer: Out of context\n",
      "id : 224, caption: A Ukrainian soldier at the Belbek military base stands on alert anticipating a possible Russian attack, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0322_836.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Ukrainian soldier at the Belbek military base stands on alert anticipating a possible Russian attack\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A Ukrainian soldier at the Belbek military base stands on alert anticipating a possible Russian attack\n",
      "Answer: Yes\n",
      "id : 225, caption: Texas This onebedroom house in Galveston sleeps three and has an average rate of 118 a night, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0168_007.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Texas This onebedroom house in Galveston sleeps three and has an average rate of 118 a night\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Texas This onebedroom house in Galveston sleeps three and has an average rate of 118 a night\n",
      "Answer: Not out of context\n",
      "id : 226, caption: Robert Atkins as Sir Toby Belch and Norman Forbes as Sir Andrew Aguecheek are entertained by Feste in a 1932 production of Twelfth Night at the New theatre in London, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0568_221.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Robert Atkins as Sir Toby Belch and Norman Forbes as Sir Andrew Aguecheek are entertained by Feste in a 1932 production of Twelfth Night at the New theatre in London\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Robert Atkins as Sir Toby Belch and Norman Forbes as Sir Andrew Aguecheek are entertained by Feste in a 1932 production of Twelfth Night at the New theatre in London\n",
      "Answer: out of context\n",
      "id : 227, caption: Mahmoud Abbas made the announcement at a meeting in the West Bank city of Ramallah, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0348_602.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mahmoud Abbas made the announcement at a meeting in the West Bank city of Ramallah\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mahmoud Abbas made the announcement at a meeting in the West Bank city of Ramallah\n",
      "Answer: Yes\n",
      "id : 228, caption: Maria Kirilenko ran into an immovable force in Serena Williams, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0197_131.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Maria Kirilenko ran into an immovable force in Serena Williams\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Maria Kirilenko ran into an immovable force in Serena Williams\n",
      "Answer: Yes\n",
      "id : 229, caption: Stage winner and new overall leader Italy s Vincenzo Nibali climbs Bradfield, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0329_569.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stage winner and new overall leader Italy s Vincenzo Nibali climbs Bradfield\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stage winner and new overall leader Italy s Vincenzo Nibali climbs Bradfield\n",
      "Answer: out of context\n",
      "id : 230, caption: File photo taken in 2015 shows an illustration of an iPhone held up in front of the Apple logo, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0692_299.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:File photo taken in 2015 shows an illustration of an iPhone held up in front of the Apple logo\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:File photo taken in 2015 shows an illustration of an iPhone held up in front of the Apple logo\n",
      "Answer: Not out of context\n",
      "id : 231, caption: The sun rises at the USMexico border in Brownsville Texas on Sunday May 15 2016, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0185_040.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The sun rises at the USMexico border in Brownsville Texas on Sunday May 15 2016\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The sun rises at the USMexico border in Brownsville Texas on Sunday May 15 2016\n",
      "Answer: out of context\n",
      "id : 232, caption: Singer Beyonce poses at the 2011 MTV Video Music Awards in Los Angeles August 28 2011, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0362_250.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Singer Beyonce poses at the 2011 MTV Video Music Awards in Los Angeles August 28 2011\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Singer Beyonce poses at the 2011 MTV Video Music Awards in Los Angeles August 28 2011\n",
      "Answer: Out of context\n",
      "id : 233, caption: Jonny Moseley of the United States jumps in the finals of men s freestyle moguls in Nagano Moseley would go on to win a gold medal, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0601_043.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jonny Moseley of the United States jumps in the finals of men s freestyle moguls in Nagano Moseley would go on to win a gold medal\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jonny Moseley of the United States jumps in the finals of men s freestyle moguls in Nagano Moseley would go on to win a gold medal\n",
      "Answer: out of context\n",
      "id : 234, caption: The casket of Beau Biden arrives in Dover Del, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0713_713.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The casket of Beau Biden arrives in Dover Del\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The casket of Beau Biden arrives in Dover Del\n",
      "Answer: Yes, the image shows the casket of Beau Biden arriving in Dover, Delaware.\n",
      "id : 235, caption: Facebook is urging users to download the official WhatsApp app from Google Play, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0115_693.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Facebook is urging users to download the official WhatsApp app from Google Play\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Facebook is urging users to download the official WhatsApp app from Google Play\n",
      "Answer: Yes\n",
      "id : 236, caption: Sen Dianne Feinstein the ranking Democrat on the Intelligence Committee says that what the executive branch can create it should be able to dissolve referring to Guantanamo, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0268_756.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sen Dianne Feinstein the ranking Democrat on the Intelligence Committee says that what the executive branch can create it should be able to dissolve referring to Guantanamo\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sen Dianne Feinstein the ranking Democrat on the Intelligence Committee says that what the executive branch can create it should be able to dissolve referring to Guantanamo\n",
      "Answer: Guantanamo Bay\n",
      "id : 237, caption: Lytro s Illum camera allows user to focus their photos after taking them promising to make blurred shots a thing of the past, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0016_176.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Lytro s Illum camera allows user to focus their photos after taking them promising to make blurred shots a thing of the past\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Lytro s Illum camera allows user to focus their photos after taking them promising to make blurred shots a thing of the past\n",
      "Answer: Yes, the caption accurately describes the content of the image. The Lytro s Illum camera allows users to focus their photos after taking them, promising to make blurred shots a thing of the past.\n",
      "id : 238, caption: Verizon deal will see Vodafone deliver a huge dividend worth around 51bn, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0600_310.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Verizon deal will see Vodafone deliver a huge dividend worth around 51bn\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Verizon deal will see Vodafone deliver a huge dividend worth around 51bn\n",
      "Answer: yes\n",
      "id : 239, caption: Two pupils from Brighton college in East Sussex celebrate their GCSE results, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0061_680.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Two pupils from Brighton college in East Sussex celebrate their GCSE results\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Two pupils from Brighton college in East Sussex celebrate their GCSE results\n",
      "Answer: Out of context\n",
      "id : 240, caption: The nuclearpowered aircraft carrier Abraham Lincoln arrives at Naval Station Norfolk in Norfolk Va on Aug 7 2012, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0183_429.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The nuclearpowered aircraft carrier Abraham Lincoln arrives at Naval Station Norfolk in Norfolk Va on Aug 7 2012\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The nuclearpowered aircraft carrier Abraham Lincoln arrives at Naval Station Norfolk in Norfolk Va on Aug 7 2012\n",
      "Answer: Yes\n",
      "id : 241, caption: Police tape stretches across Union Hill Road in Pike County Eight family members were shot executionstyle according to authorities, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0558_309.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Police tape stretches across Union Hill Road in Pike County Eight family members were shot executionstyle according to authorities\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Police tape stretches across Union Hill Road in Pike County Eight family members were shot executionstyle according to authorities\n",
      "Answer: Out of context\n",
      "id : 242, caption: Firefighters clear debris away from the front of a home in Denton Texas to help a woman trapped in the house after a large tree was toppled, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0514_996.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Firefighters clear debris away from the front of a home in Denton Texas to help a woman trapped in the house after a large tree was toppled\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Firefighters clear debris away from the front of a home in Denton Texas to help a woman trapped in the house after a large tree was toppled\n",
      "Answer: Out of context\n",
      "id : 243, caption: Armed Turkana men herd goats inside the Ilemi Triangle region northwest Kenya Water scarcity has made it a disputed territory in east Africa claimed by South Sudan and Kenya, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0243_441.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Armed Turkana men herd goats inside the Ilemi Triangle region northwest Kenya Water scarcity has made it a disputed territory in east Africa claimed by South Sudan and Kenya\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Armed Turkana men herd goats inside the Ilemi Triangle region northwest Kenya Water scarcity has made it a disputed territory in east Africa claimed by South Sudan and Kenya\n",
      "Answer: Out of context\n",
      "id : 244, caption: Novak Djokovic of Serbia celebrates after winning his match against Milos Raonic of Canada 75 76, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0053_980.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Novak Djokovic of Serbia celebrates after winning his match against Milos Raonic of Canada 75 76\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Novak Djokovic of Serbia celebrates after winning his match against Milos Raonic of Canada 75 76\n",
      "Answer: out of context\n",
      "id : 245, caption: Sonny James performs during the Columbia Records show at Fan Fair on June 13 1975 at Municipal Auditorium, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0435_970.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sonny James performs during the Columbia Records show at Fan Fair on June 13 1975 at Municipal Auditorium\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Sonny James performs during the Columbia Records show at Fan Fair on June 13 1975 at Municipal Auditorium\n",
      "Answer: Out of context\n",
      "id : 246, caption: Adele Jackson Laura Martin Rachel Morris and Iain Pringle, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0272_020.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Adele Jackson Laura Martin Rachel Morris and Iain Pringle\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Adele Jackson Laura Martin Rachel Morris and Iain Pringle\n",
      "Answer: Out of context.\n",
      "id : 247, caption: Minnesota Rep Michele Bachmann is likely to form an exploratory committee to run for president in 2012, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0401_336.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Minnesota Rep Michele Bachmann is likely to form an exploratory committee to run for president in 2012\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Minnesota Rep Michele Bachmann is likely to form an exploratory committee to run for president in 2012\n",
      "Answer: Out of context\n",
      "id : 248, caption: Senators are dropping off snacks for House Democrats who are holding a sitin over lack of gun legislation, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0537_828.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Senators are dropping off snacks for House Democrats who are holding a sitin over lack of gun legislation\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Senators are dropping off snacks for House Democrats who are holding a sitin over lack of gun legislation\n",
      "Answer: Out of context\n",
      "id : 249, caption: Marianne Balshone pictured with her daughter and granddaughter now lives in Florida, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0000_162.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marianne Balshone pictured with her daughter and granddaughter now lives in Florida\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Marianne Balshone pictured with her daughter and granddaughter now lives in Florida\n",
      "Answer: Yes, the caption accurately describes the content of the image. The image shows Marianne Balshone posing for a picture with her daughter and granddaughter.\n",
      "id : 250, caption: New York US A special performance of Beneath The Veil at the Lincoln Centre for the Performing Arts, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0279_428.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:New York US A special performance of Beneath The Veil at the Lincoln Centre for the Performing Arts\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:New York US A special performance of Beneath The Veil at the Lincoln Centre for the Performing Arts\n",
      "Answer: Yes, the caption accurately describes the content of the image. It is a special performance of Beneath The Veil at the Lincoln Centre for the Performing Arts in New York.\n",
      "id : 251, caption: Iraqis reach for fruit during food distribution at Khazir refugee camp about 200 miles north of Baghdad, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0446_118.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Iraqis reach for fruit during food distribution at Khazir refugee camp about 200 miles north of Baghdad\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Iraqis reach for fruit during food distribution at Khazir refugee camp about 200 miles north of Baghdad\n",
      "Answer: Yes\n",
      "id : 252, caption: Kimberly Neal left is embraced at a gathering in memory of her brother in Milwaukee, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0238_197.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kimberly Neal left is embraced at a gathering in memory of her brother in Milwaukee\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kimberly Neal left is embraced at a gathering in memory of her brother in Milwaukee\n",
      "Answer: Yes, the caption accurately describes the content of the image. Kimberly Neal is being embraced at a gathering in memory of her brother in Milwaukee.\n",
      "id : 253, caption: Huu Do Chi is about to publish a comic art collection in the US, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0020_126.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Huu Do Chi is about to publish a comic art collection in the US\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Huu Do Chi is about to publish a comic art collection in the US\n",
      "Answer: Yes\n",
      "id : 254, caption: CCTV was captured of Clive Howard s car including its distinctive roofrack, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0445_263.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:CCTV was captured of Clive Howard s car including its distinctive roofrack\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:CCTV was captured of Clive Howard s car including its distinctive roofrack\n",
      "Answer: Yes, the caption accurately describes the content of the image. The image shows CCTV footage of Clive Howard's car, including its distinctive roofrack.\n",
      "id : 255, caption: Ruslan Nurudinov competes in the men s 105kg weightlifting final at Riocentro, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0770_002.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ruslan Nurudinov competes in the men s 105kg weightlifting final at Riocentro\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Ruslan Nurudinov competes in the men s 105kg weightlifting final at Riocentro\n",
      "Answer: Yes\n",
      "id : 256, caption: President Teresa A Sullivan has said the university is reexamining its sexual assault polices, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0586_203.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Teresa A Sullivan has said the university is reexamining its sexual assault polices\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:President Teresa A Sullivan has said the university is reexamining its sexual assault polices\n",
      "Answer: Yes\n",
      "id : 257, caption: The Greenbrier swimming pool in 1900 in White Sulphur Springs WVa, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0392_332.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Greenbrier swimming pool in 1900 in White Sulphur Springs WVa\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Greenbrier swimming pool in 1900 in White Sulphur Springs WVa\n",
      "Answer: Out of context\n",
      "id : 258, caption: Stewart endures yet another photo shoot this one in his Nationwide Series suit Nice nice shouts a director You re a pro That was bad ass, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0259_665.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stewart endures yet another photo shoot this one in his Nationwide Series suit Nice nice shouts a director You re a pro That was bad ass\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stewart endures yet another photo shoot this one in his Nationwide Series suit Nice nice shouts a director You re a pro That was bad ass\n",
      "Answer: out of context\n",
      "id : 259, caption: Nine Inch Nails vocalist Trent Reznor performs during a concert at Key Arena in Seattle in 2008, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0632_667.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Nine Inch Nails vocalist Trent Reznor performs during a concert at Key Arena in Seattle in 2008\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Nine Inch Nails vocalist Trent Reznor performs during a concert at Key Arena in Seattle in 2008\n",
      "Answer: Not out of context.\n",
      "id : 260, caption: Newt Gingrich pictured with wife Callista Gingrich checks many of the boxes that Donald Trump has said he is looking for in a vice president, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0245_622.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Newt Gingrich pictured with wife Callista Gingrich checks many of the boxes that Donald Trump has said he is looking for in a vice president\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Newt Gingrich pictured with wife Callista Gingrich checks many of the boxes that Donald Trump has said he is looking for in a vice president\n",
      "Answer: Yes\n",
      "id : 261, caption: A fan looks at a wax figure of Lady Gaga during the unveiling ceremony at Madame Tussauds in Shanghai China, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0760_302.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A fan looks at a wax figure of Lady Gaga during the unveiling ceremony at Madame Tussauds in Shanghai China\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:A fan looks at a wax figure of Lady Gaga during the unveiling ceremony at Madame Tussauds in Shanghai China\n",
      "Answer: The caption accurately describes the content of the image, as it depicts a fan looking at a wax figure of Lady Gaga during the unveiling ceremony at Madame Tussauds in Shanghai, China.\n",
      "id : 262, caption: Rimzim Dadu and her colleagues are trying to reinterpret Indian textiles, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0094_350.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rimzim Dadu and her colleagues are trying to reinterpret Indian textiles\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rimzim Dadu and her colleagues are trying to reinterpret Indian textiles\n",
      "Answer: Out of context\n",
      "id : 263, caption: The World Bank s Laurent Gonnet wants the country s commercial lenders to be less cautious, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0423_495.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The World Bank s Laurent Gonnet wants the country s commercial lenders to be less cautious\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The World Bank s Laurent Gonnet wants the country s commercial lenders to be less cautious\n",
      "Answer: The World Bank's Laurent Gonnet wants the country's commercial lenders to be less cautious.\n",
      "id : 264, caption: US Senator Kay Bailey Hutchison at the Tampa Bay convention, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0032_565.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:US Senator Kay Bailey Hutchison at the Tampa Bay convention\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:US Senator Kay Bailey Hutchison at the Tampa Bay convention\n",
      "Answer: Yes, the caption accurately describes the content of the image.\n",
      "id : 265, caption: The Corby Highland Gathering demonstrates Scottish culture alive in the town, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0312_726.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Corby Highland Gathering demonstrates Scottish culture alive in the town\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Corby Highland Gathering demonstrates Scottish culture alive in the town\n",
      "Answer: The caption accurately describes the content of the image, as it depicts a man playing the bagpipes at the Corby Highland Gathering, showcasing Scottish culture in the town.\n",
      "id : 266, caption: Mr Evans is leading a three man team to walk the 800 mile journey from from Salalah Oman to Doha Qatar, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0066_249.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mr Evans is leading a three man team to walk the 800 mile journey from from Salalah Oman to Doha Qatar\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Mr Evans is leading a three man team to walk the 800 mile journey from from Salalah Oman to Doha Qatar\n",
      "Answer: Out of context\n",
      "id : 267, caption: Rubio urges voters in Ohio to back Kasich, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0565_125.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rubio urges voters in Ohio to back Kasich\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Rubio urges voters in Ohio to back Kasich\n",
      "Answer: Yes\n",
      "id : 268, caption: Former BBC director general Mark Thompson leaves the public accounts committee hearing into payoffs to former colleagues, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0646_149.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former BBC director general Mark Thompson leaves the public accounts committee hearing into payoffs to former colleagues\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Former BBC director general Mark Thompson leaves the public accounts committee hearing into payoffs to former colleagues\n",
      "Answer: Out of context\n",
      "id : 269, caption: It took a host of Raiders defenders to stack up Lions running back Reggie Bush on a firsthalf run, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0717_734.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:It took a host of Raiders defenders to stack up Lions running back Reggie Bush on a firsthalf run\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:It took a host of Raiders defenders to stack up Lions running back Reggie Bush on a firsthalf run\n",
      "Answer: out of context\n",
      "id : 270, caption: Uma Thurman lights up in 1994 s Pulp Fiction WHO cites statistics claiming 44 of Hollywood films in 2014 contained smoking, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0014_310.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Uma Thurman lights up in 1994 s Pulp Fiction WHO cites statistics claiming 44 of Hollywood films in 2014 contained smoking\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Uma Thurman lights up in 1994 s Pulp Fiction WHO cites statistics claiming 44 of Hollywood films in 2014 contained smoking\n",
      "Answer: out of context\n",
      "id : 271, caption: Tensions are high between North and South Korea, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0761_050.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tensions are high between North and South Korea\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Tensions are high between North and South Korea\n",
      "Answer: Yes, the caption accurately describes the content of the image.\n",
      "id : 272, caption: Elon Musk CEO of Tesla Motors and SpaceX talked about Mars with Stephen Colbert, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0202_005.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elon Musk CEO of Tesla Motors and SpaceX talked about Mars with Stephen Colbert\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elon Musk CEO of Tesla Motors and SpaceX talked about Mars with Stephen Colbert\n",
      "Answer: yes\n",
      "id : 273, caption: HMS Plymouth was attacked by Argentine aircraft on 8 June 1982, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0382_132.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:HMS Plymouth was attacked by Argentine aircraft on 8 June 1982\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:HMS Plymouth was attacked by Argentine aircraft on 8 June 1982\n",
      "Answer: Yes\n",
      "id : 274, caption: Noomi Rapace best known her portrayal of Lisbeth Salander in the film adaptations of the Millennium series, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0057_541.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Noomi Rapace best known her portrayal of Lisbeth Salander in the film adaptations of the Millennium series\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Noomi Rapace best known her portrayal of Lisbeth Salander in the film adaptations of the Millennium series\n",
      "Answer: out of context\n",
      "id : 275, caption: Brad Pitt reportedly a fan of the Brown Derby, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0222_531.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brad Pitt reportedly a fan of the Brown Derby\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Brad Pitt reportedly a fan of the Brown Derby\n",
      "Answer: Yes\n",
      "id : 276, caption: Cristina Kirchner maintains that Argentina can t afford to pay the hedge funds But it pays for the rest of us to be skeptical, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0703_678.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cristina Kirchner maintains that Argentina can t afford to pay the hedge funds But it pays for the rest of us to be skeptical\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Cristina Kirchner maintains that Argentina can t afford to pay the hedge funds But it pays for the rest of us to be skeptical\n",
      "Answer: skeptical\n",
      "id : 277, caption: Stephanie and Dom the posh pair from Channel 4 s Gogglebox, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0311_584.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephanie and Dom the posh pair from Channel 4 s Gogglebox\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephanie and Dom the posh pair from Channel 4 s Gogglebox\n",
      "Answer: Out of context\n",
      "id : 278, caption: Men in uniform the Dolce Gabbana show during Milan fashion week springsummer 2015, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0511_019.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Men in uniform the Dolce Gabbana show during Milan fashion week springsummer 2015\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Men in uniform the Dolce Gabbana show during Milan fashion week springsummer 2015\n",
      "Answer: Out of context\n",
      "id : 279, caption: William Maisel chief scientist and deputy center director for science at the Food and Drug Administration s Center for Devices and Radiological Health, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0163_650.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:William Maisel chief scientist and deputy center director for science at the Food and Drug Administration s Center for Devices and Radiological Health\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:William Maisel chief scientist and deputy center director for science at the Food and Drug Administration s Center for Devices and Radiological Health\n",
      "Answer: Out of context\n",
      "id : 280, caption: Hiroyuki Fujita of Japan tees off on the 10th hole during the first round of the PGA Championship golf tournament at Oak Hill Country Club, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0353_918.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hiroyuki Fujita of Japan tees off on the 10th hole during the first round of the PGA Championship golf tournament at Oak Hill Country Club\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Hiroyuki Fujita of Japan tees off on the 10th hole during the first round of the PGA Championship golf tournament at Oak Hill Country Club\n",
      "Answer: Out of context\n",
      "id : 281, caption: Kvitova collapses after winning her second Wimbledon title, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0773_623.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kvitova collapses after winning her second Wimbledon title\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Kvitova collapses after winning her second Wimbledon title\n",
      "Answer: out of context\n",
      "id : 282, caption: Pedestrians and traffic move along Brigade Road in Bangalore India, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0710_255.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Pedestrians and traffic move along Brigade Road in Bangalore India\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Pedestrians and traffic move along Brigade Road in Bangalore India\n",
      "Answer: The caption accurately describes the content of the image, as it depicts pedestrians and traffic moving along Brigade Road in Bangalore, India.\n",
      "id : 283, caption: Green Bay Packers wide receiver Jordy Nelson is unable to make a catch, \n",
      " image_path: ./sample_300_semantics_text_image/usa_today_images_0102_680.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Green Bay Packers wide receiver Jordy Nelson is unable to make a catch\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Green Bay Packers wide receiver Jordy Nelson is unable to make a catch\n",
      "Answer: Out of context\n",
      "id : 284, caption: Robin van Persie started the World Cup on fire but needs to rediscover his top form for Holland to prevail against Argentina, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0665_855.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Robin van Persie started the World Cup on fire but needs to rediscover his top form for Holland to prevail against Argentina\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Robin van Persie started the World Cup on fire but needs to rediscover his top form for Holland to prevail against Argentina\n",
      "Answer: out of context\n",
      "id : 285, caption: Elizabeth Wilmshurst deputy legal adviser to the Foreign and Commonwealth Office 20012003 leaves after giving evidence at the Chilcot inquiry, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0316_763.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elizabeth Wilmshurst deputy legal adviser to the Foreign and Commonwealth Office 20012003 leaves after giving evidence at the Chilcot inquiry\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Elizabeth Wilmshurst deputy legal adviser to the Foreign and Commonwealth Office 20012003 leaves after giving evidence at the Chilcot inquiry\n",
      "Answer: out of context\n",
      "id : 286, caption: Giant panda cub Bao Bao explores an enclosure at the National Zoo, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0171_479.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Giant panda cub Bao Bao explores an enclosure at the National Zoo\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Giant panda cub Bao Bao explores an enclosure at the National Zoo\n",
      "Answer: The caption accurately describes the content of the image, as it depicts a giant panda cub named Bao Bao exploring an enclosure at the National Zoo.\n",
      "id : 287, caption: EuroMillions winner John Noakes said he would leave work, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0126_061.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:EuroMillions winner John Noakes said he would leave work\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:EuroMillions winner John Noakes said he would leave work\n",
      "Answer: out of context\n",
      "id : 288, caption: People attending Pridefest on the Summerfest grounds in Milwaukee join hands as a prayer is said for the victims of the Orlando nightclub mass shooting, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0686_261.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People attending Pridefest on the Summerfest grounds in Milwaukee join hands as a prayer is said for the victims of the Orlando nightclub mass shooting\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:People attending Pridefest on the Summerfest grounds in Milwaukee join hands as a prayer is said for the victims of the Orlando nightclub mass shooting\n",
      "Answer: The caption accurately describes the content of the image, which shows people attending Pridefest on the Summerfest grounds in Milwaukee joining hands as a prayer is said for the victims of the Orlando nightclub mass shooting.\n",
      "id : 289, caption: Counsel assisting the royal commission Gail Furness data shows Catholic archdiocese of Melbourne had 450 child sex abuse claims in 35 years, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0083_239.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Counsel assisting the royal commission Gail Furness data shows Catholic archdiocese of Melbourne had 450 child sex abuse claims in 35 years\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Counsel assisting the royal commission Gail Furness data shows Catholic archdiocese of Melbourne had 450 child sex abuse claims in 35 years\n",
      "Answer: Yes\n",
      "id : 290, caption: The Popular Party has faced public anger over corruption allegations linked to extreasurer Luis Barcenas, \n",
      " image_path: ./sample_300_semantics_text_image/bbc_images_0175_634.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Popular Party has faced public anger over corruption allegations linked to extreasurer Luis Barcenas\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The Popular Party has faced public anger over corruption allegations linked to extreasurer Luis Barcenas\n",
      "Answer: out of context\n",
      "id : 291, caption: The roles being cut are part of the 9000 job losses announced by Lloyds chief Antonio HortaOsorio in 2014, \n",
      " image_path: ./sample_300_semantics_text_image/washington_post_images_0253_029.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The roles being cut are part of the 9000 job losses announced by Lloyds chief Antonio HortaOsorio in 2014\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:The roles being cut are part of the 9000 job losses announced by Lloyds chief Antonio HortaOsorio in 2014\n",
      "Answer: Out of context\n",
      "id : 292, caption: Bradford City s sports psychologist John Muranka has been embraced by the manager Phil Parkinson after coming to the club under Peter Taylor, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0299_980.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bradford City s sports psychologist John Muranka has been embraced by the manager Phil Parkinson after coming to the club under Peter Taylor\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Bradford City s sports psychologist John Muranka has been embraced by the manager Phil Parkinson after coming to the club under Peter Taylor\n",
      "Answer: out of context\n",
      "id : 293, caption: Captain Ronald S Johnson a Ferguson native promised a new approach and has said he would visit the ground zero of protests, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0537_537.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Captain Ronald S Johnson a Ferguson native promised a new approach and has said he would visit the ground zero of protests\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Captain Ronald S Johnson a Ferguson native promised a new approach and has said he would visit the ground zero of protests\n",
      "Answer: out of context\n",
      "id : 294, caption: Felipe Massa of Williams gets his first podium finish of the season with third place, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0297_134.jpg \n",
      " falsified: True\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Felipe Massa of Williams gets his first podium finish of the season with third place\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Felipe Massa of Williams gets his first podium finish of the season with third place\n",
      "Answer: Out of context\n",
      "id : 295, caption: Jon Sparkes head of Crisis criticised the rules, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0456_264.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jon Sparkes head of Crisis criticised the rules\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Jon Sparkes head of Crisis criticised the rules\n",
      "Answer: Yes, the man in the photo is Jon Sparkes, the head of Crisis.\n",
      "id : 296, caption: Netflix is capitalising on the success of its shows like House of Cards and expanding its slate, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0207_988.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Netflix is capitalising on the success of its shows like House of Cards and expanding its slate\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Netflix is capitalising on the success of its shows like House of Cards and expanding its slate\n",
      "Answer: Yes\n",
      "id : 297, caption: Stephen Fry as Professor Gissing in Doors Open, \n",
      " image_path: ./sample_300_semantics_text_image/guardian_images_0329_752.jpg \n",
      " falsified: False\n",
      "User: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Fry as Professor Gissing in Doors Open\n",
      "Answer:\n",
      "Assistant: Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\n",
      "\n",
      "Caption:Stephen Fry as Professor Gissing in Doors Open\n",
      "Answer: out of context\n",
      "CSV file saved as image_caption_analysis_semantics_text_image_instructblip.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "json_path = \"./sample_300_semantics_text_image/sampled_annotations.json\"  # Adjust path as needed\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Path to JSON annotation file\n",
    "json_path = \"./sample_300_semantics_text_image/sampled_annotations.json\"\n",
    "image_dir = \"./sample_300_semantics_text_image/\"\n",
    "output_csv = \"image_caption_analysis_semantics_text_image_instructblip.csv\"\n",
    "i=0\n",
    "\n",
    "question = \"\"\"<image> ##Context##: You are an expert annotator working on misinformation. You are provided with an image and its caption. Evaluate whether the caption accurately represents the image. If the caption is out of context, identify which specific elements of the image do not align with the caption. \\n\n",
    "##Objective##: Determine if the caption is used in context with the image. \\n\n",
    "##Style##: Concise and factual \\n \n",
    "##Tone##: Neutral and objective. \\n\n",
    "##Response##: Provide your answer as one of the following words—either “out of context” or “not out of context”—without any additional explanation or details. \\n\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"caption\", \"image_path\", \"falsified_label\", \"intern_vl2_response\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=\",\")  # Explicit delimiter\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Iterate over each annotation\n",
    "    for  ann in data[\"annotations\"]:\n",
    "        caption = ann[\"caption\"]\n",
    "        image_path = os.path.join(image_dir, ann[\"image_path\"] + \".jpg\")\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Warning: Image not found at {image_path}\")\n",
    "            continue  # Skip missing images\n",
    "\n",
    "        # Construct the prompt\n",
    "        question = \"Does the caption accurately describe the content of this image, or is the image being used out of context? Only respond with one of the following words: [out of context, not out of context]. Do not provide any explanations or additional information.\"\n",
    "        prompt = f\"{question}\\n\\nCaption:{caption}\\nAnswer:\"\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        #prompt = \"Does the caption accurately describe the content of this image, or is the image being used out of context?/nCaption:Workers put up a preelection poster featuring Vladimir Putin and Dmitry Medvedev in Krasnodar Russia \"\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            num_beams=5,\n",
    "            max_length=256,\n",
    "            min_length=1,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.5,\n",
    "            length_penalty=1.0,\n",
    "            temperature=1,\n",
    "        )\n",
    "        generated_text = processor.batch_decode(outputs, skip_special_tokens=True)[0].strip()\n",
    "        # Process image with the model\n",
    "       \n",
    "        falsified = ann['falsified']\n",
    "        # Generate model response\n",
    "        print(f'id : {i}, caption: {caption}, \\n image_path: {image_path} \\n falsified: {falsified}')\n",
    "        print(f'User: {prompt}\\nAssistant: {generated_text}')\n",
    "\n",
    "        # Write to CSV\n",
    "        writer.writerow({\n",
    "            \"caption\": caption,\n",
    "            \"image_path\": image_path,\n",
    "            \"falsified_label\": ann['falsified'],  # Update this logic if you have falsification criteria\n",
    "            \"intern_vl2_response\": response\n",
    "        })\n",
    "        i = i +1\n",
    "\n",
    "print(f\"CSV file saved as {output_csv}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen-venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
